```{r 'exp3_prepare'}
# source("R/pdl9.export.raw.data.R")
load("data/pdl9.RData")

Acquisition$error <- 100 * Acquisition$error
Generation$FOC.correct <- 100 * Generation$FOC.correct

excludes <- c()
Acquisition[["excluded.id"]] <- as.integer(Acquisition[["id"]] %in% excludes)
Generation[["excluded.id"]] <- as.integer(Generation[["id"]] %in% excludes)

Generation[["excluded.id"]] <- as.integer(Generation[["id"]] %in% excludes)
## This should be consistent!
# table(Generation$id, Generation$excluded.id)
```

Experiments 1 and 2 found a violation of the invariance assumption, suggesting that the interpretation of the parametric PD approach may be problematic. 
In particular, the results of Experiments 1 and 2 consistently suggest that the PD parameters may not yield an exhaustive measure of explicit knowledge:
The degree to which participants made use of their explicit knowledge varied between the inclusion and exclusion tasks.
Experiment 3 aimed at obtaining a better understanding of this invariance violation and its effect on the interpretation of generation task performance in the PD framework.

Whereas the invariance violations clearly threaten the validity of the PD model, they may yet turn out to be uncritical for an ordinal interpretation of PD data that has often been used in applications (i.e., a comparison of inclusion versus exclusion performance, and of exclusion versus baseline performance).
Even if the (independence and) invariance assumptions do not hold, the general approach of drawing conclusions about the underlying processes by comparing performance between inclusion and exclusion conditions may not be entirely invalidated:
It has been formally shown that an ordinal interpretation of PD findings does not rely on parametric assumptions [@hirshman_ordinal_2004].
However, the ordinal PD approach does assume that baseline performance is identical in the inclusion and exclusion tasks -- an assumption that has been shown to be violated at least in some cases [@stahl_distorted_2015]. 
More critically for the present question of invariance, it also assumes (not only that inclusion performance increases but also) that exclusion performance monotonically decreases with increasing explicit knowledge.
Note that, if (contrary to this assumption) explicit knowledge does not affect exclusion performance at all, the ordinal PD approach may technically still be used.
However, the results would be misleading if a difference in explicit (but not implicit) knowledge between two conditions led to a difference in inclusion but not in exclusion performance.
In this case, the ordinal PD would suggest that the two conditions differ in explicit *and implicit* knowledge [@hirshman_ordinal_2004, Data Pattern I].
In other words, for the ordinal PD approach to yield valid results, exclusion performance must fall below baseline when explicit knowledge is present (this would yield Hirshman's Data Pattern IV, which indicates an increase in explicit knowledge).
Therefore, a critical empirical test for the ordinal PD approach is whether, and under which conditions, participants are able to use explicit knowledge to suppress generation below baseline levels under exclusion conditions. 

A critical precondition for the expression of explicit knowledge may be the opportunity for practice with the generation task. 
Experiment 3 investigated the effect of practice on the expression of explicit knowledge: 
In Experiments 1 and 2, participants were given the opportunity to practice inclusion and exclusion of the instructed explicit knowledge, but nevertheless failed to approach ceiling (floor) performance in the inclusion (exclusion) conditions.
In Experiment 3, we investigated whether such transition-specific practice can help reduce the invariance violation by comparing practiced with non-practiced transitions.
We also wanted to more directly investigate transfer of practice to unpracticed transitions about which participants had explicit knowledge.
We therefore manipulated the number of revealed transitions, and whether these revealed transitions were revealed prior to or after practice blocks, both  between and within subjects.
We realized five between-subjects conditions:

1. In the *Control* group, no explicit knowledge was revealed to participants.

<!-- 3. Explicit knowledge without practice (1 transition, non-practiced, *non-practiced*): -->
2. In the *No-Practice* group, 
one transition <!--(third & fourth location of the sequence)--> was revealed immediately before the first generation block,
but *after* the practice blocks that preceded the first generation block. 
To avoid carry-over of practice effects from the first generation block, a different non-practiced transition  <!--(fifth & sixth location of the sequence)--> was revealed after the second practice blocks and immediately preceding the second generation block.

<!-- 5. Explicit knowledge with unspecific inhibition practice (1 transition with *unspecific* practice): -->
3. In the *Unspecific-Practice* group,
one transition was revealed to participants *after* practive, immediately before each generation block (as in the *No-Practice* group).
In the third practice block before the exclusion task, participants were asked to inhibit a specific response location (i.e., they were asked *not* to use the $5^{th}$ location/$N$ key).

<!-- 2. Explicit knowledge with practice (1 transition, practiced, *practiced*): -->
4. In the *Practice* group, 
one transition <!--(first & second location of the sequence)--> was revealed to participants immediately *before* the practice blocks. Participants were encouraged to include (exclude) the revealed transition during practice and in the generation block.

<!-- 4. Explicit knowledge with & without practice (1 transition practiced + 1 transition non-practiced, *practiced & non-practiced*): -->
5. In the *Transfer* group, information about two transitions was revealed; one of them was non-practiced (as in the No-Practice group), the other one practiced (as in the Practice group).
The practiced transition <!--(first & second location of the sequence)--> was revealed before the first practice blocks.
After these practice blocks, the second (non-practiced) transition  <!--(third & fourth location of the sequence)--> was revealed immediately before the first generation block.
The practiced transition was again named before participants worked on the practice blocks of the second generation phase.
After these practice blocks, a second non-practiced transition  <!--(fifth & sixth location of the sequence)--> was revealed immediately before the second generation block.


The Control and Practice groups were identical to Experiment 1; the other groups extended the previous design.
This allowed us to assess generation performance for three main transition types; (1) *non-revealed* transitions, (2) transitions that were revealed but remained *non-practiced*, and (3) transitions that were revealed and *practiced* in the practice blocks.
^[In the second generation block of the No-Practice, Unspecific-Practice, and Transfer groups, a fourth transition type can be distinguished: Transitions that were revealed but non-practiced before the first generation block. Because participants included (or excluded) these transitions in the previous (i.e., the first) generation block, performance on these transitions should be more similar to practiced than to non-practiced transitions in the second block.]

A comparison of *non-revealed* with (revealed but) *non-practiced* transitions allows us to assess the degree to which participants can spontaneously make use of their explicit knowledge in the generation task.
Comparing *non-practiced* with *practiced* transitions allowed us to assess whether specific inclusion/exclusion practice could increase the use of explicit knowledge to a comparable level in the inclusion and exclusion tasks (i.e., eliminate the violation of invariance).
We also compared whether performance for revealed but *non-practiced* transitions differs between the No-Practice and Transfer groups, as would be expected if the effect of specific practice transfers to non-practiced explicit knowledge.
Finally, we explored whether, in the Unspecific-Practice group, unspecific inhibition practice affects performance for both revealed but *non-practiced* and/or *non-revealed* transitions.

In sum, we hypothesized that, as in Experiment 1, the invariance assumption for the controlled process would be violated.
Relatedly, we aimed at replicating the finding that possessing explicit knowledge would not be sufficient for its expression in the generation task.
Specifically, (a) explicit knowledge without practice (*No-Practice* group) should not lead to below-chance exclusion performance, 
and (b) this should also hold for non-practiced transitions for participants who practiced another transition (*Transfer* group). 
We had no clear hypothesis regarding the unspecific response-inhibition practice,
but wanted to explore whether it would be as effective as transition-specific exclusion practice in improving the validity of the generation task as a measure of explicit knowledge.
Finally, Experiment 3 addresses a possible artifactual effect of practice on the invariance violation.
Specifically, the practice blocks administered in Experiments 1 and 2 might have *caused* the invariance violation. If this was the case, then invariance should not be violated in the absence of such practice.

## Method

### Design

The study realized a 5 (*Practice group*: Control, No-Practice, Unspecific-Practice, Practice, Transfer)
<!-- *explicit knowledge*: no explicit knowledge, explicit knowledge with practice, explicit knowledge without practice, explicit knoledge with & without practice, explicit knowledge with unspecific inhibition practice)-->
$\times$ 2 (*PD instruction*: inclusion vs. exclusion) $\times$ 2 (*block order*: inclusion first vs. exclusion first) design with repeated measures on the *PD instruction* factor.

### Participants

```{r 'exp3_participants'}
N <- length(unique(Generation[["id"]]))
n.excludes <- length(excludes)

tmp<-aggregate(formula = RT~id+female+age, data = Generation, FUN = mean)
Sex<-table(tmp[["female"]])

meanAge<-paste0("$M = ", (round(mean(tmp[["age"]]),digits=1)), "$")
rangeAge<-paste(c(min(tmp[["age"]]),max(tmp[["age"]])),collapse=" and ")
```


`r #N` One hundred and forty-seven participants (`r Sex["1"]` women) aged between `r rangeAge` years (`r meanAge` years) completed the study.
Most were undergraduates from Heinrich-Heine-Universität Düsseldorf.
Participants were randomly assigned to experimental conditions.
They received either course credit or 3.50 Euro for their participation.

### Materials and Procedure

The experimental procedure closely followed Experiment 1.
During an SRTT consisting of 8 blocks with 144 trials each (for a total of 1,152 responses), participants in all conditions were trained with a 
*probabilistic* sequence similar to the one used in Experiment 1.
After the SRTT, participants were informed about the underlying sequential structure of stimulus locations and asked to generate a short sequence of six key presses that followed this (unspecified) structure.

The generation task followed, with counterbalanced order of inclusion versus exclusion blocks. 
The number of practice blocks was held constant (in contrast to Experiment 1, where it depended on performance).
Upon completing the computerized task, participants answered the same questionnaire as in Experiment 1.

### Data analysis

Given that model  $\mathcal{M}_2$  failed to fit the data from both Experiments 1 and 2 and model, we fitted only model $\mathcal{M}_1$ and used posterior analyses to evaluate the invariance assumption.
For the model-based analyses, we adapted the equations from Experiment 1 to the design of Experiment 3 (which did not contain experimental groups with random material).

In order to accommodate for the more complex design, we used a model specification that allowed for participant and item (i.e., transition) effects and their interactions by estimating fixed effects for each transition type plus individual participants' deviations from these effects.
The model equations of model $\mathcal{M}_1$ are given by:

$$
  C_{ijm} = \begin{cases}
    \Phi(\mu_{jlm}^{(C)} + \delta_{ijm}^{(C)}) & \text{if } j \epsilon 1, 2 \text{ (item has been revealed \& practiced, revealed \& non-practiced)}\\
                                              0 & \text{if }j=3 \text{ (item has not been revealed)}\\
    \end{cases}
$$
and
$$
  A_{imt} = \Phi(\mu_{mt}^{(A)} + \delta_{imt}^{(A)})
$$

where $\mu_{jlm}^{(C)}$
is the fixed effect of transition type $j$ (non-revealed, revealed & practiced, revealed & non-practiced) in condition $l$ and *PD instruction* condition $m$ on controlled processes, and
$\delta_{ijm}^{(C)}$ is the $i$th participant's deviation from the corresponding mean.
Accordingly, $\mu_{mt}^{(A)}$ is the fixed effect of *PD instruction* condition $m$ and transition $t$ on automatic processes, and
$\delta_{imt}^{(A)}$ is the $i$th participant's deviation from the corresponding mean.

Model $\mathcal{M}_1$ imposes two auxiliary assumptions:
First, it assumed that no explicit knowledge has been acquired during the SRT phase (i.e., $C=0$ for non-revealed transitions).
Second, it assumed that revealing sequence knowledge did not affect automatic processes (i.e., $A$ does not vary as a function of the between-subjects manipulation of explicit knowledge, index $l$).
Both auxiliary assumptions were tested by posterior predictive checks.
In addition to reporting $T_{A1}$ and $T_{B1}$ as in the previous studies, we calculated additional model check statistics $T_{A2}$, which summarizes how well the model describes the item-wise category counts (aggregated over participants), and $T_{A3}$, which summarizes how well the model describes the category counts per participant-item combination; finally, the additional statistic $T_{B2}$ summarizes how well the model describes the variances and covariances introduced by items.
We also calculated the posterior differences $C_I - C_E$ and $A_I - A_E$ to more directly test the invariance assumption.



## Results

We first analyzed the performance data from the SRT task in a traditional way to determine whether sequence knowledge had been acquired during the task.
Next, we analyzed generation task performance using a hierarchical PD model.
Finally, to test our predictions regarding the different effects of practice in a model-free manner we analyzed generation performance for transitions that were revealed.

### Acquisition task

If participants acquired knowledge about the regularity underlying the sequence of key presses, we expect a performance advantage for regular over irregular transitions, reflected in reduced RT and/or error rate.
If this advantage is due to learning, it is expected to increase over SRTT blocks.

#### Reaction times

```{r 'exp3_acquisition_RT', fig.width = 4.4, fig.cap="RTs during acquisition phase, split by *FOC transition status*. Error bars represent 95% within-subjects confidence intervals.\\label{fig:figure_exp3_RT}"}
par(mfrow = c(1, 1))
exp3_acq_RT <- Acquisition[Acquisition[["excluded.id"]]==0 & Acquisition[["Trial.Nr"]] > 1 & Acquisition[["error"]]==0  & Acquisition[["vR.error"]]==0
                            & Acquisition[["RT"]]<1000 & Acquisition[["RT"]]>50,]

apa_lineplot(data = exp3_acq_RT, id = "id", factors = c("Block number", "FOC transition status"), dv = "SRI", ylim = c(440, 540), ylab = "Reaction time [msec]", dispersion = wsci, args_arrows = list(length = .05))

exp3_acq_RT.out <- apa.glm(
       data = exp3_acq_RT
       , dv = "SRI"
       , id = "id"
       , within = c("Block number", "FOC transition status"))
#knitr::kable(exp3_acq_RT.out$table)

```

For all RT analyses, we excluded the first trial of each block as well as trials with errors, trials succeeding an error, reactions faster than 50 ms and those slower than 1,000 ms.
Figure 9 shows reaction times during acquisition.

We conducted a `r exp3_acq_RT.out$name` repeated-measures ANOVA.
There was a main effect of *block number*,
`r exp3_acq_RT.out[["Block_number"]]`, with RT decreasing over blocks. 
There also was a main effect of *FOC transitions status*,
`r exp3_acq_RT.out[["FOC_transition_status"]]`,
reflecting faster responses to regular than to irregular transitions.
The interaction of *block* and *FOC transition status* was also significant,
`r exp3_acq_RT.out[["Block_number_FOC_transition_status"]]`, reflecting the finding that the RT advantage for regular transitions increased over blocks, which indicated successful sequence learning.

#### Error rates

```{r 'exp3_acquisition_err', fig.width = 4.4, fig.cap="Error rates during acquisition phase, split by *FOC transition status*. Error bars represent 95% within-subjects confidence intervals. \\label{fig:figure_exp3_ER}"}
## Error rates

exp3_acq_err <- Acquisition[Acquisition[["Trial"]]>1 & Acquisition[["excluded.id"]]==0, ]

apa_lineplot(id = "id", dv = "error", data = exp3_acq_err, factors = c("Block number","FOC transition status"), dispersion = wsci, ylim = c(0, 10), args_arrows = list(length = .05), ylab = "Error rate [%]")

exp3_acq_err.out <- apa.glm(data = exp3_acq_err
                             ,id = "id"
                             , dv = "error"
                             , within = c("Block number", "FOC transition status"))
#knitr::kable(exp3_acq_err.out$table)


```


For all analyses of error rates, we excluded the first trial of each block.
Figure 10 shows error rates during acquisition.

The pattern of findings was similar to that obtained for RT.
We conducted an `r exp3_acq_err.out$name` repeated-measures ANOVA that revealed
a main effect of *block number*,
`r exp3_acq_err.out[["Block_number"]]`,
reflecting increasing error rates over blocks;
and a main effect of *FOC transition status*,
`r exp3_acq_err.out[["FOC_transition_status"]]`,
reflecting an accuracy advantage (i.e., lower error rates) for regular transitions.
The interaction of *block number* and *FOC transition status* was also significant,
`r exp3_acq_err.out[["Block_number_FOC_transition_status"]]`,
reflecting an increase of the accuracy advantage for regular (as compared to irregular) transitions over blocks, indicating successful sequence learning.


### Generation task

We analyzed generation performance by fitting $\mathcal{M}_1$ and computed model fit statistics to assess whether each model can account for the data. 
Parameter estimates from model $\mathcal{M}_1$ were used to address the invariance assumptions, directly.
The first trial of a block as well as any response repetitions were excluded from all generation task analyses.

```{r cache = FALSE}
load("hierarchical_pd/exp3_stan_summary.RData")

# DIC_1vs2 <- papaja::printnum(M2$num$DIC - M1$num$DIC, digits = 2, big.mark = ",")
# DIC_1vs2a <- papaja::printnum(M2a$num$DIC - M1$num$DIC, digits = 2, big.mark = ",")

```

```{r}
load(file = "hierarchical_pd/exp3/pd_Halt_cdfs.RData")
a <- paste0("$p = ", papaja::printp(cdfs$difference_of_means$a(0)), "$") 
c_practiced <- paste0("$p = ", papaja::printp(cdfs$difference_of_means$c_practiced(0)), "$")
c_nonpracticed <- paste0("$p = ", papaja::printp(cdfs$difference_of_means$c_nonpracticed(0)), "$")

# credible interval of difference
ci.a <- paste0("95% CI [", paste(papaja::printnum(quantile(cdfs$difference_of_means$a, c(.025, .975)), gt1 = FALSE), collapse = ", "), "]")
ci.c_practiced <- paste0("95% CI [", paste(papaja::printnum(quantile(cdfs$difference_of_means$c_practiced, c(.025, .975)), gt1 = FALSE), collapse = ", "), "]")
ci.c_nonpracticed <- paste0("95% CI [", paste(papaja::printnum(quantile(cdfs$difference_of_means$c_nonpracticed, c(.025, .975)), gt1 = FALSE), collapse = ", "), "]")
```


The model checks for model $\mathcal{M}_1$ were satisfactory,
`r M1$fit`

Figure 11 shows the parameter estimates obtained from model $\mathcal{M}_1$; while estimates of the automatic process were only slightly above chance in both *PD instruction* conditions, estimates of the controlled process differ strongly between *PD instruction* conditions.

Figure 12 shows that the invariance assumption for automatic processes was violated with $A_I > A_E$, `r ci.a`, and Bayesian `r a`.
For revealed and practiced transitions, the invariance assumption was violated with $C_I >  C_E$, `r ci.c_practiced` and a Bayesian `r c_practiced`.
For revealed but non-practiced transitions, the invariance assumption was violated with $C_I >  C_E$, `r ci.c_nonpracticed` and a Bayesian `r c_nonpracticed`.



```{r fig.cap = "Parameter estimates from Experiment 3. Error bars represent 95% confidence intervals."}
load("hierarchical_pd/exp3/pd_Halt_posteriors.RData")

par(mfrow = c(1, 2))

apa_beeplot(
  data = means_df[means_df$Parameter=="a", ]
  , id = "person"
  , dv = "Estimate"
  , factors = c("PD instruction")
  , ylim = c(0, 1)
)

apa_beeplot(
  data = means_df[means_df$Parameter=="c", ]
  , id = "person"
  , dv = "Estimate"
  , factors = c("transition", "PD instruction")
  , ylim = c(0, 1)
)
```


```{r fig.height = 5, fig.width = 8.8, fig.cap = "Posterior differences between $A_I - A_E$ and $C_I - C_E$ in Experiment 3, plotted for each participant (gray dots) with 95% credible intervals. Dashed lines represent the posterior means of the differences between mean parameter estimates. Dotted lines represent 95% credible intervals."}

load(file = "hierarchical_pd/exp3/posteriors_for_plot.RData")

N <- sum(!is.na(delta_quantiles[1, ,1]))

par(mfrow = c(1, 3))

# a parameter for all transitions
k <- "a"
plot.default(
  x = 1:N
  , col = "white"
  , xlim = c(0, N+1)
  , ylim = c(-1, 1)
  , xlab = "Participant"
  , ylab = "Difference between Inclusion and Exclusion"
  , main = bquote(italic(A[I]) -italic(A[E])~ .(paste0(", all transitions")))
  , frame.plot = FALSE
  , xaxt = "n"
  , las = 1
)

tmp <- delta_quantiles[, order(delta_quantiles[3, , k]), k]
# Credible Intervals
segments(x0 = 1:N, x1 = 1:N, y0 = tmp[1, ], y1 = tmp[5, ], col = "lightgrey", lwd = .5)
segments(x0 = 0:(N-1), x1 = 2:(N+1), y0 = tmp[1, ], y1 = tmp[1, ], col = "lightgrey", lwd = .5)
segments(x0 = 0:(N-1), x1 = 2:(N+1), y0 = tmp[5, ], y1 = tmp[5, ], col = "lightgrey", lwd = .5)

abline(h = 0, lty = "solid", col = "grey60")
abline(h = posterior_mean_delta, lty = "dashed", col = "darkred")
abline(h = posterior_quantiles_delta[c("2.5%", "97.5%")], lty = "dotted", col = "darkred")
    
# Medians: posterior_mean_delta
points(x = 1:N, tmp[3, ], col = "grey40", pch = 21, bg = "grey40", cex = .5)
# points(x = 1:121, tmp[3, ], col = "lightgrey", pch = 21, bg = "lightgrey", cex = .05)

## Credible Interval eye-candy
segments(x0 = 1:N, x1 = 1:N, y0 = tmp[1, ], y1 = tmp[5, ], col = "lightgrey", lwd = .1)
segments(x0 = 0:(N-1), x1 = 2:(N+1), y0 = tmp[1, ], y1 = tmp[1, ], col = "lightgrey", lwd = .1)
segments(x0 = 0:(N-1), x1 = 2:(N+1), y0 = tmp[5, ], y1 = tmp[5, ], col = "lightgrey", lwd = .1)

axis(side = 1, at = c(1, N), labels = c(1, N))

N2 <- sum(!is.na(practiced_quantiles[1,]))
# c parameter
k <- "c"
j <- "practiced"
tmp <- practiced_quantiles[, order(practiced_quantiles[3, ])][, 1:N2]


plot.default(
      x = 1:N2
      , col = "white"
      , xlim = c(0, N2+1)
      , ylim = c(-1, 1)
      , xlab = "Participant"
      , ylab = "Difference between Inclusion and Exclusion"
      , main = bquote(italic(C[I]) -italic(C[E])~ .(paste0(", ", j, " transitions")))
      , frame.plot = FALSE
      , xaxt = "n"
      , las = 1
    )


# Credible Intervals

segments(x0 = 1:N2, x1 = 1:N2, y0 = tmp[1, ], y1 = tmp[5, ], col = "lightgrey", lwd = .5)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[1, ], y1 = tmp[1, ], col = "lightgrey", lwd = .5)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[5, ], y1 = tmp[5, ], col = "lightgrey", lwd = .5)

abline(h = 0, lty = "solid", col = "grey60")
abline(h = posterior_mean_delta_practiced, lty = "dashed", col = "darkred")
abline(h = posterior_quantiles_delta_practiced[c("2.5%", "97.5%")], lty = "dotted", col = "darkred")

# Medians
points(x = 1:N2, y = tmp[3, ], col = "grey40", pch = 21, bg = "grey40")
# points(x = 1:61, tmp[3, ], col = "lightgrey", pch = 21, bg = "lightgrey", cex = .1)
# Credible Intervals eye-candy
segments(x0 = 1:N2, x1 = 1:N2, y0 = tmp[1, ], y1 = tmp[5, ], col = "lightgrey", lwd = .1)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[1, ], y1 = tmp[1, ], col = "lightgrey", lwd = .1)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[5, ], y1 = tmp[5, ], col = "lightgrey", lwd = .1)
axis(side = 1, at = c(1, N2), labels = c(1, N2))

N2 <- sum(!is.na(nonpracticed_quantiles[1,]))
# c parameter
k <- "c"
j <- "non-practiced"
tmp <- nonpracticed_quantiles[, order(nonpracticed_quantiles[3, ])][, 1:N2]


plot.default(
  x = 1:N2
  , col = "white"
  , xlim = c(0, N2+1)
  , ylim = c(-1, 1)
  , xlab = "Participant"
  , ylab = "Difference between Inclusion and Exclusion"
  , main = bquote(italic(C[I]) -italic(C[E])~ .(paste0(", ", j, " transitions")))
  , frame.plot = FALSE
  , xaxt = "n"
  , las = 1
)


# Credible Intervals

segments(x0 = 1:N2, x1 = 1:N2, y0 = tmp[1, ], y1 = tmp[5, ], col = "lightgrey", lwd = .5)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[1, ], y1 = tmp[1, ], col = "lightgrey", lwd = .5)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[5, ], y1 = tmp[5, ], col = "lightgrey", lwd = .5)

abline(h = 0, lty = "solid", col = "grey60")
abline(h = posterior_mean_delta_nonpracticed, lty = "dashed", col = "darkred")
abline(h = posterior_quantiles_delta_nonpracticed[c("2.5%", "97.5%")], lty = "dotted", col = "darkred")

# Medians
points(x = 1:N2, y = tmp[3, ], col = "grey40", pch = 21, bg = "grey40")
# points(x = 1:61, tmp[3, ], col = "lightgrey", pch = 21, bg = "lightgrey", cex = .1)
# Credible Intervals eye-candy
segments(x0 = 1:N2, x1 = 1:N2, y0 = tmp[1, ], y1 = tmp[5, ], col = "lightgrey", lwd = .1)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[1, ], y1 = tmp[1, ], col = "lightgrey", lwd = .1)
segments(x0 = 0:(N2-1), x1 = 2:(N2+1), y0 = tmp[5, ], y1 = tmp[5, ], col = "lightgrey", lwd = .1)
axis(side = 1, at = c(1, N2), labels = c(1, N2))
```



```{r 'exp3_generation', fig.cap = "Proportions of correctly generated transitions during PD generation task, excluding repetitions"}
exp3gen <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["excluded.id"]]==0,]
exp3gen$Instruktion <- relevel(exp3gen$Instruktion, "Inklusion")
exp3gen.out <- apa.glm(data = exp3gen
                       , dv="FOC.correct"
                       , id="id"
                       , between=c("Condition","Order")
                       , within=c("PD instruction"))
#knitr::kable(exp3gen.out$table)

# apa_barplot(data = exp3gen, dv = "FOC.correct", id = "id", factors = c("Condition", "PD instruction"), ylim = c(0, 1), ylab = "Proportion correct")

# apa_barplot(data = exp3gen[exp3gen[["PD instruction"]]=="Exclusion",], dv = "FOC.correct", id = "id", factors = c("Order"), ylim = c(0, 1), ylab = "Proportion correct")

# 
# library(BayesFactor)
# 
# exp3gen$id <- as.factor(exp3gen$id)
# agg <- apa.aggregate(data = exp3gen, dv = "FOC.correct", factors = c("id", "Condition", "Order", "Instruktion"), fun = mean)
# # BF <- anovaBF(formula = FOC.correct ~ Condition * Order * Instruktion + id, whichRandom = "id", data = agg, whichModels = "top")
# # BF <- recompute(BF, multicore = TRUE, iterations = 10^5)

## separate t tests
fun.tmp <- function(x) {
  apa.t.test(data = x, within = "Instruktion", dv = "FOC.correct", id = "id")
}

t.out <- lapply(X = split(exp3gen, f = exp3gen$Condition), FUN = fun.tmp)

```



```{r 'exp3_gen_block1'}
exp3gen_block1 <- Generation[Generation[["Trial"]] > 1&Generation[["repetition"]]==0&Generation[["Block.Nr"]]=="first"&Generation[["excluded.id"]]==0,]

exp3gen_block1.out <- apa.glm(data=exp3gen_block1
                              , id = "id"
                              , dv = "FOC.correct"
                              , between = c("Condition","PD instruction"))

#apa_barplot(data = exp3gen_block1, dv = "FOC.correct", id = "id", factors = c("Condition", "PD instruction"), ylim = c(0, 1), ylab = "Proportion correct")

## separate t tests
fun.tmp <- function(x) {
  apa.t.test(data = x, between = "PD instruction", dv = "FOC.correct", id = "id")
}

t.out <- lapply(X = split(exp3gen_block1, f = exp3gen_block1$Condition), FUN = fun.tmp)

```


### Effects of practice on generation of revealed transitions

To test our predictions regarding the different effects of practice in a model-free manner, we analyzed raw generation frequencies for only those transitions about which explicit knowledge was revealed.

```{r 'exp3_gen_revealed', fig.cap = "Generation performance for revealed transitions. Error bars represent 95% confidence intervals. Horizontal lines represent chance baseline."}

Generation$Condition <- factor(
  Generation$InstrExpl
  , levels = c("Expl.No", "Expl.NoOne", "Expl.PosOne", "Expl.One", "Expl.OneOne")
  , labels = c("Control", "No-Practice", "Unspecific-Practice", "Practice", "Transfer")
)


exp3gen_rev <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["excluded.id"]]==0 & Generation[["vR.revealed"]]!="not", ]

exp3gen_rev.out <- apa.glm(data=exp3gen_rev
               , id = "id"
               , dv = "FOC.correct"
               , between = c("Condition", "Order")
               , within = c("PD instruction"))

#knitr::kable(exp3gen_rev.out$table)

apa_barplot(data = exp3gen_rev, dv = "FOC.correct", id = "id", factors = c("Condition", "PD instruction"), ylim = c(0, 100), ylab = "Percentage correct")

## separate t tests
fun.tmp <- function(x) {
  apa.t.test(data = x, within = "Instruktion", dv = "FOC.correct", id = "id")
}
exp3gen_rev$Instruktion <- relevel(exp3gen_rev$Instruktion, "Inklusion")
t.out <- lapply(X = split(exp3gen_rev, f = exp3gen_rev$Condition)[-1], FUN = fun.tmp)



```

Figure 13 shows generation performance for revealed transitions.
A `r exp3gen_rev.out$name` ANOVA revealed 
a nonsignificant main effect of *Condition*, `r exp3gen_rev.out[["Condition"]]`, 
but a significant main effect of *PD instruction*, `r exp3gen_rev.out[["PD_instruction"]]`,
and their significant interaction, `r exp3gen_rev.out[["Condition_PD_instruction"]]`.
The main effect of *PD instruction* reflects the clear influence of the instructed explicit knowledge depicted in figure 13.
It is present in all practice conditions but modulated by amount of knowledge and type of practice (i.e., greater effects given specific practice): 
The effect was greatest in the *Transfer* group, `r t.out[["Transfer"]][["stat"]]`;
somewhat smaller in the *Practice* group, `r t.out[["Practice"]][["stat"]]`; 
it was still smaller and comparable without practice, *No-practice* group, `r t.out[["No-Practice"]][["stat"]]`; or with only unspecific practice, *Unspecific-practice* group, `r t.out[["Unspecific-Practice"]][["stat"]]`.

We investigated this issue more closely in two sets of follow-up analyses.
Whereas the above findings support the hypothesis that practice improves the degree to which explicit knowledge is expressed in the generation task, it does not elucidate the mechanism by which this occurs. 
One mechanism by which practice may improve performance is by boosting the proportion of regular transitions in inclusion blocks. 

#### Inclusion

```{r 'exp3_gen_revealed_hyps_incl', fig.cap = "Inclusion performance for revealed transitions. Left: Between-subjects comparison between *No-Practice* and *Practice* groups. Right: Within-subjects comparison in *Transfer* group. Horizontal lines represent chance baseline."}

par(mfrow = c(1, 2))

## Practice effect: Between-subjects comparison

tmp<-Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & (Generation[["InstrExpl"]]=="Expl.One"|Generation[["InstrExpl"]]=="Expl.NoOne") & Generation[["vR.Start.instruiert"]]==1 & Generation[["PD instruction"]]=="Inclusion" & Generation[["excluded.id"]]==0,]

tmp<-Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & (Generation[["InstrExpl"]]=="Expl.One"|Generation[["InstrExpl"]]=="Expl.NoOne") & (Generation[["vR.revealed"]]=="postT.recently"| Generation[["vR.revealed"]]=="preT") & Generation[["PD instruction"]]=="Inclusion" & Generation[["excluded.id"]]==0,]


tmp[["InstrExpl"]]<-droplevels(tmp[["InstrExpl"]])
tmp[["transition"]]<-factor(tmp[["InstrExpl"]],levels=c("Expl.One","Expl.NoOne"),labels = c("practiced","non-practiced"))

between <- apa.glm(data = tmp, dv = "FOC.correct", id = "id", between = c("InstrExpl"))

apa_barplot(
  data = tmp
  , id = "id"
  , dv = "FOC.correct"
  , factors=c("transition","Block number")
  , ylim = c(0, 110)
  , intercept = c(.2, .2)
  , xlab = "Transition type"
  , ylab = "Percentage correct"
  , args_legend = list(plot = FALSE)
)


## Practice effect: Within-subjects comparison

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & (Generation[["vR.revealed"]]=="preT"|Generation[["vR.revealed"]]=="postT.recently") & Generation[["PD instruction"]]=="Inclusion" & Generation[["excluded.id"]]==0,]
tmp[["InstrExpl"]] <- droplevels(tmp[["InstrExpl"]])
tmp[["vR.revealed"]] <- droplevels(tmp[["vR.revealed"]])

tmp[["transition"]] <- factor(tmp[["vR.revealed"]], levels=c("preT", "postT.recently"), labels = c("practiced", "non-practiced"))

within <- apa.glm(data = tmp, dv = "FOC.correct", id = "id", within = c("transition"))

apa_barplot(
  data = tmp
  , id = "id"
  , dv = "FOC.correct"
  , factors = c("transition", "Block number")
  , ylim = c(0, 110)
  , intercept = c(.2, .2)
  , ylab = ""
  , xlab = "Transition type"
  , dispersion = wsci
  , args_legend = list(ncol = 2, x = .9, y = 110)
)

par(mfrow = c(1, 1))
```

Inclusion performance for revealed transitions in the *No-Practice* and *Practice* groups was analyzed as a function of practice (practiced vs. non-practiced), as depicted in Figure 14.
Results showed no effect of practice on generation performance, `r between[["InstrExpl"]]`.
Similarly, when we compared inclusion performance for practiced vs. non-practiced transitions in the *Transfer* group, there was no effect of practice, `r within[["transition"]]`.
We conclude that practice did not affect inclusion performance for revealed transitions.

```{r 'exp3_gen_revealed_hyps', fig.cap = "Exclusion performance for revealed transitions. Left: Between-subjects comparison between *No-Practice* and *Practice* groups. Right: Within-subjects comparison in *Transfer* group. Horizontal lines represent chance baseline."}

# library(BayesFactor)

par(mfrow = c(1, 2))

## Practice effect: Between-subjects comparison (both blocks)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.NoOne" &  Generation[["vR.Start.instruiert"]]==1 &                Generation[["vR.revealed"]]!= "postT.before" &                Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula=FOC.correct~id, data=tmp, FUN=mean)
bs.nonpracticed <- apa.t(t.test(x = agg$FOC.correct, mu = .2, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = .2)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.One" &  Generation[["vR.Start.instruiert"]]==1 &                    Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = FOC.correct~id, data = tmp, FUN = mean)
bs.practiced <- apa.t(t.test(x = agg$FOC.correct, mu = .2, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = .2)


## Practice effect: Between-subjects comparison (only first block)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.NoOne" & Generation[["Block.Nr"]]=="first" & Generation[["vR.Start.instruiert"]]==1 & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula=FOC.correct~id, data=tmp, FUN=mean)
bs.nonpracticed1 <- apa.t(t.test(x = agg$FOC.correct, mu = .2, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = .2)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.One" & Generation[["Block.Nr"]]=="first" & Generation[["vR.Start.instruiert"]]==1 & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = FOC.correct~id, data = tmp, FUN = mean)
bs.practiced1 <- apa.t(t.test(x = agg$FOC.correct, mu = .2, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = .2)

tmp <- Generation[Generation[["Trial"]] > 1&Generation[["repetition"]]==0&(Generation[["InstrExpl"]]=="Expl.One"|Generation[["InstrExpl"]]=="Expl.NoOne")&Generation[["vR.Start.instruiert"]]==1&Generation[["PD instruction"]]=="Exclusion"&Generation[["excluded.id"]]==0,]

tmp[["InstrExpl"]]<-droplevels(tmp[["InstrExpl"]])
tmp[["transition"]]<-factor(tmp[["InstrExpl"]],levels=c("Expl.One","Expl.NoOne"),labels = c("practiced","non-practiced"))

between <- apa.glm(data = tmp, dv = "FOC.correct", id = "id", between = c("InstrExpl"))

apa_barplot(
  data = tmp
  , id = "id"
  , dv = "FOC.correct"
  , factors = c("transition", "Block number")
  , ylim = c(0, 100)
  , intercept = c(.2, .2)
  , ylab = "Percentage correct"
  , xlab = "Transition type"
  , args_legend = list(plot = FALSE)
)

## Practice effect: Within-subjects comparison

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["vR.revealed"]]=="preT" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = FOC.correct~id, data = tmp,FUN = mean)
ws.practiced<-apa.t(t.test(x = agg$FOC.correct, mu=.2, alternative="less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = .2)

tmp<-Generation[Generation[["Trial"]]>1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["vR.revealed"]]=="postT.recently" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]
agg <- aggregate(formula = FOC.correct~id, data = tmp,FUN = mean)
ws.nonpracticed<-apa.t(t.test(x = agg$FOC.correct, mu=.2, alternative="less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = .2)

tmp <- Generation[Generation[["Trial"]] > 1&Generation[["repetition"]]==0&Generation[["InstrExpl"]]=="Expl.OneOne"&(Generation[["vR.revealed"]]=="preT"|Generation[["vR.revealed"]]=="postT.recently")&Generation[["PD instruction"]]=="Exclusion"&Generation[["excluded.id"]]==0,]
tmp[["InstrExpl"]] <- droplevels(tmp[["InstrExpl"]])
tmp[["vR.revealed"]] <- droplevels(tmp[["vR.revealed"]])

tmp[["transition"]] <- factor(tmp[["vR.revealed"]], levels=c("preT", "postT.recently"), labels = c("practiced", "non-practiced"))

within <- apa.glm(data = tmp, dv = "FOC.correct", id = "id", within = c("transition"))

apa_barplot(
  data = tmp
  , id = "id"
  , dv = "FOC.correct"
  , factors = c("transition", "Block number")
  , ylim = c(0, 100)
  , intercept = c(.2, .2)
  , xlab = "Transition type"
  , ylab = ""
)

par(mfrow = c(1, 1))
```


```{r}
tmp <- Generation[Generation[["Trial"]]>1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["Block.Nr"]]=="first" & Generation[["vR.revealed"]]=="preT" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = korrekt~id, data = tmp, FUN = mean)
ws.practiced.1 <- apa.t(t.test(x = agg$korrekt, mu = .2, alternative = "less"), nrow(agg))


tmp<-Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["Block.Nr"]]=="first" & Generation[["vR.revealed"]]=="postT.recently" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = korrekt~id, data = tmp, FUN = mean)
ws.nonpracticed.1 <- apa.t(t.test(x = agg$korrekt, mu = .2, alternative = "less"), nrow(agg))

```



#### Exclusion

Next, we analyzed whether practice improves suppressing the regular transition in the exclusion task.
We hypothesized that, without training, participants might not be able to suppress their generation of regular transitions below the chance level in the exclusion task. 
To test this hypothesis, we compared generation performance for the revealed transitions between the *No-Practice* and *Practice* groups, as depicted in the left panel of Figure 15.
The expected below-chance performance was not found in the data from both blocks: 
Whereas the direction of effects was as expected, there was no deviation from chance, neither for the practice condition, `r bs.practiced`, nor for the no-practice condition, `r bs.nonpracticed`.
However, the expected pattern was found when only the first block was analyzed: Below-chance performance was found for the practice condition, `r bs.practiced1`, but not for the no-practice condition, `r bs.nonpracticed1`.

To more directly establish a practice effect, we next turned to the data from the *Transfer* group for a within-subjects comparison of practiced and non-practiced transitions.
In addition, we addressed the transfer hypothesis: 
If specific training is required for each single transition, the finding of at-chance exclusion performance should replicate for non-practiced transitions in participants who practiced another transition.
In contrast, if training on one transition transfers to other transitions, we should find below-chance performance for non-practiced transitions in a parallel within-participants comparison in the *Transfer* group.
As can be seen from the right panel of Figure 15, generation performance was below chance for practiced, `r ws.practiced`, as well as for non-practiced transitions, `r ws.nonpracticed`, indicating transfer of exclusion practice from practiced to non-practiced transitions. 
^[Analyzing only the first block revealed the same pattern of results: Generation performance was below chance for practiced, `r ws.practiced.1`, as well as for non-practiced transitions, `r ws.nonpracticed.1`.]


## Discussion

The experimental manipulations had the expected effects on implicit and explicit sequence knowledge:
Participants in Experiment 3 acquired knowledge about the sequence, as expressed in RT- and accuracy advantages for regular transition that increased over SRTT blocks.
Participants received different amounts of instructed explicit knowledge, and they were able to express this knowledge in the generation task, as revealed by the effect of *PD instruction* on generation of revealed transitions.
However, performance differed across groups (i.e., practice conditions), suggesting that specific exclusion practice was beneficial to implementing PD instructions. 
Finally, even with practice, inclusion performance did not reach ceiling and exclusion performance did not reach floor levels, indicating that participants were not able to exhaustively express their explicit knowledge in the generation task.

The invariance assumption was again found to be violated for both controlled and automatic processes.
Explicit knowledge was expressed to a greater degree in the inclusion than in the exclusion blocks of the generation task.
Generation practice improved the degree to which explicit knowledge was expressed under exclusion instructions, but invariance was violated despite repeated opportunities for practicing to include/exclude a specific transition.

Result showed that practice increased the magnitude of the invariance violation (i.e., the I-E difference).
Importantly, however, this does not imply that our evidence for invariance violation reflect an artifact of practice. 
First, increasing the overall expression of explicit knowledge (as suggested by parameter estimates, as well as the below-chance exclusion performance under practice conditions) is of course precisely the intended effect of practice.
Second, only with practice were participants sometimes able to suppress exclusion performance below chance baselines (as required by the PD model). 
Third, invariance was also violated in the absence of practice.
We conclude that invariance was violated because, overall, participants were not able to refrain from using their explicit knowledge under exclusion conditions (even if practiced).
Perhaps more precisely, participants failed to generate a sufficiently high proportion of irregular transitions under exclusion conditions.

