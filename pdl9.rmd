```{r 'pdl9-prepare'}
# source("R/pdl9.export.raw.data.R")
load("data/pdl9.RData")

Acquisition$error <- 100 * Acquisition$error
Generation$FOC.correct <- 100 * Generation$FOC.correct

excludes <- c()
Acquisition[["excluded.id"]] <- as.integer(Acquisition[["id"]] %in% excludes)
Generation[["excluded.id"]] <- as.integer(Generation[["id"]] %in% excludes)

Generation[["excluded.id"]] <- as.integer(Generation[["id"]] %in% excludes)
## This should be consistent!
# table(Generation$id, Generation$excluded.id)
```

<!-- Experiments 1 and 2 found a violation of the invariance assumption, suggesting that the interpretation of the parametric PD approach may be problematic.  -->
<!-- In particular, the results of Experiments 1 and 2 consistently suggest that the PD parameters may not yield an exhaustive measure of explicit knowledge: -->
<!-- The degree to which participants made use of their explicit knowledge varied between the inclusion and exclusion tasks. -->
<!-- Experiment 3 aimed at obtaining a better understanding of this invariance violation and its effect on the interpretation of generation task performance in the PD framework. -->

<!-- Whereas the invariance violations clearly threaten the validity of the PD model, they may yet turn out to be uncritical for an ordinal interpretation of PD data that has often been used in applications (i.e., a comparison of inclusion versus exclusion performance, and of exclusion versus baseline performance). -->

<!-- Even if the (independence and) invariance assumptions do not hold, the general approach of drawing conclusions about the underlying processes by comparing performance between inclusion and exclusion conditions may not be entirely invalidated: -->
<!-- It has been formally shown that an ordinal interpretation of PD findings does not rely on parametric assumptions [@hirshman_ordinal_2004]. -->
<!-- However, the ordinal PD approach does assume that baseline performance is identical in the inclusion and exclusion tasks -- an assumption that has been shown to be violated at least in some cases [@stahl_distorted_2015]. -->
<!-- More critically for the present question of invariance, it also assumes (not only that inclusion performance increases but also) that exclusion performance monotonically decreases with increasing explicit knowledge. -->
<!-- Note that, if (contrary to this assumption) explicit knowledge does not affect exclusion performance at all, the ordinal PD approach may technically still be used. -->
<!-- However, the results would be misleading if a difference in explicit (but not implicit) knowledge between two conditions led to a difference in inclusion but not in exclusion performance. -->
<!-- In this case, the ordinal PD would suggest that the two conditions differ in explicit *and implicit* knowledge [@hirshman_ordinal_2004, Data Pattern I]. -->
<!-- In other words, for the ordinal PD approach to yield valid results, exclusion performance must fall below baseline when explicit knowledge is present (this would yield Hirshman's Data Pattern IV, which indicates an increase in explicit knowledge). -->
<!-- Therefore, a critical empirical test for the ordinal PD approach is whether, and under which conditions, participants are able to use explicit knowledge to suppress generation below baseline levels under exclusion conditions.  -->


A critical assumption of the ordinal PD is that explicit knowledge monotonically increases inclusion performance *and* monotonically decreases exclusion performance.
If (contrary to this assumption) explicit knowledge does not affect exclusion performance at all, the ordinal PD approach may technically still be applied;
however, the results would be misleading if a difference in explicit (but not implicit) knowledge between two conditions led to a difference in inclusion but not in exclusion performance.
In this case, the ordinal PD would suggest that the two conditions differ in explicit *and implicit* knowledge [@hirshman_ordinal_2004, Data Pattern I].
For the ordinal PD approach to yield valid results, exclusion performance must even fall *below baseline* when explicit knowledge is sufficiently strong so as to counter the influence of implicit knowledge (this would yield Hirshman's Data Pattern IV, which indicates an increase in explicit knowledge).
Therefore, a critical empirical test for the ordinal PD approach is whether (and under which conditions) participants are able to use explicit knowledge to suppress generation below baseline levels under exclusion conditions.
Our primary goal of Experiment 1 was to test this assumption; therefore, while keeping implicit sequence constant at moderate levels across conditions, 
we manipulated *explicit* knowledge by revealing parts of the sequence to participants *after* finishing the SRTT.


A secondary goal of Experiment 1 was to manipulate the amount of *practice* participants had with including and excluding their explicit knowledge.
If participants acquired explicit knowledge about a transition while performing an SRTT, they are likely to encounter the same transition again during the same SRTT several times:
On these additional exposures to the transition, they might be able to practice including the explicit knowledge (e.g. by intentionally implementing it into a motor pattern).
This practice might be helpful in following the instructions of the subsequent PD generation task.
We investigated whether this type of transition-specific practice helps in implementing the PD instructions by comparing practiced with non-practiced transitions.
We also wanted to investigate transfer of practiced to unpracticed transitions about which participants had explicit knowledge.
We therefore manipulated the number of revealed transitions, and whether these revealed transitions were revealed prior to or after practice blocks, both between and within subject.
<!-- A critical precondition for the expression of explicit knowledge may be the opportunity for practice with the generation task.  -->
<!-- In Experiment 3, we investigated whether such transition-specific practice can help reduce the invariance violation by comparing practiced with non-practiced transitions. -->
<!-- We also wanted to more directly investigate transfer of practice to unpracticed transitions about which participants had explicit knowledge. -->
<!-- We therefore manipulated the number of revealed transitions, and whether these revealed transitions were revealed prior to or after practice blocks, both  between and within subjects. -->

## Method

We realized five between-subjects conditions:

1. In the *Control* group, no explicit knowledge was revealed to participants.

<!-- 3. Explicit knowledge without practice (1 transition, non-practiced, *non-practiced*): -->
2. In the *No-Practice* group, 
one transition <!--(third & fourth location of the sequence)--> was revealed immediately before the first generation block,
but *after* the practice blocks that preceded the first generation block. 
To avoid carry-over of practice effects from the first generation block, a different non-practiced transition  <!--(fifth & sixth location of the sequence)--> was revealed after the second practice blocks and immediately preceding the second generation block.

<!-- 5. Explicit knowledge with unspecific inhibition practice (1 transition with *unspecific* practice): -->
3. In the *Unspecific-Practice* group,
one transition was revealed to participants *after* practice, immediately before each generation block (as in the *No-Practice* group).
In the third practice block before the exclusion task, participants were asked to inhibit a specific response location (i.e., they were asked *not* to use the $5^{th}$ location/$N$ key).

<!-- 2. Explicit knowledge with practice (1 transition, practiced, *practiced*): -->
4. In the *Practice* group, 
one transition <!--(first & second location of the sequence)--> was revealed to participants immediately *before* the practice blocks. Participants were encouraged to include (exclude) the revealed transition during practice and in the generation block.

<!-- 4. Explicit knowledge with & without practice (1 transition practiced + 1 transition non-practiced, *practiced & non-practiced*): -->
5. In the *Transfer* group, information about two transitions was revealed; one of them was non-practiced (as in the No-Practice group), the other one practiced (as in the Practice group).
The practiced transition <!--(first & second location of the sequence)--> was revealed before the first practice blocks.
After these practice blocks, the second (non-practiced) transition  <!--(third & fourth location of the sequence)--> was revealed immediately before the first generation block.
The practiced transition was again named before participants worked on the practice blocks of the second generation phase.
After these practice blocks, a second non-practiced transition  <!--(fifth & sixth location of the sequence)--> was revealed immediately before the second generation block.

This allowed us to assess generation performance for different levels of explicit knowledge.
Inclusion performance should increase with increasing explicit knowledge, and exclusion performance should decrease with increasing explicit knowledge.

Moreover, we more specifically addressed the hypothesis that explicit knowledge may not be exhaustively expressed during the generation task (and, in particular, under exclusion instructions), and that the level of its expression may depend on practice.
This design allowed us to assess generation performance for three main transition types; (1) *non-revealed* transitions, (2) transitions that were revealed but remained *non-practiced*, and (3) transitions that were revealed and *practiced* in the practice blocks.
^[In the second generation block of the No-Practice, Unspecific-Practice, and Transfer groups, a fourth transition type can be distinguished: Transitions that were revealed but non-practiced before the first generation block. Because participants included (or excluded) these transitions in the previous (i.e., the first) generation block, performance on these transitions should be more similar to practiced than to non-practiced transitions in the second block.]

A comparison of *non-revealed* with (revealed but) *non-practiced* transitions allows us to assess the degree to which participants can spontaneously make use of their explicit knowledge in the generation task.
Comparing *non-practiced* with *practiced* transitions allowed us to assess whether specific inclusion/exclusion practice could increase the use of explicit knowledge.
We also compared whether performance for revealed but *non-practiced* transitions differs between the No-Practice and Transfer groups, as would be expected if the effect of specific practice transfers to non-practiced explicit knowledge.
Finally, we explored whether unspecific inhibition practice affects performance for both revealed but *non-practiced* and/or *non-revealed* transitions.

In sum, we hypothesized that possessing explicit knowledge may not be sufficient for its expression in the generation task.
Specifically, (a) explicit knowledge without practice (*No-Practice* group) may fail to lead to below-chance exclusion performance, 
and (b) this may also hold for non-practiced transitions for participants who practiced another transition (*Transfer* group).
If the exclusion task is not at all sensitive to explicit knowledge, this would lead to erroneous conclusions if the ordinal PD is applied;
moreover, this would also suggest that the invariance assumption for explicit knowledge of the parametric PD might also be violated.
We had no clear hypothesis regarding the unspecific response-inhibition practice,
but wanted to explore whether it would be as effective as transition-specific exclusion practice in improving the validity of the generation task as a measure of explicit knowledge.


### Design

The study realized a 5 (*Condition*: Control, No-Practice, Unspecific-Practice, Practice, Transfer)
$\times$ 2 (*PD instruction*: inclusion vs. exclusion) $\times$ 2 (*block order*: inclusion first vs. exclusion first) design with repeated measures on the *PD instruction* factor.

### Participants

```{r 'pdl9-participants'}
N <- length(unique(Generation[["id"]]))
n.excludes <- length(excludes)

tmp<-aggregate(formula = RT~id+female+age, data = Generation, FUN = mean)
Sex<-table(tmp[["female"]])

meanAge<-paste0("$M = ", (round(mean(tmp[["age"]]),digits=1)), "$")
rangeAge<-paste(c(min(tmp[["age"]]),max(tmp[["age"]])),collapse=" and ")
```


`r #N` One hundred and forty-seven participants (`r Sex["1"]` women) aged between `r rangeAge` years (`r meanAge` years) completed the study.
Most were undergraduates from Heinrich-Heine-Universität Düsseldorf.
Participants were randomly assigned to experimental conditions.
They received either course credit or 3.50 Euro for their participation.
^[
The present research used procedures that are exempt from mandatory formal
ethical approval under the ethical guidelines of the Deutsche Gesellschaft für Psychologie.
]


<!-- old version -->
<!-- ### Materials and Procedure -->

<!-- During an SRTT consisting of 8 blocks with 144 trials each (for a total of 1,152 responses), participants in all conditions were trained with a  -->
<!-- *probabilistic* sequence similar to the one used in Experiment 1. -->
<!-- After the SRTT, participants were informed about the underlying sequential structure of stimulus locations and asked to generate a short sequence of six key presses that followed this (unspecified) structure. -->

<!-- The generation task followed, with counterbalanced order of inclusion versus exclusion blocks.  -->
<!-- The number of practice blocks was held constant (in contrast to Experiment 1, where it depended on performance). -->
<!-- Upon completing the computerized task, participants answered the same questionnaire as in Experiment 1. -->

### Materials

A *probabilistic* sequence was generated from the first-order conditional sequence $2-6-5-3-4-1$.
With a probability of $.6$, a stimulus location was followed by the next location from this sequence;
otherwise, another stimulus location was randomly chosen from a uniform distribution.
There were no direct repetitions of response locations. 

### Procedure

The experiment consisted of three consecutive parts:
Participants first worked on a SRTT (the *acquisition task*), followed by a *generation task* and, finally, a debriefing phase. 
In the acquisition task, participants performed a SRTT consisting of 8 blocks with 144 trials each (for a total of 1,152 responses).
SRTT and generation task were run on 17" CRT monitors (with a screen resolution of $1{,}024~\text{px} \times 768~\text{px}$).
The viewing distance was approximately 60cm. 
A horizontal sequence of six white squares ($56~\text{px}$) was presented on a gray screen. The distance between squares was $112~\text{px}$.
Each screen location corresponded to a key on a QWERTZ keyboard (from left to right Y, X, C, B, N, M).
Participants had to respond whenever a square's color changed from white to red by pressing the corresponding key. 
They were instructed to place the left ring-, middle- and index fingers on the keys Y, X and C. 
The right index-, middle- and ring fingers were to be placed on keys B, N and M. 
There was no time limit for responses in the learning phase (nor in the generation phase). 
A warning beep indicated an incorrect response. 
The response-stimulus interval (RSI) was $250~\text{ms}$;
there were no pauses within a single learning block.

Following the SRTT phase, participants were told that stimulus locations during the SRTT followed an underlying sequential structure (but were not informed about the exact sequence). 
They were then asked to try to generate a short sequence of six locations that followed this structure.

Before working on practice blocks, one transition was revealed to participants in the *Practice* and *Transfer* groups.
After practice blocks, another transition was revealed to participants in the *No-Practice*, *Unspecific-Practice*, and *Transfer* groups.
Participants were told to memorize those transitions and to use their knowledge in the following tasks.

The generation task contained a counterbalanced order of inclusion versus exclusion blocks.
Under inclusion (exclusion) instructions, participants were told to generate a sequence as similar (dissimilar) as possible to the sequence from the acquisition task.
For both tasks, participants were instructed to follow their intuition if they had no explicit knowledge about the underlying sequence.
Participants who had received information about transitions were instructed to include (exclude) the revealed transitions.

To familiarize participants with both inclusion and exclusion instructions, they worked on short practice blocks of twelve consecutive responses.
Prior to the inclusion task, three practice blocks involved inclusion instructions;
prior to the exclusion task, the first and second practice blocks were performed under inclusion instructions and the third practice block was performed under exclusion instructions.
In the main block of the generation task, participants freely generated 120 consecutive response locations. 
Question marks appeared at all locations and participants' key presses were reflected by the corresponding square's color changing to red.
Direct repetitions were explicitly discouraged and were followed by a warning beep.

Upon completing the computerized task, participants were asked to complete a questionnaire containing the following items (translated from German): 
(1) "One of the tasks mentioned a sequence in which the squares lit up during the first part of the study.
In one of the experimental conditions, the squares did indeed follow a specific sequence. Do you think you were in this condition or not?", 
(2) "How confident are you (in %)?", and (3) "Can you describe the sequence in detail?". 
Subsequently, participants were asked to indicate, for each of the six response keys, the next key in the sequence on a printed keyboard layout and
to indicate how confident they were in this decision. 
Finally, participants were thanked and debriefed.

### Data analysis

All analyses were performed using the R software^[
We used `r cite_r(file = "r-references.bib", withhold = FALSE, pkgs = c("papaja", "afex"))`.
] and Stan [@carpenter_stan:_2016].
For analyses of reaction times during the acquisition task,
we excluded the first trial of each block as well as trials with errors, trials succeeding an error, reactions faster than 50 ms and those slower than 1,000 ms.
For analyses of error rates during the acquisition task, we excluded the first trial of each block.

Generation task analyses were conducted with the first trial of each block as well as any response repetitions excluded.
During the generation task, participants generated 120 keypresses.
We coded these data as 119 first-order conditional transitions (e.g., a 4-key sequence $1{-}2{-}3{-}4$ was coded as the three transitions $1{-}2$, $2{-}3$, and $3{-}4$); we then computed the frequency of transitions that were consistent (i.e., part of) or inconsistent with (i.e., not part of) the training sequence.
This scoring procedure follows the one used in the studies of @destrebecqz_can_2001 and @wilkinson_intentional_2004.
^[This scoring procedure ignores sequential dependencies inherent in the free-generation data.
For instance, the frequency with which a specific location is generated determines how often a transition starting from this location can be generated, and thereby, how well the knowledge available about this transition can be estimated:
To illustrate, if the starting point of a transition is never generated, it is not possible to learn anything about the knowledge participants may have acquired about this transition.
We believe this is not a serious threat to the present analysis because participants generated the locations at comparable rates.
Still, other types of dependencies may yet turn out to be more problematic, and future research should consider modeling entire generation sequences instead of individual transitions.]
<!-- Scoring data from the free generation task in this way might be problematic, as the frequency that a specific location is generated determines how often the transition that holds this location as a starting point can be generated. -->
<!-- To illustrate, consider a participant who holds knowledge about a single regular transition $1{-}2$ and therefore adopts a strategy of repeatedly generating $1{-}2{-}1{-}2...$:  -->
<!-- Given knowledge about only a sixth of the sequence, his performance (scored this way) would suggest knowledge about half of the sequence. -->
<!-- However, this is the canonical way of scoring data from the free-generation task, it is therefore important to use the same scoring procedure in the present study, too. -->
<!-- We thank K.C. Klauer for pointing out in a review of this manuscript that this scoring is negligent to the number of transitions that could have been produced, but were not (i.e., how often the first location of a transition was produced but was *not* followed by the second location of a transition). Moreover, it could also be problematic that two consecute transitions overlap by one response and thus also overlap with regard to the error-term attached to this shared response. -->
Response repetitions were excluded form analyses, as these were explicitly discouraged in the instructions.
We analyzed generation performance using an ordinal-PD approach (Appendix B reports an additional model-based analysis).

<!-- Given that model  $\mathcal{M}_2$  failed to fit the data from both Experiments 1 and 2 and model, we fitted only model $\mathcal{M}_1$ and used posterior analyses to evaluate the invariance assumption. -->
<!-- For the model-based analyses, we adapted the equations from Experiment 1 to the design of Experiment 3 (which did not contain experimental groups with random material). -->

<!-- In order to accommodate for the more complex design, we used a model specification that allowed for participant and item (i.e., transition) effects and their interactions by estimating fixed effects for each transition type plus individual participants' deviations from these effects. -->
<!-- The model equations of model $\mathcal{M}_1$ are given by: -->

<!-- $$ -->
<!--   C_{ijm} = \begin{cases} -->
<!--     \Phi(\mu_{jlm}^{(C)} + \delta_{ijm}^{(C)}) & \text{if } j \epsilon 1, 2 \text{ (item has been revealed \& practiced, revealed \& non-practiced)}\\ -->
<!--                                               0 & \text{if }j=3 \text{ (item has not been revealed)}\\ -->
<!--     \end{cases} -->
<!-- $$ -->
<!-- and -->
<!-- $$ -->
<!--   A_{imt} = \Phi(\mu_{mt}^{(A)} + \delta_{imt}^{(A)}) -->
<!-- $$ -->

<!-- where $\mu_{jlm}^{(C)}$ -->
<!-- is the fixed effect of transition type $j$ (non-revealed, revealed & practiced, revealed & non-practiced) in condition $l$ and *PD instruction* condition $m$ on controlled processes, and -->
<!-- $\delta_{ijm}^{(C)}$ is the $i$th participant's deviation from the corresponding mean. -->
<!-- Accordingly, $\mu_{mt}^{(A)}$ is the fixed effect of *PD instruction* condition $m$ and transition $t$ on automatic processes, and -->
<!-- $\delta_{imt}^{(A)}$ is the $i$th participant's deviation from the corresponding mean. -->

<!-- Model $\mathcal{M}_1$ imposes two auxiliary assumptions: -->
<!-- First, it assumed that no explicit knowledge has been acquired during the SRT phase (i.e., $C=0$ for non-revealed transitions). -->
<!-- Second, it assumed that revealing sequence knowledge did not affect automatic processes (i.e., $A$ does not vary as a function of the between-subjects manipulation of explicit knowledge, index $l$). -->
<!-- Both auxiliary assumptions were tested by posterior predictive checks. -->
<!-- In addition to reporting $T_{A1}$ and $T_{B1}$ as in the previous studies, we calculated additional model check statistics $T_{A2}$, which summarizes how well the model describes the item-wise category counts (aggregated over participants), and $T_{A3}$, which summarizes how well the model describes the category counts per participant-item combination; finally, the additional statistic $T_{B2}$ summarizes how well the model describes the variances and covariances introduced by items. -->
<!-- We also calculated the posterior differences $C_I - C_E$ and $A_I - A_E$ to more directly test the invariance assumption. -->



## Results

We first analyzed the performance data from the SRT task to determine whether sequence knowledge had been acquired during the task.
Next, we analyzed generation task performance using an ordinal PD approach.
Finally, to test our predictions regarding the different effects of practice, we analyzed generation performance for transitions about which explicit knowledge had been revealed.


### Acquisition task

If participants acquired knowledge about the regularity underlying the sequence of key presses, we expect a performance advantage for regular over irregular transitions, reflected in reduced RT and/or error rate.
If this advantage is due to learning, it is expected to increase over SRTT blocks.

#### Reaction times

```{r pdl9-acquisition-rt, fig.width = 4.4, fig.cap="RTs during acquisition phase of Experiment 1, split by *FOC transition status*. Error bars represent 95% within-subjects confidence intervals."}

pdl9_acquisition_rt <- Acquisition[Acquisition[["excluded.id"]]==0 & Acquisition[["Trial.Nr"]] > 1 & Acquisition[["error"]]==0  & Acquisition[["vR.error"]]==0 & Acquisition[["SRI"]]<1000 & Acquisition[["SRI"]]>50,]

apa_lineplot(
  data = pdl9_acquisition_rt
  , id = "id"
  , factors = c("Block number", "FOC transition status")
  , dv = "SRI"
  , ylim = c(460, 560)
  , ylab = "Reaction time [msec]"
  , args_arrows = list(length = .05)
  , dispersion = wsci
)

pdl9_acquisition_rt.anova <- apa.glm(
  data = pdl9_acquisition_rt
  , dv = "SRI"
  , id = "id"
  , within = c("Block number", "FOC transition status")
)

```


Figure \@ref(fig:pdl9-acquisition-rt) shows reaction times during acquisition.
We conducted a `r pdl9_acquisition_rt.anova$name` repeated-measures ANOVA.
There was a main effect of *block number*,
`r pdl9_acquisition_rt.anova[["Block_number"]]`, with RT decreasing over blocks. 
There also was a main effect of *FOC transitions status*,
`r pdl9_acquisition_rt.anova[["FOC_transition_status"]]`,
reflecting faster responses to regular than to irregular transitions.
The interaction of *block* and *FOC transition status* was also significant,
`r pdl9_acquisition_rt.anova[["Block_number_FOC_transition_status"]]`, reflecting the finding that the RT advantage for regular transitions increased over blocks, which indicated successful sequence learning.

#### Error rates

```{r pdl9-acquisition-error, fig.width = 4.4, fig.cap="Error rates during acquisition phase of Experiment 1, split by *FOC transition status*. Error bars represent 95% within-subjects confidence intervals."}

pdl9_acquisition_error <- Acquisition[Acquisition[["Trial"]]>1 & Acquisition[["excluded.id"]]==0, ]

apa_lineplot(
  id = "id"
  , dv = "error"
  , data = pdl9_acquisition_error
  , factors = c("Block number","FOC transition status")
  , dispersion = wsci
  , ylim = c(0, 10)
  , args_arrows = list(length = .05)
  , ylab = "Error rate [%]"
)

pdl9_acquisition_error.anova <- apa.glm(
  data = pdl9_acquisition_error
  , id = "id"
  , dv = "error"
  , within = c("Block number", "FOC transition status")
)
```

Figure \@ref(fig:pdl9-acquisition-error) shows error rates during acquisition.
The pattern of findings was similar to that obtained for RT.
We conducted an `r pdl9_acquisition_error.anova$name` repeated-measures ANOVA that revealed
a main effect of *block number*,
`r pdl9_acquisition_error.anova[["Block_number"]]`,
reflecting increasing error rates over blocks;
and a main effect of *FOC transition status*,
`r pdl9_acquisition_error.anova[["FOC_transition_status"]]`,
reflecting an accuracy advantage (i.e., lower error rates) for regular transitions.
The interaction of *block number* and *FOC transition status* was also significant,
`r pdl9_acquisition_error.anova[["Block_number_FOC_transition_status"]]`,
reflecting an increase of the accuracy advantage for regular (as compared to irregular) transitions over blocks, indicating successful sequence learning.


### Generation task

```{r pdl9-generation, fig.cap = "Generation performance in Experiment 1, excluding repetitions. Error bars represent 95% confidence intervals. Horizontal lines represent chance baseline.", results='hide'}

pdl9_generation <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["excluded.id"]]==0,]

pdl9_generation$Condition <- factor(pdl9_generation$Condition, levels = as.character(c(1, 2, 5, 3, 4)), labels = c(
  "Control"
  , "No-Practice"
  , "Unspecific-Practice"
  , "Practice"
  , "Transfer")
)

# Overall ANOVA
pdl9_generation.anova <- apa.glm(
  data = pdl9_generation
  , dv = "FOC.correct"
  , id = "id"
  , between = c("Condition", "Order")
  , within = c("PD instruction")
)

plot_out <- apa_barplot(
  data = pdl9_generation
  , dv = "FOC.correct"
  , id = "id"
  , factors = c("PD instruction", "Condition")
  , ylim = c(0, 100)
  , ylab = c("Proportion regular [%]", "")
  , intercept = rep(20, 2)
)

saved_colors <- plot_out$args$args_rect$col

# Inclusion performance
agg <- papaja:::fast_aggregate(
  data = pdl9_generation[pdl9_generation$Instruktion=="Inklusion",]
  , dv = "FOC.correct"
  , factors = c("id", "Condition", "Order")
  , fun = mean
)

inclusion <- apa.glm(data = agg, id = "id", dv = "FOC.correct", between = c("Condition", "Order"))

# Exclusion performance 
agg <- papaja:::fast_aggregate(
  data = pdl9_generation[pdl9_generation$Instruktion=="Exklusion",]
  , dv = "FOC.correct"
  , factors = c("id", "Condition", "Order")
  , fun = mean
)

exclusion <- apa.glm(data = agg, id = "id", dv = "FOC.correct", between = c("Condition", "Order"))

# separate t tests
fun.tmp <- function(x) {
  apa.t.test(data = x, within = "Instruktion", dv = "FOC.correct", id = "id")
}

t.out <- lapply(X = split(pdl9_generation, f = pdl9_generation$Condition), FUN = fun.tmp)
```

```{r pdl9-generation-bayesian, eval = FALSE}
# library(BayesFactor)

## Inclusion performance

## with order restriction
full <- lmBF(formula = FOC.correct ~ Condition * Order, data = agg, iterations = 1e6)
null <- lmBF(formula = FOC.correct ~ Order + Condition:Order, data = agg, iterations = 1e6)

posterior_samples <- posterior(full, iter = 1e4)
prior_odds <- 1/5

p_consistent <- mean(posterior_samples[, "Condition-1"]<posterior_samples[, "Condition-2"] &
  posterior_samples[, "Condition-1"]<posterior_samples[, "Condition-3"] &
  posterior_samples[, "Condition-1"]<posterior_samples[, "Condition-4"] &
  posterior_samples[, "Condition-1"]<posterior_samples[, "Condition-5"])

bf_restriction_against_full <- p_consistent / prior_odds
## Convert to a number so that we can multiply it
bf_full_against_null = as.vector(full/null)
## Use transitivity to compute desired Bayes factor
bf_restriction_against_null = bf_restriction_against_full * bf_full_against_null


# Exclusion performance 

excl_b <- anovaBF(formula = FOC.correct ~ Condition * Order, data = agg, whichModels = "top", iterations = 1e5)
condition <- lmBF(formula = FOC.correct ~ Condition, data = agg)
order <- lmBF(formula = FOC.correct ~ Order, data = agg)

nuisance <- lmBF(formula = FOC.correct ~ Order, data = agg)
full <- lmBF(formula = FOC.correct ~ Condition * Order, data = agg, iterations = 2e5)

1/full
1/(full/nuisance)

# five levels, hyp. is that one group is always biggest, so 1/5
prior_odds <- 1/5

full <- lmBF(formula = FOC.correct ~ Condition * Order, data = agg)
null <- lmBF(formula = FOC.correct ~ Order + Condition:Order, data = agg)
# null <- lmBF(formula = FOC.correct ~ Order, data = agg)
#
posterior_samples <- posterior(full, index = 1, iter = 1e4)

p_consistent <- mean(posterior_samples[, "Condition-1"]>posterior_samples[, "Condition-2"] &
  posterior_samples[, "Condition-1"]>posterior_samples[, "Condition-3"] &
  posterior_samples[, "Condition-1"]>posterior_samples[, "Condition-4"] &
  posterior_samples[, "Condition-1"]>posterior_samples[, "Condition-5"])

bf_restriction_against_full <- p_consistent / prior_odds
## Convert to a number so that we can multiply it
bf_full_against_null = as.vector(full/null)
## Use transitivity to compute desired Bayes factor
bf_restriction_against_null = bf_restriction_against_full * bf_full_against_null

1/bf_restriction_against_null

# only first block
# first <- agg[agg$Order=="Exclusion first", ]
# 1/lmBF(formula = FOC.correct ~ Condition, data = first)
#
# # only second block
# second <- agg[agg$Order=="Inclusion first", ]
# 1/lmBF(formula = FOC.correct ~ Condition, data = second)

```

We first analyzed generation performance by applying standard ANOVA techniques to the proportions of regular transitions generated in inclusion and exclusion blocks.
We then analyzed generation performance for those transitions that were revealed to participants, testing our hypotheses about the effects of practice on generation performance.

### Overall generation performance

Figure \@ref(fig:pdl9-generation) shows the overall generation performance.
We conducted a `r pdl9_generation.anova$name` ANOVA that revealed a main effect of *PD instruction*,
`r pdl9_generation.anova$PD_instruction`,
participants generated more regular transitions in inclusion than exclusion blocks;
and a main effect of *Condition*,
`r pdl9_generation.anova$Condition`,
indicating a clear influence of the explicit knowledge manipulation on generation performance.
Moreover, the interaction of *Condition* and *PD instruction* reached significance,
`r pdl9_generation.anova$Condition_PD_instruction`,
indicating that the effect of *Condition* is qualified by *PD instruction*.
The interaction of *PD instruction* and *Block order* also reached significance,
`r pdl9_generation.anova$Order_PD_instruction`.
To disentangle these interactions, we analyzed inclusion and exclusion performance, separately.


#### Inclusion

Analyzing the number of regular transitions generated in inclusion blocks,
a `r inclusion$name` ANOVA revealed a significant main effect of *Condition*,
`r inclusion$Condition`, `r # paste0("$\\mathrm{BF}_{10} = ", printnum(exp(incl_b@bayesFactor[1, 1])), "$")`
indicating that our manipulation of explicit knowledge influenced inclusion performance;
and a main effect of *Block order*,
<!-- Bayesian and frequentist analysis lead to diverging conclusions-->
`r inclusion$Order`:
<!-- `r # paste0("$\\mathrm{BF}_{10} = ", printnum(exp(incl_b@bayesFactor[2, 1])), "$")` -->
participants generated  more regular transitions if inclusion followed exclusion;
the interaction of *Condition* and *Block order* did not reach significance,
`r inclusion$Condition_Order`.
<!-- `r # paste0("$\\mathrm{BF}_{01} = ", printnum(1/exp(incl_b@bayesFactor[3, 1])), "$")`. -->

#### Exclusion

Analyzing the number of regular transitions generated in exclusion blocks,
a `r exclusion$name` ANOVA revealed *no* significant effects on exclusion performance (all $p\mathrm{s} \geq .143$).

<!-- - To test our hypothesis that exclusion performance is not a monotonic function of explicit knowledge,  -->
<!-- we conducted a Bayesian ANOVA: -->
<!-- - BF against main effect of condition `r # paste0("$\\mathrm{BF}_{01} = ", printnum(exp(excl_b@bayesFactor[3, 1])), "$")` -->
<!-- - BF against adding Condition (+ interaction) to nuisance model = 70 -->
<!-- - BF that compares model PD_o that assumes P(regular|Control)>P(regular|Experimental) against baseline model (no main effect of condition): BF_null_pd = 76 -->


```{r 'pdl9-outcome-space', fig.cap = 'Generation performance for revealed transitions, Experiment 1', eval = FALSE}
tmp <- Generation[Generation[["Trial"]]>1 & Generation[["repetition"]]==0,]

tmp2 <- papaja:::fast_aggregate(data = tmp, factors = c("PD instruction", "vR.revealed.12", "id"), dv = "FOC.correct", fun = mean)

par(mfrow=c(1, 2))

plot(x = c(0, 1), y = c(0, 1), type="n", main = "non-practiced, first revealed",xlab="p(regular|Inklusion)",ylab="p(regular|Exklusion)")
text(
  x = tmp2[tmp2[["PD instruction"]]=="Inclusion" & tmp2[["vR.revealed.12"]]=="postT.first", "FOC.correct"]
  , y = tmp2[tmp2[["PD instruction"]]=="Exclusion" & tmp2[["vR.revealed.12"]]=="postT.first", "FOC.correct"]
  , labels = tmp2[tmp2[["PD instruction"]]=="Exclusion" & tmp2[["vR.revealed.12"]]=="postT.first", "id"]
  , cex = .5
)

plot(x = c(0, 1), y = c(0, 1), type="n", main = "practiced",xlab="p(regular|Inklusion)",ylab="p(regular|Exklusion)")
text(
  x = tmp2[tmp2[["PD instruction"]]=="Inclusion" & tmp2[["vR.revealed.12"]]=="preT", "FOC.correct"]
  , y = tmp2[tmp2[["PD instruction"]]=="Exclusion" & tmp2[["vR.revealed.12"]]=="preT", "FOC.correct"]
  , labels = tmp2[tmp2[["PD instruction"]]=="Exclusion" & tmp2[["vR.revealed.12"]]=="preT", "id"]
  , cex = .5
)

```



```{r 'pdl9-generation-block1'}
pdl9_generation_block1 <- Generation[Generation[["Trial"]]> 1 & Generation[["repetition"]]==0 & Generation[["Block.Nr"]]=="first" & Generation[["excluded.id"]]==0,]

pdl9_generation_block1.out <- apa.glm(
  data = pdl9_generation_block1
  , id = "id"
  , dv = "FOC.correct"
  , between = c("Condition","PD instruction")
)

# apa_barplot(
#   data = pdl9_generation_block1
#   , dv = "FOC.correct"
#   , id = "id"
#   , factors = c("Condition", "PD instruction")
#   , ylim = c(0, 1)
#   , ylab = "Proportion regular [%]"
# )

# separate t tests
fun.tmp <- function(x) {
  apa.t.test(data = x, between = "PD instruction", dv = "FOC.correct", id = "id")
}

t.out <- lapply(X = split(pdl9_generation_block1, f = pdl9_generation_block1$Condition), FUN = fun.tmp)
```


### Generation performance for revealed transitions

To test our predictions regarding the different effects of practice, we analyzed raw generation frequencies for only those transitions about which explicit knowledge was revealed.

```{r 'pdl9-generation-revealed', fig.cap = "Generation performance for revealed transitions in Experiment 1. Error bars represent 95% confidence intervals. Horizontal lines represent chance baseline."}

Generation$Condition <- factor(
  Generation$InstrExpl
  , levels = c("Expl.No", "Expl.NoOne", "Expl.PosOne", "Expl.One", "Expl.OneOne")
  , labels = c("Control", "No-Practice", "Unspecific-Practice", "Practice", "Transfer")
)

pdl9_generation_rev <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["excluded.id"]]==0 & Generation[["vR.revealed"]]!="not", ]

pdl9_generation_rev.out <- apa.glm(
  data = pdl9_generation_rev
  , id = "id"
  , dv = "FOC.correct"
  , between = c("Condition", "Order")
  , within = "PD instruction"
)

apa_barplot(
  data = pdl9_generation_rev
  , dv = "FOC.correct"
  , id = "id"
  , factors = c("PD instruction", "Condition")
  , ylim = c(0, 100)
  , ylab = "Proportion regular [%]"
  , intercept = 20
  , col = saved_colors[c("No-Practice", "Unspecific-Practice", "Practice", "Transfer")]
)

## separate t tests
fun.tmp <- function(x) {
  apa.t.test(data = x, within = "Instruktion", dv = "FOC.correct", id = "id")
}

t.out <- lapply(X = split(pdl9_generation_rev, f = pdl9_generation_rev$Condition)[-1], FUN = fun.tmp)



```

Figure \@ref(fig:pdl9-generation-revealed) shows generation performance for revealed transitions.
A `r pdl9_generation_rev.out$name` ANOVA revealed 
a nonsignificant main effect of *Condition*, `r pdl9_generation_rev.out[["Condition"]]`, 
but a significant main effect of *PD instruction*, `r pdl9_generation_rev.out[["PD_instruction"]]`,
and their significant interaction, `r pdl9_generation_rev.out[["Condition_PD_instruction"]]`.
The main effect of *PD instruction* reflects the clear influence of the PD instruction on the expression of explicit knowledge depicted in Figure \@ref(fig:pdl9-generation-revealed).
It is present in all practice conditions but modulated by amount of knowledge and type of practice (i.e., greater effects given specific practice): 
The effect was greatest in the *Transfer* group, `r t.out[["Transfer"]][["stat"]]`;
somewhat smaller in the *Practice* group, `r t.out[["Practice"]][["stat"]]`; 
it was still smaller and comparable in the *No-practice* group, `r t.out[["No-Practice"]][["stat"]]`, and the *Unspecific-practice* group, `r t.out[["Unspecific-Practice"]][["stat"]]`.

We investigated this issue more closely in two sets of follow-up analyses.
Whereas the above findings support the hypothesis that practice improves the degree to which explicit knowledge is expressed in the generation task, it does not elucidate the mechanism by which this occurs. 
One mechanism by which practice may improve performance is by boosting the proportion of regular transitions in inclusion blocks. 

#### Inclusion

```{r 'pdl9-generation-revealed-inclusion', fig.cap = "Inclusion performance for revealed transitions in Experiment 1. Left: Between-subjects comparison between *No-Practice* and *Practice* groups. Right: Within-subjects comparison in *Transfer* group. Horizontal lines represent chance baseline."}

par(mfrow = c(1, 2))

## Practice effect: Between-subjects comparison

tmp<-Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & (Generation[["InstrExpl"]]=="Expl.One"|Generation[["InstrExpl"]]=="Expl.NoOne") & Generation[["vR.Start.instruiert"]]==1 & Generation[["PD instruction"]]=="Inclusion" & Generation[["excluded.id"]]==0,]

tmp<-Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & (Generation[["InstrExpl"]]=="Expl.One"|Generation[["InstrExpl"]]=="Expl.NoOne") & (Generation[["vR.revealed"]]=="postT.recently"| Generation[["vR.revealed"]]=="preT") & Generation[["PD instruction"]]=="Inclusion" & Generation[["excluded.id"]]==0,]


tmp[["InstrExpl"]]<-droplevels(tmp[["InstrExpl"]])
tmp[["transition"]]<-factor(tmp[["InstrExpl"]],levels=c("Expl.One","Expl.NoOne"),labels = c("practiced","non-practiced"))

between <- apa.glm(
  data = tmp
  , dv = "FOC.correct"
  , id = "id"
  , between = "InstrExpl"
)

# apa_barplot(
#   data = tmp
#   , id = "id"
#   , dv = "FOC.correct"
#   , factors=c("transition","Block number")
#   , ylim = c(0, 110)
#   , intercept = rep(20, 2)
#   , xlab = "Transition type"
#   , ylab = "Proportion regular [%]"
#   , args_legend = list(plot = FALSE)
# )


## Practice effect: Within-subjects comparison

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & (Generation[["vR.revealed"]]=="preT"|Generation[["vR.revealed"]]=="postT.recently") & Generation[["PD instruction"]]=="Inclusion" & Generation[["excluded.id"]]==0,]
tmp[["InstrExpl"]] <- droplevels(tmp[["InstrExpl"]])
tmp[["vR.revealed"]] <- droplevels(tmp[["vR.revealed"]])

tmp[["transition"]] <- factor(tmp[["vR.revealed"]], levels=c("preT", "postT.recently"), labels = c("practiced", "non-practiced"))

within <- apa.glm(data = tmp, dv = "FOC.correct", id = "id", within = c("transition"))

# apa.barplot(
#   data = tmp
#   , id = "id"
#   , dv = "FOC.correct"
#   , factors = c("transition", "Block number")
#   , ylim = c(0, 110)
#   , intercept = rep(20, 2)
#   , ylab = ""
#   , xlab = "Transition type"
#   , dispersion = wsci
#   , args_legend = list(ncol = 2, x = .9, y = 110)
# )

```

Inclusion performance for revealed transitions in the *No-Practice* and *Practice* groups was analyzed as a function of practice (practiced vs. non-practiced)<!--, as depicted in Figure \@ref(fig:pdl9-generation-revealed-inclusion)-->.
Results showed no effect of practice on inclusion performance, `r between[["InstrExpl"]]`.
Similarly, when we compared inclusion performance for practiced vs. non-practiced transitions in the *Transfer* group, there was no effect of practice, `r within[["transition"]]`.
We conclude that practice did not affect inclusion performance for revealed transitions.

```{r 'pdl9-generation-revealed-exclusion', fig.cap = "Exclusion performance for revealed transitions in Experiment 1. Left: Between-subjects comparison between *Practice* and *No-Practice* groups. Right: Within-subjects comparison in *Transfer* group. Horizontal lines represent chance baseline."}

# library(BayesFactor)

par(mfrow = c(1, 2))

## Practice effect: Between-subjects comparison (both blocks)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.NoOne" &  Generation[["vR.Start.instruiert"]]==1 &                Generation[["vR.revealed"]]!= "postT.before" &                Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula=FOC.correct~id, data=tmp, FUN=mean)
bs.nonpracticed <- apa.t(t.test(x = agg$FOC.correct, mu = 20, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.One" &  Generation[["vR.Start.instruiert"]]==1 &                    Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = FOC.correct~id, data = tmp, FUN = mean)
bs.practiced <- apa.t(t.test(x = agg$FOC.correct, mu = 20, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)


## Practice effect: Between-subjects comparison (only first block)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.NoOne" & Generation[["Block.Nr"]]=="first" & Generation[["vR.Start.instruiert"]]==1 & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula=FOC.correct~id, data=tmp, FUN=mean)
bs.nonpracticed1 <- apa.t(t.test(x = agg$FOC.correct, mu = 20, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.One" & Generation[["Block.Nr"]]=="first" & Generation[["vR.Start.instruiert"]]==1 & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = FOC.correct~id, data = tmp, FUN = mean)
bs.practiced1 <- apa.t(t.test(x = agg$FOC.correct, mu = 20, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)

tmp <- Generation[Generation[["Trial"]] > 1&Generation[["repetition"]]==0&(Generation[["InstrExpl"]]=="Expl.One"|Generation[["InstrExpl"]]=="Expl.NoOne")&Generation[["vR.Start.instruiert"]]==1&Generation[["PD instruction"]]=="Exclusion"&Generation[["excluded.id"]]==0,]

tmp[["InstrExpl"]]<-droplevels(tmp[["InstrExpl"]])
tmp[["transition"]]<-factor(tmp[["InstrExpl"]],levels=c("Expl.One","Expl.NoOne"),labels = c("practiced","non-practiced"))

between <- apa.glm(data = tmp, dv = "FOC.correct", id = "id", between = c("InstrExpl"))

apa.barplot(
  data = tmp
  , id = "id"
  , dv = "FOC.correct"
  , factors = c("transition", "Block number")
  , ylim = c(0, 100)
  , intercept = rep(20, 2)
  , ylab = "Proportion regular [%]"
  , xlab = "Transition type"
  , args_legend = list(plot = FALSE)
  , main = expression(paste(italic("Practice"), " vs. ", italic("No-Practice"), " groups"))
)

## Practice effect: Within-subjects comparison

tmp <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["vR.revealed"]]=="preT" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = FOC.correct~id, data = tmp,FUN = mean)
ws.practiced<-apa.t(t.test(x = agg$FOC.correct, mu=20, alternative="less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)

tmp<-Generation[Generation[["Trial"]]>1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["vR.revealed"]]=="postT.recently" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]
agg <- aggregate(formula = FOC.correct~id, data = tmp,FUN = mean)
ws.nonpracticed<-apa.t(t.test(x = agg$FOC.correct, mu=20, alternative="less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)

tmp <- Generation[Generation[["Trial"]] > 1&Generation[["repetition"]]==0&Generation[["InstrExpl"]]=="Expl.OneOne"&(Generation[["vR.revealed"]]=="preT"|Generation[["vR.revealed"]]=="postT.recently")&Generation[["PD instruction"]]=="Exclusion"&Generation[["excluded.id"]]==0,]
tmp[["InstrExpl"]] <- droplevels(tmp[["InstrExpl"]])
tmp[["vR.revealed"]] <- droplevels(tmp[["vR.revealed"]])

tmp[["transition"]] <- factor(tmp[["vR.revealed"]], levels=c("preT", "postT.recently"), labels = c("practiced", "non-practiced"))

within <- apa.glm(data = tmp, dv = "FOC.correct", id = "id", within = c("transition"))

apa.barplot(
  data = tmp
  , id = "id"
  , dv = "FOC.correct"
  , factors = c("transition", "Block number")
  , ylim = c(0, 100)
  , intercept = rep(20, 2)
  , xlab = "Transition type"
  , ylab = ""
  , main = expression(paste(italic("Transfer"), " group"))
)

par(mfrow = c(1, 1))
```


```{r 'pdl9-generation-revealed-exusion-2'}
tmp <- Generation[Generation[["Trial"]]>1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["Block.Nr"]]=="first" & Generation[["vR.revealed"]]=="preT" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

library(BayesFactor)

agg <- aggregate(formula = FOC.correct~id, data = tmp, FUN = mean)
ws.practiced.1 <- apa.t(t.test(x = agg$FOC.correct, mu = 20, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)


tmp<-Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["InstrExpl"]]=="Expl.OneOne" & Generation[["Block.Nr"]]=="first" & Generation[["vR.revealed"]]=="postT.recently" & Generation[["PD instruction"]]=="Exclusion" & Generation[["excluded.id"]]==0,]

agg <- aggregate(formula = FOC.correct~id, data = tmp, FUN = mean)
ws.nonpracticed.1 <- apa.t(t.test(x = agg$FOC.correct, mu = 20, alternative = "less"), nrow(agg))
# bf <- ttestBF(x = agg$FOC.correct, mu = 20)



```



#### Exclusion

Next, we analyzed whether practice improves suppressing the regular transition in the exclusion task.
We hypothesized that, without training, participants might not be able to suppress their generation of regular transitions below the chance level in the exclusion task. 
To test this hypothesis, we compared generation performance for the revealed transitions between the *No-Practice* and *Practice* groups<!--, as depicted in the left panel of Figure \@ref(fig:pdl9-generation-revealed-exclusion)-->.
The expected below-chance performance was not found in the data from both blocks: 
Whereas the direction of effects was as expected, there was no deviation from chance, neither for the practice condition, `r bs.practiced`, nor for the no-practice condition, `r bs.nonpracticed`.
However, the expected pattern was found when only the first block was analyzed: Below-chance performance was found for the practice condition, `r bs.practiced1`, but not for the no-practice condition, `r bs.nonpracticed1`.

To more directly establish a practice effect, we next turned to the data from the *Transfer* group for a within-subjects comparison of practiced and non-practiced transitions.
In doing so, we also addressed the transfer hypothesis: 
If specific training is required for each single transition, the finding of at-chance exclusion performance should replicate for non-practiced transitions in participants who practiced another transition.
In contrast, if training on one transition transfers to other transitions, we should find below-chance performance for non-practiced transitions in a parallel within-participants comparison in the *Transfer* group.
<!--As can be seen from the right panel of Figure \@ref(fig:pdl9-generation-revealed-exclusion), -->
Generation performance was below chance for practiced, `r ws.practiced`, as well as for non-practiced transitions, `r ws.nonpracticed`, indicating transfer of exclusion practice from practiced to non-practiced transitions. 
^[Analyzing only the first block revealed the same pattern of results: Generation performance was below chance for practiced, `r ws.practiced.1`, as well as for non-practiced transitions, `r ws.nonpracticed.1`.]


```{pdl9-aggregate-pd, child = "pdl9_aggregate_pd.rmd", eval = FALSE}
```

```{r 'pdl9-generation-nonrevealed', fig.cap = "Proportions of correctly generated non-revealed transitions during PD generation task, excluding repetitions", eval=FALSE}
pdl9_generation_non <- Generation[Generation[["Trial"]] > 1 & Generation[["repetition"]]==0 & Generation[["excluded.id"]]==0 & Generation[["vR.revealed"]]=="not", ]

pdl9_generation_non.out <- apa.glm(
  data = pdl9_generation_non
  , id = "id"
  , dv = "FOC.correct"
  , between = c("Condition", "Order")
  , within = "PD instruction"
)
#knitr::kable(pdl9_generation_non.out$table)

# apa_barplot(data = pdl9_generation_non, dv = "FOC.correct", id = "id", factors = c("InstrExpl", "PD instruction"), ylim = c(0, 1), ylab = "Proportion regular [%]", intercept=20)

# apa_barplot(data = pdl9_generation_non, dv = "FOC.correct", id = "id", factors = c("InstrExpl", "PD instruction", "Block number"), ylim = c(0, 1), ylab = "Proportion regular [%]")

pdl9_generation_non_block1 <- pdl9_generation_non[pdl9_generation_non[["Block number"]]==1, ]
pdl9_generation_non_block1.out <- apa.glm(data = pdl9_generation_non_block1, dv = "FOC.correct", id = "id", between = c("Condition", "PD instruction"))

pdl9_generation_non_block2 <- pdl9_generation_non[pdl9_generation_non[["Block number"]]==2, ]
pdl9_generation_non_block2.out <- apa.glm(data = pdl9_generation_non_block2, dv = "FOC.correct", id = "id", between = c("Condition", "PD instruction"))

pdl9_generation_non_incl <- pdl9_generation_non[pdl9_generation_non[["PD instruction"]]=="Inclusion", ]
pdl9_generation_non_incl.out <- apa.glm(data = pdl9_generation_non_block2, dv = "FOC.correct", id = "id", between = c("Condition", "Order"))

pdl9_generation_non_excl <- pdl9_generation_non[pdl9_generation_non[["PD instruction"]]=="Exclusion", ]
pdl9_generation_non_excl.out <- apa.glm(data = pdl9_generation_non_block2, dv = "FOC.correct", id = "id", between = c("Condition", "Order"))

fit <- aov_ez(data = pdl9_generation_non_block1, dv = "FOC.correct", id = "id", between = c("Condition", "Instruktion"), fun.aggregate = mean)
# pdl9_generation_non_block1.tukey <- apa_print(pairs(lsmeans(fit, specs = "Condition"))) ## papaja bug

```


## Discussion

The experimental manipulations had the expected effects on SRTT performance:
Participants in Experiment 1 acquired knowledge about the sequence, as expressed in RT and accuracy advantages for regular transitions that increased over SRTT blocks.
Participants received different amounts of instructed explicit knowledge, and they were able to express this knowledge in the inclusion task, as revealed by a main effect of *Condition* on inclusion performance.
Conversely, participants were not able to express their knowledge in the exclusion task, as there was no effect of our explicit knowledge manipulation on exclusion performance.
This finding violates the monotonicity assumption.


<!-- This pattern of results indicates that revealing explicit knowledge was sufficient to increase inclusion performace, but was not sufficient to reliably decrease the number of regular transitions in the exclusion tasks. -->
<!-- Our manipulation of explicit knowledge robustly affected inclusion performance in the predicted manner; however, participants did not reach ceiling performance for revealed transitions.  -->


Analyzing exclusion performance of only revealed transitions, 
performance differed across groups (i.e., practice conditions),
suggesting that explicit knowledge was indeed expressed under exclusion instructions,
and that specific exclusion practice was beneficial to implementing these instructions.
However, even with practice, inclusion performance did not reach ceiling and exclusion performance did not reach floor levels,
indicating that participants were not able to exhaustively express their explicit knowledge of these transitions in the generation task.
This pattern of results is also in line with  Wilkinson and Shanks's [-@wilkinson_intentional_2004] speculation that participants adopt perseverative response strategies especially under exclusion instructions; these might be mildly informed by strong explicit knowledge (e.g., in our *transfer* group).

Furthermore, even if (after repeated opportunity to practice) participants were able to refrain from generating some of the revealed transitions, this was not consistently reflected in below-baseline overall generation performance. 
It can thus be concluded that increasing amounts of explicit knowledge do not necessarily lead to fewer regular transitions being generated;
<!-- We conclude that participants were not able to refrain from using their explicit knowledge under exclusion conditions (even if practiced). -->
<!-- Participants failed to generate a sufficiently high proportion of irregular transitions under exclusion conditions. -->
the monotonicity assumption of the ordinal PD is thus violated.
As a consequence,
if the ordinal PD were applied to such data, a change in only explicit knowledge between two conditions would thus be misinterpreted as reflecting changes in both implicit *and* explicit knowledge.

In sum, Experiment 1 showed that, first, increasing amounts of explicit knowledge were not reflected in decreasing levels of exclusion performance,
showing that the monotonicity assumption underlying the ordinal PD approach is violated.
Second, explicit knowledge can nevertheless be used under exclusion instructions to decrease performance to below-baseline levels
(if not exhaustively, and only under specific practice conditions);
thus, we can reject the hypothesis that explicit knowledge does not affect exclusion performance at all.

Third, the usage of explicit knowledge in the generation task was higher under inclusion than exclusion, 
suggesting a violation of invariance (i.e., $C_{I} > C_{E}$).
<!-- Move to next experiment?-->
Experiments 2 and 3 more directly tested this assumption.

<!-- Generation practice improved the degree to which explicit knowledge was expressed under exclusion instructions, -->
<!-- However, performance differed across groups (i.e., practice conditions), suggesting that specific exclusion practice was beneficial to implementing PD instructions.  -->
<!-- Finally, even with practice, inclusion performance did not reach ceiling and exclusion performance did not reach floor levels, indicating that participants were not able to exhaustively express their explicit knowledge in the generation task. -->
<!-- The invariance assumption was again found to be violated for both controlled and automatic processes. -->
<!-- Explicit knowledge was expressed to a greater degree in the inclusion than in the exclusion blocks of the generation task. -->


<!--
invariance was violated despite repeated opportunities for practicing to include/exclude a specific transition.

Result showed that practice increased the magnitude of the invariance violation (i.e., the I-E difference).
Importantly, however, this does not imply that our evidence for invariance violation reflect an artifact of practice. 
First, increasing the overall expression of explicit knowledge is of course precisely the intended effect of practice.
Second, only with practice were participants sometimes able to suppress exclusion performance below chance baselines (as required by the ordinal PD). 
We conclude that participants were not able to refrain from using their explicit knowledge under exclusion conditions (even if practiced).
Perhaps more precisely, participants failed to generate a sufficiently high proportion of irregular transitions under exclusion conditions.
-->
<!-- 1688 words -->