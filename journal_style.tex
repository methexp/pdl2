\documentclass[jou]{apa6}

\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

% Table formatting
\usepackage{longtable, booktabs}
\usepackage{pdflscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\begin{center}\begin{threeparttable}}
%   {\end{threeparttable}\end{center}\end{landscape}}

\newenvironment{lltable}
  {\begin{landscape}\begin{center}\begin{ThreePartTable}}
  {\end{ThreePartTable}\end{center}\end{landscape}}

  \usepackage{ifthen} % Only add declarations when endfloat package is loaded
  \ifthenelse{\equal{\string jou}{\string man}}{%
   \DeclareDelayedFloatFlavor{ThreePartTable}{table} % Make endfloat play with longtable
   % \DeclareDelayedFloatFlavor{ltable}{table} % Make endfloat play with lscape
   \DeclareDelayedFloatFlavor{lltable}{table} % Make endfloat play with lscape & longtable
  }{}%



% The following enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand\getlongtablewidth{%
 \begingroup
  \ifcsname LT@\roman{LT@tables}\endcsname
  \global\longtablewidth=0pt
  \renewcommand\LT@entry[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}%
  \@nameuse{LT@\roman{LT@tables}}%
  \fi
\endgroup}


  \usepackage{graphicx}
  \makeatletter
  \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
  \def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
  \makeatother
  % Scale images if necessary, so that they will not overflow the page
  % margins by default, and it is still possible to overwrite the defaults
  % using explicit options in \includegraphics[width, height, ...]{}
  \setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            pdfauthor={},
            pdftitle={Assumptions of the process-dissociation procedure are violated in implicit sequence learning},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=black,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

\setlength{\parindent}{0pt}
%\setlength{\parskip}{0pt plus 0pt minus 0pt}

\setlength{\emergencystretch}{3em}  % prevent overfull lines


% Manuscript styling
\captionsetup{font=singlespacing,justification=justified}
\usepackage{csquotes}
\usepackage{upgreek}



\usepackage{tikz} % Variable definition to generate author note

% fix for \tightlist problem in pandoc 1.14
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Essential manuscript parts
  \title{Assumptions of the process-dissociation procedure are violated in
implicit sequence learning}

  \shorttitle{Process-dissociation assumptions in sequence learning}


  \author{Marius Barth\textsuperscript{}, Christoph Stahl\textsuperscript{}, \& Hilde Haider\textsuperscript{}}

  % \def\affdep{{"", "", ""}}%
  % \def\affcity{{"", "", ""}}%

  \affiliation{
    \vspace{0.5cm}
          \textsuperscript{} University of Cologne  }

  \authornote{
    Marius Barth, Christoph Stahl, Hilde Haider, Department of Psychology,
    University of Cologne.
    
    CS and HH designed the research; MB, CS, and HH planned the studies; MB
    conducted the studies; MB and CS analyzed the data; MB, CS, and HH wrote
    the paper. We thank Jan Czarnomski, Conni Lebbing, Friederike
    Neugebauer, and Imge Ürer for help with data collection.
    
    This work was funded by Deutsche Forschungsgemeinschaft grant
    STA-1269/1-1 to CS and grant HA-5447/8-1 to HH.
    
    Data, code, and materials necessary to reproduce the analyses reported
    in this article are available at \url{https://github.com/methexp/pdl2}.
    
    Correspondence concerning this article should be addressed to Marius
    Barth, Herbert-Lewin-Str. 2, D-50931 Köln, Germany. E-mail:
    \href{mailto:marius.barth@uni-koeln.de}{\nolinkurl{marius.barth@uni-koeln.de}}
  }

  \note{\emph{(Unpublished manuscript, 2017-08-24)}.}

  \abstract{In implicit sequence learning, a process-dissociation (PD) approach has
been proposed to dissociate implicit and explicit learning processes.
Applied to the popular generation task, participants perform two
different task versions: \emph{inclusion} instructions require
generating the transitions that form the learned sequence;
\emph{exclusion} instructions require generating transitions other than
those of the learned sequence. Whereas accurate performance under
inclusion may be based on either implicit or explicit knowledge,
avoiding to generate learned transitions requires controllable explicit
sequence knowledge. The PD approach yields separate estimates of
explicit and implicit knowledge that are derived from the same task; it
therefore avoids many problems of previous measurement approaches.
However, the PD approach rests on the critical assumption that the
implicit and explicit processes are invariant across inclusion and
exclusion conditions. We tested whether the invariance assumptions holds
for the PD generation task. Across three studies using first-order as
well as second-order regularities, invariance of the controlled process
was found to be violated. In particular, despite extensive amounts of
practice, explicit knowledge was not exhaustively expressed in the
exclusion condition. We discuss the implications of these findings for
the use of process-dissociation in assessing implicit knowledge.}
  \keywords{sequence learning, process-dissociation procedure, invariance assumption \\

    \indent Word count: 15,777
  }





\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\theoremstyle{definition}
\newtheorem{example}{Example}
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}

\maketitle

\setcounter{secnumdepth}{0}



Riding a bicycle is an easy task, but most of us will be hard-pressed to
describe in detail the coordinated movements necessary for pedaling,
keeping direction, and maintaining balance. Capturing this intuition,
theories of human learning commonly distinguish two types of knowledge:
Explicit learning that is accompanied by awareness of its contents, and
implicit learning that operates independently of awareness (Shanks \&
St. John, 1994).

Such implicit learning has been demonstrated using the Serial Reaction
Time Task (SRTT, Nissen \& Bullemer, 1987), which has participants
respond to stimuli presented at four horizontal screen locations by
pressing the key that corresponds to the stimulus location. Unbeknownst
to participants, the stimulus locations follow a regular sequence. With
practice, participants learn to respond faster on trials with regular
stimulus-location transitions than on irregular transitions. Critically,
on a subsequent task, participants are often not able to express
explicit knowledge about the sequential structure (Cohen, Ivry, \&
Keele, 1990; Nissen \& Bullemer, 1987; Willingham, Nissen, \& Bullemer,
1989).

There has been a long-lasting debate whether or not this effect is
evidence for implicit learning, a question entwined with methodological
considerations of how to properly measure and separate the contributions
of supposedly implicit and/or explicit learning systems to this task
(for a recent review, see Timmermans \& Cleeremans, 2015). One of the
most promising methods has been the process-dissociation approach as
applied to the free generation task (Destrebecqz \& Cleeremans, 2001);
yet, its validity rests on a set of previously untested assumptions. The
present study assesses two of the crucial assumptions on which this
method is based.

\subsection{Measuring implicit knowledge in the
SRTT}\label{measuring-implicit-knowledge-in-the-srtt}

In order to conclude that the learning effect in the SRTT (i.e., an RT
advantage for regular transitions) is based on implicit knowledge,
dissociations from subsequent assessments of explicit knowledge are
typically sought. They depend on the assumptions that the explicit task
is as \emph{sensitive} to explicit sequence knowledge as the SRTT (the
absence of an explicit effect may otherwise be due to lower
reliability); and that it is also an \emph{exhaustive and exclusive}
measure of explicit knowledge, such that performance on the explicit
task reflects all explicit but \emph{no} implicit knowledge (Reingold \&
Merikle, 1990; Shanks \& St. John, 1994). Multiple explicit-knowledge
assessment tasks have been proposed, including verbal reports (i.e.,
recall of the sequence), recognition, prediction, and generation tests.
Yet, while dissociations from RT advantages in the SRTT have been
demonstrated in some studies, these tests have also been criticized for
not meeting the above criteria, or the reported dissociations did not
replicate (Shanks \& Perruchet, 2002).

Contrary to the reported dissociations, studies utilizing recognition
tests typically found substantial \emph{associations} of the RT
advantage in the SRTT with explicit knowledge (Perruchet \& Amorim,
1992; Perruchet \& Gallego, 1993; Perruchet, Bigand, \& Benoit-Gonin,
1997). It has been argued that these associations were found because the
subsequently used recognition task might not be exclusive to explicit
but might also be driven by fluency-based processes. To test this
alternative explanation, Buchner and colleagues (Buchner, Erdfelder,
Steffens, \& Martensen, 1997; Buchner, Steffens, \& Rothkegel, 1998)
used the process-dissociation approach to disentangle (explicit)
recollection and (implicit) fluency in the recognition task, finding
that recognition is in fact driven by both processes. Still, Shanks and
Johnstone (1999) argued that fluency-based recognition judgments cannot
be equated with implicit knowledge, leading them to conclude that there
was no conclusive evidence for implicit learning in the SRTT literature.

Given the interpretative problems of the recognition task, Destrebecqz
and Cleeremans (2001) introduced the PD approach to the free-generation
task, a measure that was considered to be the most sensitive to sequence
learning (Perruchet \& Amorim, 1992). Participants were instructed,
after finishing the SRTT, to generate a sequence that is either similar
(in the inclusion condition) or dissimilar (in the exclusion condition)
to that encountered during the SRTT. If participants can generate a
similar sequence under the inclusion instruction, they can be said to
have acquired knowledge about the sequence; yet, this knowledge may
reflect both implicit and explicit knowledge because both may be used to
re-generate the learned sequence. However, only explicit knowledge is
assumed to be under participants' control: When asked to generate a
sequence that is dissimilar to the learned sequence -- that is, to
\emph{exclude} their explicit knowledge -- participants can avoid
generating similar transitions only \emph{if their sequence knowledge is
explicit}. If, instead, their sequence knowledge is implicit, they would
still generate a sequence \emph{similar} to the learned sequence despite
being instructed to do the opposite.

To selectively impair explicit knowledge, Destrebecqz and Cleeremans
(2001) manipulated the (presence versus absence of a) response-stimulus
interval (RSI), speculating that a certain minimal amount of preparation
time would be necessary to acquire explicit knowledge during the SRTT.
In both an RSI and a no-RSI condition, performance in the
free-generation task was above a chance baseline, corroborating previous
findings that the generation task is sensitive to sequence knowledge.
Critically, in the no-RSI condition, performance under inclusion (\(I\))
was similar to performance under exclusion (\(E\)) instructions (i.e.,
\(I=E\)), suggesting that participants had no control over their
sequence knowledge, and that the sequence knowledge in the no-RSI
condition was fully implicit. (In addition, exclusion performance was
above baseline, i.e., \(E > B\), indicating that participants in the
no-RSI condition were not able to withhold generating parts of the
sequence they previously had implicitly learned.) Conversely, in the RSI
condition, a robust inclusion-exclusion performance difference (i.e.,
\(I > E\)) indicated that participants were able to control their
sequence knowledge, suggesting that this knowledge is explicit.

\subsection{Assumptions underlying the PD
approach}\label{assumptions-underlying-the-pd-approach}

These conclusions about the presence versus absence of explicit
knowledge, based on comparisons of inclusion and exclusion performance,
depend on two assumptions: First, explicit knowledge must be assumed to
be fully controllable (otherwise, the lack of an inclusion-exclusion
difference cannot be interpreted as the absence of explicit knowledge
but may instead reflect uncontrollable explicit knowledge). Put
differently, conclusions drawn from the PD approach are limited to
controllable explicit knowledge and do not extend to knowledge that may
be explicit but not controllable (in the sense that it may be used to
affect the similarity of the generated sequence with the learned
sequence). This is unproblematic as long as the PD approach is used to
investigate theories that hold controllability as a central tenet of
explicit knowledge. Second, comparisons between inclusion and exclusion
task performance are only meaningful if both tasks are indeed comparable
measures of sequence knowledge.\footnote{For instance, if inclusion and
  exclusion performance differ in their sensitivity to implicit
  knowledge, this might lead to an artificial \(I>E\) finding suggestive
  of the presence of explicit knowledge.} In other words, the processes
underlying free-generation performance are assumed to be \emph{invariant
to the inclusion versus exclusion instructions}. This assumption is
critical for the validity of the PD approach, but it has so far not been
tested directly.

The PD generation task has been used repeatedly to investigate sequence
learning, but results were typically less clear-cut than those of the
initial studies. First, most studies found \(I>E\), suggesting the
presence of at least some amount of controllable (explicit) knowledge
even under no-RSI conditions (Wilkinson \& Shanks, 2004). The debate
focused on the evidence for residual implicit knowledge under exclusion
instructions: Some studies replicated the \(E > B\) finding of
Destrebecqz and Cleeremans (2001), and concluded that SRTT learning is
driven by implicit knowledge (e.g., Destrebecqz \& Cleeremans, 2003; Q.
Fu, Fu, \& Dienes, 2008; Haider, Eichler, \& Lange, 2011); other studies
found only \(E = B\), a pattern interpreted as evidence that only
explicit knowledge is acquired during the SRTT (e.g., Destrebecqz, 2004;
Norman, Price, \& Duff, 2006; Shanks, Rowland, \& Ranger, 2005;
Wilkinson \& Shanks, 2004). Wilkinson and Shanks (2004) failed to
replicate the \(E > B\) finding and speculated that this may come about
because participants attempt to refrain from generating regular
sequences under exclusion by resorting to various perseverative response
strategies (i.e., by repeatedly generating regular-looking runs such as
\(1{-}2{-}3{-}4\)). If participants indeed use different strategies
under the inclusion and exclusion instructions, this may violate the
invariance assumption.

Moreover, in the presence of explicit knowledge, conclusions about the
presence or absence of implicit knowledge, based on comparing exclusion
performance with a baseline (i.e., \(E>B\) vs. \(E=B\)), depend on
additional assumptions regarding the interplay between both types of
knowledge. If both types of knowledge may be involved, additional
assumptions must be met if one aims at comparing inclusion and exclusion
performance across two experimental conditions in order to draw
conclusions about the relative contributions of explicit and implicit of
knowledge; the \emph{ordinal} PD approach formulates such a set of
assumptions (Hirshman, 2004). Further assumptions are required for a
\emph{parametric} PD measurement model that can provide quantitative
estimates of the underlying latent cognitive processes, for instance if
the relative magnitude of the effect of a manipulation on explicit
versus implicit knowledge is the quantity of interest. We next discuss
critical assumptions underlying these two candidate methodological
frameworks for the PD paradigm.

\subsubsection{Ordinal PD approach}\label{ordinal-pd-approach}

Analyzing their data by comparing inclusion and exclusion performance
with a baseline, Destrebecqz and Cleeremans (2001) adopted an analysis
strategy that has been later formalized --- with modifications --- by
Hirshman (2004) as the \emph{ordinal-PD} approach. Instead of providing
quantitative estimates of implicit and explicit knowledge, the
ordinal-PD approach identified specific patterns of results that allow
for ordinal comparisons between two experimental conditions (i.e.,
conclusions about increasing or decreasing amounts of explicit and/or
implicit knowledge). In the light of the then-ongoing controversy about
the PD method, this has been critically acclaimed as a way around the
strong assumptions underlying the original (parametric) PD (Curran,
2001).

However, even this approach is based on assumptions that might be
violated in a specific application. First, it is assumed that baseline
performance is the same under both inclusion and exclusion instructions
-- an assumption that may be violated in sequence learning (Stahl,
Barth, \& Haider, 2015).

Perhaps more critically, the second basic assumption of the ordinal-PD
approach holds that both inclusion and exclusion performance are a
monotonically increasing function of implicit knowledge; and that
inclusion performance monotonically increases but \emph{exclusion
performance monotonically decreases as a function of explicit
knowledge}. The exclusion strategies suggested by Wilkinson and Shanks
(2004) would, however, imply that explicit knowledge does not
necessarily inform exclusion performance: If participants adopted a
perseverative response strategy (instead of engaging in an effortful
search for their explicit knowledge, and attempting to implement this
knowledge into a motor pattern consistent with the exclusion
instructions), they would still be able to suppress their exclusion
performance to baseline; however, they would not be able to suppress
their exclusion performance \emph{below} baseline (i.e.
\(E < B\)).\footnote{Moreover, if response strategies are informed by
  fragmentary knowledge about the regularity, such fragmentary knowledge
  might influence exclusion performance in any direction, depending on
  whether or not the chosen strategy is consistent with what the
  researcher considers to be successful exclusion. This effect might
  even outweigh performance changes due to the available explicit
  knowledge.} The present Experiment 1 provides a first empirical test
of this basic assumption of the ordinal-PD approach as applied to the
free-generation task.\footnote{Even though Destrebecqz and Cleeremans
  (2001) deviated from the ordinal PD as put forward by Hirshman (2004),
  their conclusions still rest on the assumptions of the ordinal PD
  specified here. Moreover, in order to interpret \(I-E\) differences,
  they implicitly assume that the \emph{same} strictly monotonic
  function links automatic and controlled processes with both inclusion
  and exclusion (whereas Hirshman allowed inclusion and exclusion
  performance to be linked by different functions). This additional
  assumption remains untested, yet.}

\subsubsection{The parametric PD model}\label{the-parametric-pd-model}

The parametric PD model provides quantitative estimates of the
underlying processes but relies on stronger assumptions. This section
introduces the parametric PD model and its assumptions and then
discusses its relation to the ordinal PD.

The PD model can be formalized as a set of equations describing
inclusion (\(I\)) and exclusion (\(E\)) performance as a function of the
probabilities of controlled process, \(C\), reflecting explicit
knowledge, and the automatic process, \(A\), reflecting implicit
knowledge, as follows: \[I=C+(1-C)*A\] and \[E=(1-C)*A\] These equations
reflect the notions that (1) regular transitions generated under
inclusion can arise from either the controlled process (with probability
\(C\)) or, given that it fails (with probability \(1-C\)), from the
automatic process \(A\); and (2) regular transitions generated under
exclusion are solely due to the automatic process in the absence of the
influence of the controlled process, \((1-C)*A\). Solving these
equations for \(C\) and \(A\) (or using parameter estimation techniques
for multinomial models) yields estimates of the contributions of the
controlled and automatic process.

The validity of the PD method and model has been the target of debate
since its introduction by Jacoby (1991; see, e.g., Buchner, Erdfelder,
and Vaterrodt-Plünnecke, 1995; Curran \& Hintzman, 1995; Graf \&
Komatsu, 1994). This is because the PD approach is not a theory-free
measurement tool but rests on a set of strong and possibly problematic
assumptions. First and obviously, it assumes the existence of two
qualitatively different---controlled and automatic---processes, and it
aims to measure the magnitude of their respective contributions. It is,
however, not well-suited for comparing single- and dual-process models:
To illustrate, Ratcliff, Van Zandt, and McKoon (1995) found that data
generated from a single-process model could produce a data pattern that,
when analyzed using the PD approach, appears to support the existence --
and differential contributions -- of two qualitatively distinct
processes. This implies that empirical dissociations between the
controlled and automatic estimates do not necessarily imply the
existence of two qualitatively different underlying processes.

Second, it is assumed that both processes operate independently; that
is, on each trial, both the explicit and the implicit process attempt to
produce a candidate response in parallel, without influencing each
other.\footnote{As an alternative to independence, a redundancy relation
  has been proposed such that the implicit process always operates,
  whereas the explicit process operates only in a subset of cases
  (Joordens \& Merikle, 1993). An empirical comparison of the
  independence and redundancy assumptions has, however, supported
  independence (Joordens, Wilson, Spalek, \& Paré, 2010).} In
particular, the response proposed by the automatic process is assumed to
be uninfluenced by whether the controlled process proposes the same or a
different candidate response. Relatedly, the model assumes that
independence holds across persons and items; when data are aggregated
over (potentially heterogeneous) participants and items, a violation can
lead to biases in parameter estimates. There has been considerable
debate about the independence assumption in applications of the PD to
episodic memory paradigms (Curran \& Hintzman, 1995, 1997; Hintzman \&
Curran, 1997; Jacoby \& Shrout, 1997). Evidence suggests that
aggregation independence may often be violated; hierarchical extension
of the PD model have been proposed to address this problem (Rouder, Lu,
Morey, Sun, \& Speckman, 2008).

Third, and most important for the present study, it is assumed that both
the controlled and automatic processes are \emph{invariant} across the
inclusion and exclusion instructions. This is reflected in the PD
equations by the use of a single parameter \(C\) instead of separate
parameters for inclusion and exclusion; in other words, the PD equations
represent a simplified model that incorporates the invariance assumption
\(C = C_{\textit{Inclusion}}=C_{\textit{Exclusion}}\). Similarly, the PD
equations include only a single parameter \(A\), reflecting the
simplifying assumption that the automatic process is invariant across
inclusion and exclusion, \(A = A_{Inclusion} = A_{Exclusion}\). If the
PD instruction affects those cognitive processes, the PD equations do no
longer yield valid estimates. Recently, the invariance assumption was
indeed found to be violated for the controlled process across three
different paradigms (Klauer, Dittrich, Scholtes, \& Voss,
2015).\footnote{This assumption has not been tested earlier because the
  PD equations represent a saturated model: With two data points (i.e.,
  the proportion of correct responses under inclusion and exclusion
  conditions), only two parameters (i.e., \(C\) and \(A\)) can be
  estimated. An extension of the design is needed to allow for
  estimating separate parameters \(C_{Inclusion}\) and
  \(C_{Exclusion}\), and/or \(A_{Inclusion}\) and \(A_{Exclusion}\).}

To summarize, Wilkinson and Shanks (2004) speculated that participants
might use perseverative response strategies \emph{especially in the
exclusion condition} of the PD generation task; as a consequence,
explicit knowledge would be less likely to affect exclusion performance.
In terms of the parametric PD model, this would translate into an
invariance violation of the controlled process with \(C_I > C_E\). If
the probability of controlled processes in exclusion \(C_E\) is
negligible small, or if the invariance violation increases with
increasing explicit knowledge, it cannot be assumed that explicit
knowledge reliably decreases with explicit knowledge; thus, in terms of
the ordinal-PD approach, an invariance violation of this kind would
translate into a violation of the monotonicity assumption. In contrast,
if neither is the case (e.g., if the invariance violation remains
constant across different levels of explicit knowledge), the
monotonicity assumption may hold despite an invariance violation. It is
therefore important to test both the monotonicity and the invariance
assumptions.

\subsection{Overview of the present
studies}\label{overview-of-the-present-studies}

The present study aimed at testing, in the free generation task, the
assumptions underlying both the ordinal- and the parametric-PD methods.
For this purpose, it was necessary to extend the traditional PD design
by manipulating both explicit knowledge (in Experiments 1-3) and
implicit knowledge (in Experiments 2 \& 3).

We manipulated \emph{explicit} knowledge by explicitly informing
participants, after the SRTT training phase, about a subset of the
regular transitions (e.g., 1 out of 6) of the sequence. By presenting
information about the transitions \emph{after training} we ensured that
the manipulation did not affect the amount of sequence knowledge
acquired during training (i.e., we made sure that participants did not
use that information during the SRTT to strategically search for more
regular transitions). We manipulated \emph{implicit} knowledge by
varying the amount of regularity present in the SRTT training sequence.
For this purpose, we used materials with a mere probabilistic
regularity; such materials are typically assumed to produce robust
implicit knowledge but no explicit knowledge (Jiménez \& Méndez, 1999;
Jiménez, Méndez, \& Cleeremans, 1996).

Experiment 1 tested the speculation that explicit knowledge remains
underutilized in exclusion, and its relevance for the monotonicity
assumption (we found that the monotonicity assumption is violated,
suggesting that this is because invariance of the controlled process is
violated).

In Experiments 2 and 3, we directly tested the invariance assumptions of
the parametric PD model, closely following the methodology used by
Klauer et al. (2015): We fit an extended process-dissociation model
\(\mathcal{M}_1\) that allowed for testing the invariance assumption of
both the controlled and the automatic process. The model provided us
with separate estimates for these processes for both inclusion and
exclusion tasks; and we used the differences between these estimates to
test the invariance assumption. This model relies on the auxiliary
assumptions that each experimental manipulation selectively influenced
only one of both processes; these assumptions are tested by
goodness-of-fit tests proposed by Klauer (2010). Moreover, in order to
justify the auxiliary assumptions, we specified a standard
process-dissociation model \(\mathcal{M}_2\) that does not enforce the
auxiliary assumptions but enforces the invariance assumption; model
comparison techniques (DIC; Spiegelhalter, Best, Carlin, \& Van Der
Linde, 2002) were then used to compare model \(\mathcal{M}_1\) and model
\(\mathcal{M}_2\). If model \(\mathcal{M}_1\) is favored over model
\(\mathcal{M}_2\), this can be taken as evidence in favor of our
auxiliary assumptions over the invariance assumption. Finally, instead
of aggregating data, we used hierarchical Bayesian extensions of all
models (cf., Klauer, 2010; Rouder \& Lu, 2005; Rouder et al.,
2008).\footnote{This modeling approach controls for interindividual
  differences.}

\section{Experiment 1}\label{experiment-1}

A critical assumption of the ordinal PD is that explicit knowledge
monotonically increases inclusion performance \emph{and} monotonically
decreases exclusion performance. If (contrary to this assumption)
explicit knowledge does not affect exclusion performance at all, the
ordinal PD approach may technically still be applied; however, the
results would be misleading if a difference in explicit (but not
implicit) knowledge between two conditions led to a difference in
inclusion but not in exclusion performance. In this case, the ordinal PD
would suggest that the two conditions differ in explicit \emph{and
implicit} knowledge (Hirshman, 2004, Data Pattern I). For the ordinal PD
approach to yield valid results, exclusion performance must even fall
\emph{below baseline} when explicit knowledge is sufficiently strong so
as to counter the influence of implicit knowledge (this would yield
Hirshman's Data Pattern IV, which indicates an increase in explicit
knowledge). Therefore, a critical empirical test for the ordinal PD
approach is whether (and under which conditions) participants are able
to use explicit knowledge to suppress generation below baseline levels
under exclusion conditions. Our primary goal of Experiment 1 was to test
this assumption; therefore, while keeping implicit sequence constant at
moderate levels across conditions, we manipulated \emph{explicit}
knowledge by revealing parts of the sequence to participants
\emph{after} finishing the SRTT.

A secondary goal of Experiment 1 was to manipulate the amount of
\emph{practice} participants had with including and excluding their
explicit knowledge. If participants acquired explicit knowledge about a
transition while performing an SRTT, they are likely to encounter the
same transition again during the same SRTT several times: On these
additional exposures to the transition, they might be able to practice
including the explicit knowledge (e.g.~by intentionally implementing it
into a motor pattern). This practice might be helpful in following the
instructions of the subsequent PD generation task. We investigated
whether this type of transition-specific practice helps in implementing
the PD instructions by comparing practiced with non-practiced
transitions. We also wanted to investigate transfer of practiced to
unpracticed transitions about which participants had explicit knowledge.
We therefore manipulated the number of revealed transitions, and whether
these revealed transitions were revealed prior to or after practice
blocks, both between and within subject.

\subsection{Method}\label{method}

We realized five between-subjects conditions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In the \emph{Control} group, no explicit knowledge was revealed to
  participants.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In the \emph{No-Practice} group, one transition was revealed
  immediately before the first generation block, but \emph{after} the
  practice blocks that preceded the first generation block. To avoid
  carry-over of practice effects from the first generation block, a
  different non-practiced transition was revealed after the second
  practice blocks and immediately preceding the second generation block.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  In the \emph{Unspecific-Practice} group, one transition was revealed
  to participants \emph{after} practice, immediately before each
  generation block (as in the \emph{No-Practice} group). In the third
  practice block before the exclusion task, participants were asked to
  inhibit a specific response location (i.e., they were asked \emph{not}
  to use the \(5^{th}\) location/\(N\) key).
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  In the \emph{Practice} group, one transition was revealed to
  participants immediately \emph{before} the practice blocks.
  Participants were encouraged to include (exclude) the revealed
  transition during practice and in the generation block.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  In the \emph{Transfer} group, information about two transitions was
  revealed; one of them was non-practiced (as in the No-Practice group),
  the other one practiced (as in the Practice group). The practiced
  transition was revealed before the first practice blocks. After these
  practice blocks, the second (non-practiced) transition was revealed
  immediately before the first generation block. The practiced
  transition was again named before participants worked on the practice
  blocks of the second generation phase. After these practice blocks, a
  second non-practiced transition was revealed immediately before the
  second generation block.
\end{enumerate}

This allowed us to assess generation performance for different levels of
explicit knowledge. Inclusion performance should increase with
increasing explicit knowledge, and exclusion performance should decrease
with increasing explicit knowledge.

Moreover, we more specifically addressed the hypothesis that explicit
knowledge may not be exhaustively expressed during the generation task
(and, in particular, under exclusion instructions), and that the level
of its expression may depend on practice. This design allowed us to
assess generation performance for three main transition types; (1)
\emph{non-revealed} transitions, (2) transitions that were revealed but
remained \emph{non-practiced}, and (3) transitions that were revealed
and \emph{practiced} in the practice blocks.\footnote{In the second
  generation block of the No-Practice, Unspecific-Practice, and Transfer
  groups, a fourth transition type can be distinguished: Transitions
  that were revealed but non-practiced before the first generation
  block. Because participants included (or excluded) these transitions
  in the previous (i.e., the first) generation block, performance on
  these transitions should be more similar to practiced than to
  non-practiced transitions in the second block.}

A comparison of \emph{non-revealed} with (revealed but)
\emph{non-practiced} transitions allows us to assess the degree to which
participants can spontaneously make use of their explicit knowledge in
the generation task. Comparing \emph{non-practiced} with
\emph{practiced} transitions allowed us to assess whether specific
inclusion/exclusion practice could increase the use of explicit
knowledge. We also compared whether performance for revealed but
\emph{non-practiced} transitions differs between the No-Practice and
Transfer groups, as would be expected if the effect of specific practice
transfers to non-practiced explicit knowledge. Finally, we explored
whether unspecific inhibition practice affects performance for both
revealed but \emph{non-practiced} and/or \emph{non-revealed}
transitions.

In sum, we hypothesized that possessing explicit knowledge may not be
sufficient for its expression in the generation task. Specifically, (a)
explicit knowledge without practice (\emph{No-Practice} group) may fail
to lead to below-chance exclusion performance, and (b) this may also
hold for non-practiced transitions for participants who practiced
another transition (\emph{Transfer} group). If the exclusion task is not
at all sensitive to explicit knowledge, this would lead to erroneous
conclusions if the ordinal PD is applied; moreover, this would also
suggest that the invariance assumption for explicit knowledge of the
parametric PD might also be violated. We had no clear hypothesis
regarding the unspecific response-inhibition practice, but wanted to
explore whether it would be as effective as transition-specific
exclusion practice in improving the validity of the generation task as a
measure of explicit knowledge.

\subsubsection{Design}\label{design}

The study realized a 5 (\emph{Condition}: Control, No-Practice,
Unspecific-Practice, Practice, Transfer) \(\times\) 2 (\emph{PD
instruction}: inclusion vs.~exclusion) \(\times\) 2 (\emph{block order}:
inclusion first vs.~exclusion first) design with repeated measures on
the \emph{PD instruction} factor.

\subsubsection{Participants}\label{participants}

One hundred and forty-seven participants (113 women) aged between 17 and
55 years (\(M = 23.7\) years) completed the study. Most were
undergraduates from Heinrich-Heine-Universität Düsseldorf. Participants
were randomly assigned to experimental conditions. They received either
course credit or 3.50 Euro for their participation.\footnote{The present
  research used procedures that are exempt from mandatory formal ethical
  approval under the ethical guidelines of the Deutsche Gesellschaft für
  Psychologie.}

\subsubsection{Materials}\label{materials}

A \emph{probabilistic} sequence was generated from the first-order
conditional sequence \(2-6-5-3-4-1\). With a probability of \(.6\), a
stimulus location was followed by the next location from this sequence;
otherwise, another stimulus location was randomly chosen from a uniform
distribution. There were no direct repetitions of response locations.

\subsubsection{Procedure}\label{procedure}

The experiment consisted of three consecutive parts: Participants first
worked on a SRTT (the \emph{acquisition task}), followed by a
\emph{generation task} and, finally, a debriefing phase. In the
acquisition task, participants performed a SRTT consisting of 8 blocks
with 144 trials each (for a total of 1,152 responses). SRTT and
generation task were run on 17" CRT monitors (with a screen resolution
of \(1{,}024~\text{px} \times 768~\text{px}\)). The viewing distance was
approximately 60cm. A horizontal sequence of six white squares
(\(56~\text{px}\)) was presented on a gray screen. The distance between
squares was \(112~\text{px}\). Each screen location corresponded to a
key on a QWERTZ keyboard (from left to right Y, X, C, B, N, M).
Participants had to respond whenever a square's color changed from white
to red by pressing the corresponding key. They were instructed to place
the left ring-, middle- and index fingers on the keys Y, X and C. The
right index-, middle- and ring fingers were to be placed on keys B, N
and M. There was no time limit for responses in the learning phase (nor
in the generation phase). A warning beep indicated an incorrect
response. The response-stimulus interval (RSI) was \(250~\text{ms}\);
there were no pauses within a single learning block.

Following the SRTT phase, participants were told that stimulus locations
during the SRTT followed an underlying sequential structure (but were
not informed about the exact sequence). They were then asked to try to
generate a short sequence of six locations that followed this structure.

Before working on practice blocks, one transition was revealed to
participants in the \emph{Practice} and \emph{Transfer} groups. After
practice blocks, another transition was revealed to participants in the
\emph{No-Practice}, \emph{Unspecific-Practice}, and \emph{Transfer}
groups. Participants were told to memorize those transitions and to use
their knowledge in the following tasks.

The generation task contained a counterbalanced order of inclusion
versus exclusion blocks. Under inclusion (exclusion) instructions,
participants were told to generate a sequence as similar (dissimilar) as
possible to the sequence from the acquisition task. For both tasks,
participants were instructed to follow their intuition if they had no
explicit knowledge about the underlying sequence. Participants who had
received information about transitions were instructed to include
(exclude) the revealed transitions.

To familiarize participants with both inclusion and exclusion
instructions, they worked on short practice blocks of twelve consecutive
responses. Prior to the inclusion task, three practice blocks involved
inclusion instructions; prior to the exclusion task, the first and
second practice blocks were performed under inclusion instructions and
the third practice block was performed under exclusion instructions. In
the main block of the generation task, participants freely generated 120
consecutive response locations. Question marks appeared at all locations
and participants' key presses were reflected by the corresponding
square's color changing to red. Direct repetitions were explicitly
discouraged and were followed by a warning beep.

Upon completing the computerized task, participants were asked to
complete a questionnaire containing the following items (translated from
German): (1) \enquote{One of the tasks mentioned a sequence in which the
squares lit up during the first part of the study. In one of the
experimental conditions, the squares did indeed follow a specific
sequence. Do you think you were in this condition or not?}, (2)
\enquote{How confident are you (in \%)?}, and (3) \enquote{Can you
describe the sequence in detail?}. Subsequently, participants were asked
to indicate, for each of the six response keys, the next key in the
sequence on a printed keyboard layout and to indicate how confident they
were in this decision. Finally, participants were thanked and debriefed.

\subsubsection{Data analysis}\label{data-analysis}

All analyses were performed using the R software\footnote{We used R
  (3.4.1, R Core Team, 2017) and the R-packages \emph{afex} (0.18.0,
  Singmann, Bolker, Westfall, \& Aust, 2017), and \emph{papaja}
  (0.1.0.9492, Aust \& Barth, 2017).} and Stan (Carpenter et al., 2016).
For analyses of reaction times during the acquisition task, we excluded
the first trial of each block as well as trials with errors, trials
succeeding an error, reactions faster than 50 ms and those slower than
1,000 ms. For analyses of error rates during the acquisition task, we
excluded the first trial of each block.

Generation task analyses were conducted with the first trial of each
block as well as any response repetitions excluded. During the
generation task, participants generated 120 keypresses. We coded these
data as 119 first-order conditional transitions (e.g., a 4-key sequence
\(1{-}2{-}3{-}4\) was coded as the three transitions \(1{-}2\),
\(2{-}3\), and \(3{-}4\)); we then computed the frequency of transitions
that were consistent (i.e., part of) or inconsistent with (i.e., not
part of) the training sequence. This scoring procedure follows the one
used in the studies of Destrebecqz and Cleeremans (2001) and Wilkinson
and Shanks (2004).\footnote{This scoring procedure ignores sequential
  dependencies inherent in the free-generation data. For instance, the
  frequency with which a specific location is generated determines how
  often a transition starting from this location can be generated, and
  thereby, how well the knowledge available about this transition can be
  estimated: To illustrate, if the starting point of a transition is
  never generated, it is not possible to learn anything about the
  knowledge participants may have acquired about this transition. We
  believe this is not a serious threat to the present analysis because
  participants generated the locations at comparable rates. Still, other
  types of dependencies may yet turn out to be more problematic, and
  future research should consider modeling entire generation sequences
  instead of individual transitions.} Response repetitions were excluded
form analyses, as these were explicitly discouraged in the instructions.
We analyzed generation performance using an ordinal-PD approach
(Appendix B reports an additional model-based analysis).

\subsection{Results}\label{results}

We first analyzed the performance data from the SRT task to determine
whether sequence knowledge had been acquired during the task. Next, we
analyzed generation task performance using an ordinal PD approach.
Finally, to test our predictions regarding the different effects of
practice, we analyzed generation performance for transitions about which
explicit knowledge had been revealed.

\subsubsection{Acquisition task}\label{acquisition-task}

If participants acquired knowledge about the regularity underlying the
sequence of key presses, we expect a performance advantage for regular
over irregular transitions, reflected in reduced RT and/or error rate.
If this advantage is due to learning, it is expected to increase over
SRTT blocks.

\paragraph{Reaction times}\label{reaction-times}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl9-acquisition-rt-1.pdf}
\caption{\label{fig:pdl9-acquisition-rt}RTs during acquisition phase of
Experiment 1, split by \emph{FOC transition status}. Error bars
represent 95\% within-subjects confidence intervals.}
\end{figure}

Figure \ref{fig:pdl9-acquisition-rt} shows reaction times during
acquisition. We conducted a 8 (\emph{Block number}) \(\times\) 2
(\emph{FOC transition status}: regular vs.~irregular) repeated-measures
ANOVA. There was a main effect of \emph{block number},
\(F(4.05, 591.75) = 80.42\), \(\mathrm{MSE} = 1,658.05\), \(p < .001\),
\(\eta^2_G = .048\), with RT decreasing over blocks. There also was a
main effect of \emph{FOC transitions status}, \(F(1, 146) = 716.67\),
\(\mathrm{MSE} = 982.05\), \(p < .001\), \(\eta^2_G = .062\), reflecting
faster responses to regular than to irregular transitions. The
interaction of \emph{block} and \emph{FOC transition status} was also
significant, \(F(6.39, 933.34) = 45.89\), \(\mathrm{MSE} = 257.06\),
\(p < .001\), \(\eta^2_G = .007\), reflecting the finding that the RT
advantage for regular transitions increased over blocks, which indicated
successful sequence learning.

\paragraph{Error rates}\label{error-rates}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl9-acquisition-error-1.pdf}
\caption{\label{fig:pdl9-acquisition-error}Error rates during acquisition
phase of Experiment 1, split by \emph{FOC transition status}. Error bars
represent 95\% within-subjects confidence intervals.}
\end{figure}

Figure \ref{fig:pdl9-acquisition-error} shows error rates during
acquisition. The pattern of findings was similar to that obtained for
RT. We conducted an 8 (\emph{Block number}) \(\times\) 2 (\emph{FOC
transition status}: regular vs.~irregular) repeated-measures ANOVA that
revealed a main effect of \emph{block number},
\(F(6.29, 917.65) = 8.35\), \(\mathrm{MSE} = 9.42\), \(p < .001\),
\(\eta^2_G = .015\), reflecting increasing error rates over blocks; and
a main effect of \emph{FOC transition status}, \(F(1, 146) = 188.88\),
\(\mathrm{MSE} = 11.92\), \(p < .001\), \(\eta^2_G = .066\), reflecting
an accuracy advantage (i.e., lower error rates) for regular transitions.
The interaction of \emph{block number} and \emph{FOC transition status}
was also significant, \(F(6.53, 953.88) = 7.36\),
\(\mathrm{MSE} = 7.09\), \(p < .001\), \(\eta^2_G = .011\), reflecting
an increase of the accuracy advantage for regular (as compared to
irregular) transitions over blocks, indicating successful sequence
learning.

\subsubsection{Generation task}\label{generation-task}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl9-generation-1.pdf}
\caption{\label{fig:pdl9-generation}Generation performance in Experiment 1,
excluding repetitions. Error bars represent 95\% confidence intervals.
Horizontal lines represent chance baseline.}
\end{figure}

We first analyzed generation performance by applying standard ANOVA
techniques to the proportions of regular transitions generated in
inclusion and exclusion blocks. We then analyzed generation performance
for those transitions that were revealed to participants, testing our
hypotheses about the effects of practice on generation performance.

\subsubsection{Overall generation
performance}\label{overall-generation-performance}

Figure \ref{fig:pdl9-generation} shows the overall generation
performance. We conducted a 5 (\emph{Condition}: Control vs.~No-Practice
vs.~Unspecific-Practice vs.~Practice vs.~Transfer) \(\times\) 2
(\emph{Order}: Inclusion first vs.~Exclusion first) \(\times\) 2
(\emph{PD instruction}: Inclusion vs.~Exclusion) ANOVA that revealed a
main effect of \emph{PD instruction}, \(F(1, 137) = 64.03\),
\(\mathrm{MSE} = 176.93\), \(p < .001\), \(\eta^2_G = .199\),
participants generated more regular transitions in inclusion than
exclusion blocks; and a main effect of \emph{Condition},
\(F(4, 137) = 13.81\), \(\mathrm{MSE} = 155.01\), \(p < .001\),
\(\eta^2_G = .158\), indicating a clear influence of the explicit
knowledge manipulation on generation performance. Moreover, the
interaction of \emph{Condition} and \emph{PD instruction} reached
significance, \(F(4, 137) = 9.63\), \(\mathrm{MSE} = 176.93\),
\(p < .001\), \(\eta^2_G = .130\), indicating that the effect of
\emph{Condition} is qualified by \emph{PD instruction}. The interaction
of \emph{PD instruction} and \emph{Block order} also reached
significance, \(F(1, 137) = 10.89\), \(\mathrm{MSE} = 176.93\),
\(p = .001\), \(\eta^2_G = .041\). To disentangle these interactions, we
analyzed inclusion and exclusion performance, separately.

\paragraph{Inclusion}\label{inclusion}

Analyzing the number of regular transitions generated in inclusion
blocks, a 5 (\emph{Condition}: Control vs.~No-Practice
vs.~Unspecific-Practice vs.~Practice vs.~Transfer) \(\times\) 2
(\emph{Order}: Inclusion first vs.~Exclusion first) ANOVA revealed a
significant main effect of \emph{Condition}, \(F(4, 137) = 17.74\),
\(\mathrm{MSE} = 211.85\), \(p < .001\), \(\eta^2_G = .341\), indicating
that our manipulation of explicit knowledge influenced inclusion
performance; and a main effect of \emph{Block order},
\(F(1, 137) = 9.95\), \(\mathrm{MSE} = 211.85\), \(p = .002\),
\(\eta^2_G = .068\): participants generated more regular transitions if
inclusion followed exclusion; the interaction of \emph{Condition} and
\emph{Block order} did not reach significance, \(F(4, 137) = 0.52\),
\(\mathrm{MSE} = 211.85\), \(p = .723\), \(\eta^2_G = .015\).

\paragraph{Exclusion}\label{exclusion}

Analyzing the number of regular transitions generated in exclusion
blocks, a 5 (\emph{Condition}: Control vs.~No-Practice
vs.~Unspecific-Practice vs.~Practice vs.~Transfer) \(\times\) 2
(\emph{Order}: Inclusion first vs.~Exclusion first) ANOVA revealed
\emph{no} significant effects on exclusion performance (all
\(p\mathrm{s} \geq .143\)).

\subsubsection{Generation performance for revealed
transitions}\label{generation-performance-for-revealed-transitions}

To test our predictions regarding the different effects of practice, we
analyzed raw generation frequencies for only those transitions about
which explicit knowledge was revealed.

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl9-generation-revealed-1.pdf}
\caption{\label{fig:pdl9-generation-revealed}Generation performance for
revealed transitions in Experiment 1. Error bars represent 95\%
confidence intervals. Horizontal lines represent chance baseline.}
\end{figure}

Figure \ref{fig:pdl9-generation-revealed} shows generation performance
for revealed transitions. A 5 (\emph{Condition}: Control vs.~No-Practice
vs.~Unspecific-Practice vs.~Practice vs.~Transfer) \(\times\) 2
(\emph{Order}: Inclusion first vs.~Exclusion first) \(\times\) 2
(\emph{PD instruction}: Inclusion vs.~Exclusion) ANOVA revealed a
nonsignificant main effect of \emph{Condition}, \(F(3, 110) = 2.00\),
\(\mathrm{MSE} = 660.29\), \(p = .119\), \(\eta^2_G = .028\), but a
significant main effect of \emph{PD instruction},
\(F(1, 110) = 243.88\), \(\mathrm{MSE} = 575.67\), \(p < .001\),
\(\eta^2_G = .508\), and their significant interaction,
\(F(3, 110) = 5.59\), \(\mathrm{MSE} = 575.67\), \(p = .001\),
\(\eta^2_G = .066\). The main effect of \emph{PD instruction} reflects
the clear influence of the PD instruction on the expression of explicit
knowledge depicted in Figure \ref{fig:pdl9-generation-revealed}. It is
present in all practice conditions but modulated by amount of knowledge
and type of practice (i.e., greater effects given specific practice):
The effect was greatest in the \emph{Transfer} group,
\(t(29) = -14.84\), \(p < .001\), \(d = -2.71\); somewhat smaller in the
\emph{Practice} group, \(t(28) = -9.79\), \(p < .001\), \(d = -1.82\);
it was still smaller and comparable in the \emph{No-practice} group,
\(t(28) = -5.25\), \(p < .001\), \(d = -0.97\), and the
\emph{Unspecific-practice} group, \(t(29) = -5.13\), \(p < .001\),
\(d = -0.94\).

We investigated this issue more closely in two sets of follow-up
analyses. Whereas the above findings support the hypothesis that
practice improves the degree to which explicit knowledge is expressed in
the generation task, it does not elucidate the mechanism by which this
occurs. One mechanism by which practice may improve performance is by
boosting the proportion of regular transitions in inclusion blocks.

\paragraph{Inclusion}\label{inclusion-1}

Inclusion performance for revealed transitions in the \emph{No-Practice}
and \emph{Practice} groups was analyzed as a function of practice
(practiced vs.~non-practiced). Results showed no effect of practice on
inclusion performance, \(F(1, 56) = 0.21\), \(\mathrm{MSE} = 696.48\),
\(p = .652\), \(\eta^2_G = .004\). Similarly, when we compared inclusion
performance for practiced vs.~non-practiced transitions in the
\emph{Transfer} group, there was no effect of practice,
\(F(1, 29) = 1.19\), \(\mathrm{MSE} = 365.77\), \(p = .285\),
\(\eta^2_G = .014\). We conclude that practice did not affect inclusion
performance for revealed transitions.

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl9-generation-revealed-exclusion-1.pdf}
\caption{\label{fig:pdl9-generation-revealed-exclusion}Exclusion performance
for revealed transitions in Experiment 1. Left: Between-subjects
comparison between \emph{Practice} and \emph{No-Practice} groups. Right:
Within-subjects comparison in \emph{Transfer} group. Horizontal lines
represent chance baseline.}
\end{figure}

\paragraph{Exclusion}\label{exclusion-1}

Next, we analyzed whether practice improves suppressing the regular
transition in the exclusion task. We hypothesized that, without
training, participants might not be able to suppress their generation of
regular transitions below the chance level in the exclusion task. To
test this hypothesis, we compared generation performance for the
revealed transitions between the \emph{No-Practice} and \emph{Practice}
groups. The expected below-chance performance was not found in the data
from both blocks: Whereas the direction of effects was as expected,
there was no deviation from chance, neither for the practice condition,
\(t(28) = -0.79\), \(p = .219\), \(d = -0.15\), nor for the no-practice
condition, \(t(28) = 1.60\), \(p = .940\), \(d = 0.30\). However, the
expected pattern was found when only the first block was analyzed:
Below-chance performance was found for the practice condition,
\(t(14) = -4.89\), \(p < .001\), \(d = -1.26\), but not for the
no-practice condition, \(t(13) = 0.18\), \(p = .569\), \(d = 0.05\).

To more directly establish a practice effect, we next turned to the data
from the \emph{Transfer} group for a within-subjects comparison of
practiced and non-practiced transitions. In doing so, we also addressed
the transfer hypothesis: If specific training is required for each
single transition, the finding of at-chance exclusion performance should
replicate for non-practiced transitions in participants who practiced
another transition. In contrast, if training on one transition transfers
to other transitions, we should find below-chance performance for
non-practiced transitions in a parallel within-participants comparison
in the \emph{Transfer} group. Generation performance was below chance
for practiced, \(t(29) = -9.60\), \(p < .001\), \(d = -1.75\), as well
as for non-practiced transitions, \(t(29) = -2.04\), \(p = .025\),
\(d = -0.37\), indicating transfer of exclusion practice from practiced
to non-practiced transitions.\footnote{Analyzing only the first block
  revealed the same pattern of results: Generation performance was below
  chance for practiced, \(t(14) = -5.42\), \(p < .001\), \(d = -1.40\),
  as well as for non-practiced transitions, \(t(14) = -4.56\),
  \(p < .001\), \(d = -1.18\).}

\subsection{Discussion}\label{discussion}

The experimental manipulations had the expected effects on SRTT
performance: Participants in Experiment 1 acquired knowledge about the
sequence, as expressed in RT and accuracy advantages for regular
transitions that increased over SRTT blocks. Participants received
different amounts of instructed explicit knowledge, and they were able
to express this knowledge in the inclusion task, as revealed by a main
effect of \emph{Condition} on inclusion performance. Conversely,
participants were not able to express their knowledge in the exclusion
task, as there was no effect of our explicit knowledge manipulation on
exclusion performance. This finding violates the monotonicity
assumption.

Analyzing exclusion performance of only revealed transitions,
performance differed across groups (i.e., practice conditions),
suggesting that explicit knowledge was indeed expressed under exclusion
instructions, and that specific exclusion practice was beneficial to
implementing these instructions. However, even with practice, inclusion
performance did not reach ceiling and exclusion performance did not
reach floor levels, indicating that participants were not able to
exhaustively express their explicit knowledge of these transitions in
the generation task. This pattern of results is also in line with
Wilkinson and Shanks's (2004) speculation that participants adopt
perseverative response strategies especially under exclusion
instructions; these might be mildly informed by strong explicit
knowledge (e.g., in our \emph{transfer} group).

Furthermore, even if (after repeated opportunity to practice)
participants were able to refrain from generating some of the revealed
transitions, this was not consistently reflected in below-baseline
overall generation performance. It can thus be concluded that increasing
amounts of explicit knowledge do not necessarily lead to fewer regular
transitions being generated; the monotonicity assumption of the ordinal
PD is thus violated. As a consequence, if the ordinal PD were applied to
such data, a change in only explicit knowledge between two conditions
would thus be misinterpreted as reflecting changes in both implicit
\emph{and} explicit knowledge.

In sum, Experiment 1 showed that, first, increasing amounts of explicit
knowledge were not reflected in decreasing levels of exclusion
performance, showing that the monotonicity assumption underlying the
ordinal PD approach is violated. Second, explicit knowledge can
nevertheless be used under exclusion instructions to decrease
performance to below-baseline levels (if not exhaustively, and only
under specific practice conditions); thus, we can reject the hypothesis
that explicit knowledge does not affect exclusion performance at all.

Third, the usage of explicit knowledge in the generation task was higher
under inclusion than exclusion, suggesting a violation of invariance
(i.e., \(C_{I} > C_{E}\)). Experiments 2 and 3 more directly tested this
assumption.

\section{Experiment 2}\label{experiment-2}

Experiment 2 applied the parametric PD model and tested the invariance
assumption for automatic and controlled processes using materials with
first-order conditional regularities. We implemented two different
levels of implicit knowledge by presenting either random or
probabilistic sequences to participants during the SRTT. Orthogonally,
we implemented two different levels of explicit knowledge by
experimentally inducing such knowledge: After the SRTT, we informed one
half of participants about one of the six transitions in the regular
sequence.

\subsection{Method}\label{method-1}

\subsubsection{Design}\label{design-1}

The study realized a 2 (\emph{material}: random vs.~probabilistic)
\(\times\) 2 (\emph{explicit knowledge}: no transition revealed vs.~one
transition revealed) \(\times\) 2 (\emph{PD instruction}: inclusion
vs.~exclusion) \(\times\) 2 (\emph{block order}: inclusion first
vs.~exclusion first) design with repeated measures on the \emph{PD
instruction} factor.

\subsubsection{Participants}\label{participants-1}

One hundred and twenty-one participants (87 women) aged between 17 and
51 years (\(M = 23.7\) years) completed the study. Most were
undergraduates from University of Cologne. Participants were randomly
assigned to experimental conditions. They received either course credit
or 3.50 Euro for their participation.

\subsubsection{Materials}\label{materials-1}

We used two different types of material:

\begin{itemize}
\tightlist
\item
  A \emph{random} sequence was randomly generated for each participant
  anew by drawing with replacement from a uniform distribution of six
  response locations. 
\item
  A \emph{probabilistic} sequence was generated similar to the sequence
  in Experiment 1.
\end{itemize}

In both materials there were no direct repetitions of response
locations. In the random group, there was no \enquote{regular} sequence,
and transition frequencies varied across persons. To compute the
dependent variable in the generation task (i.e., the proportion of
rule-adhering or regular transitions), we used the generating sequence
for participants who worked on \emph{probabilistic} material; for
participants who worked on \emph{random} material, we determined an
individual criterion for each participant. In order to calculate the
individual criteria, we first generated all possible sequences that
follow the constraints that they are 6-item-sequences that do not
contain repetitions and contain all six response locations. Then, for
each participant, we calculated how many of the transitions that were
presented during the acquisition phase followed each of those 120
non-redundant 6-item-sequences. We then chose, for each participant
anew, the sequence that most frequently adhered to the transitions
presented during acquisition phase and took this 6-item-sequence to
calculate the dependent variable during the generation phase. Given
probabilistic materials, this scoring leads to the same results as using
the generating sequence as a criterion. For the group that was
instructed about a regular transition, the \emph{criterion sequence}
always contained the revealed transition.

\subsubsection{Procedure}\label{procedure-1}

During an SRTT consisting of 8 blocks with 144 trials each (for a total
of 1,152 responses), participants were trained on either random or
probabilistic sequences. After the SRTT, participants were informed
about the underlying sequential structure of stimulus locations and
asked to generate a short sequence of six key presses that followed this
(unspecified) structure.

The generation task followed, with counterbalanced order of inclusion
versus exclusion blocks. Prior to the inclusion task, two practice
blocks involved inclusion instructions; prior to the exclusion task, the
first practice block was performed under inclusion instructions and the
second practice block was performed under exclusion instructions. If
participants who were explicitly informed about one transition failed to
include (exclude) the revealed transition in practice blocks, they were
informed that they did something wrong; the already revealed transition
was again presented and two additional practice blocks had to be
performed. This procedure was repeated until the revealed transition was
successfully included (excluded) in two consecutive practice blocks (in
contrast to Experiment 1, where the number of practice blocks was held
constant). Upon completing the computerized task, participants answered
the same questionnaire as in Experiment 1.

\subsubsection{Data analysis}\label{data-analysis-1}

For analyses of reaction times during the acquisition task, we excluded
the first trial of each block as well as trials with errors, trials
succeeding an error, reactions faster than 50 ms and those slower than
1,000 ms. For analyses of error rates during the acquisition task, we
excluded the first trial of each block.

Generation task analyses were conducted with the first trial of a block
as well as any response repetitions excluded (descriptive statistics are
reported in Appendix C). For the model-based analyses, we used
hierarchical Bayesian extensions of the process-dissociation model
(Klauer, 2010; Rouder \& Lu, 2005; Rouder et al., 2008). We estimated
model \(\mathcal{M}_1\) that extended the traditional
process-dissociation model by allowing for a violation of the invariance
assumption: Controlled and automatic processes were allowed to vary as a
function of instruction (inclusion vs.~exclusion). The first-level
equations of this model were given by:

\[
\begin{aligned}
  I_{ij} & =  C_{ijm} + (1-C_{ijm}) A_{ijm},& m = 1\\
  E_{ij} & =  (1-C_{ijm}) A_{ijm},& m = 2
\end{aligned}
\] where \(i\) indexes participants, \(j\) indexes transition type
(i.e., revealed: \(j = 1\); nonrevealed: \(j = 2\)), and \(m\) indexes
the \emph{PD instruction} condition (inclusion: \(m=1\); exclusion:
\(m=2\)).

Parameters \(C_{ijm}\) and \(A_{ijm}\) are probabilities in the range
between zero and one; following previous work (e.g. Albert \& Chib,
1993; Klauer et al., 2015; Rouder et al., 2008), we used a probit
function to link these probabilities to the second-level parameters as
follows:

\[
  C_{ijm} = \begin{cases}
    \Phi(\mu_{km}^{(C)} + \delta_{im}^{(C)}) & \text{if } j=1 \text{ (item has been revealed)}\\
                                            0 & \text{if } j=2 \text{ (item has not been revealed)}\\
    \end{cases}
\] and \[
  A_{ijm} = \Phi(\mu_{jkm}^{(A)} + \delta_{ijm}^{(A)})
\]

where \(\Phi\) denotes the standard normal cumulative distribution
function, \(\mu_{km}^{(C)}\) is the fixed effect of material \(k\) (that
participant \(i\) worked on during the SRTT) and \emph{PD instruction}
condition \(m\) on controlled processes. \(\delta_{im}^{(C)}\) is the
\(i\)th participant's deviation from his or her group's mean.

Accordingly, \(\mu_{jkm}^{(A)}\) is the fixed effect of transition type
\(j\), material \(k\), and \emph{PD instruction} condition \(m\) on
automatic processes, and \(\delta_{ijm}^{(A)}\) is the \(i\)th
participant's deviation from the corresponding mean. Priors on
parameters are given in the Appendix B.

This specification imposes two auxiliary assumptions to the model:
First, it is assumed that controlled processes \(C\) are set to zero for
nonrevealed transitions (i.e., \(C=0\) for \(j=2\)), in other words, we
assumed that no explicit knowledge has been acquired during the SRT
phase. Second, it is assumed that automatic processes \(A\) do not vary
as a function of the between-subjects manipulation of explicit knowledge
\(l\) (i.e., \(\mu^{(A)}_{l=1} = \mu^{(A)}_{l=2}\)). These assumptions
allowed us to relax and test the invariance assumption by obtaining
separate estimates of both \(C\) and \(A\) for the inclusion and
exclusion conditions (note that a \emph{full} model relaxing all three
assumptions cannot be estimated).

To assess goodness of fit, we used posterior predictive model checks as
proposed by Klauer (2010): Statistic \(T_{A1}\) summarizes how well the
model describes the individual category counts for the eight categories
(revealed vs.~nonrevealed \(\times\) regular vs.~nonregular \(\times\)
inclusion vs.~exclusion). Statistic \(T_{B1}\) summarizes how well the
model describes the covariations in the data across participants.

Additionally, we also estimated a model \(\mathcal{M}_2\) that does not
impose the auxiliary assumptions but enforces the invariance assumptions
(i.e., parameters were not allowed to vary as a function of PD
instruction condition \(m\)):

\[
\begin{aligned}
  I_{ij} & =  C_{ij} + (1-C_{ij}) A_{ij}\\
  E_{ij} & =  (1-C_{ij}) A_{ij}
\end{aligned}
\]

The second-level equations of model \(\mathcal{M}_2\) are then given by:

\[
  C_{ij} = \Phi(\mu_{jkl}^{(C)} + \delta_{ij}^{(C)})
\] and \[
  A_{ij} = \Phi(\mu_{jkl}^{(A)} + \delta_{ij}^{(A)})
\]

where \(i\) indexes participants, \(j\) indexes transition type, \(k\)
indexes the learning material that participant \(i\) worked on during
the SRTT, and \(l\) indexes the manipulation of explicit knowledge
(i.e., whether or not a transition has been revealed to participant
\(i\)). Note that, given this model specification, separate parameters
are estimated for each between-subjects condition \(kl\) and each
transition type \(j\), while the invariance assumption is maintained
(i.e., there is no index \(m\) for \emph{PD instruction} in the model
equations).

These two models were compared using the deviance information criterion
DIC (Spiegelhalter et al., 2002; Spiegelhalter, Best, Carlin, \& van der
Linde, 2014); the DIC is an extension of AIC for Bayesian hierarchical
models, and differences of 10 are considered to imply \emph{strong}
evidence in favor of the model with the lower DIC value (Klauer et al.,
2015). Therefore, if model \(\mathcal{M}_1\) outperforms model
\(\mathcal{M}_2\), it can be concluded that the auxiliary assumptions
are less problematic than the invariance assumptions.

Furthermore, model \(\mathcal{M}_1\) yields separate estimates of
controlled and automatic processes for both inclusion and exclusion. The
invariance assumption can be targeted directly by calculating the
posterior differences \(A_{I} - A_{E}\) and \(C_{I} - C_{E}\): If the
posterior distributions of these differences include zero, it can be
concluded that the respective invariance assumption holds; if the
posterior does not contain zero, it can be concluded that the respective
invariance assumption is violated.

\subsection{Results}\label{results-1}

We first analyzed the performance data from the SRT task to determine
whether sequence knowledge had been acquired during the task. Next, we
analyzed generation task performance using hierarchical PD models.

\subsubsection{Acquisition task}\label{acquisition-task-1}

If participants acquired knowledge about the (probabilistic) regularity
underlying the sequence of key presses, we expect a performance
advantage for regular over irregular transitions, reflected in reduced
RT and/or error rate. If this advantage is due to learning, it is
expected to increase over SRTT blocks.

\paragraph{Reaction times}\label{reaction-times-1}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl7-acquisition-rt-1.pdf}
\caption{\label{fig:pdl7-acquisition-rt}RTs during acquisition phase of
Experiment 2, split by \emph{material} and \emph{FOC transition status}.
Error bars represent 95\% within-subjects confidence intervals.}
\end{figure}

Figure \ref{fig:pdl7-acquisition-rt} shows reaction times during the
SRTT. We conducted a 2 (\emph{Material}: Random vs.~Probabilistic)
\(\times\) 8 (\emph{Block number}) \(\times\) 2 (\emph{FOC transition
status}: regular vs.~irregular) ANOVA that revealed a main effect of
\emph{material}, \(F(1, 119) = 8.11\), \(\mathrm{MSE} = 39,617.25\),
\(p = .005\), \(\eta^2_G = .055\); a main effect of \emph{block number}
\(F(4.89, 582.06) = 33.35\), \(\mathrm{MSE} = 1,032.91\), \(p < .001\),
\(\eta^2_G = .029\); a main effect of \emph{FOC transition status},
\(F(1, 119) = 125.46\), \(\mathrm{MSE} = 714.88\), \(p < .001\),
\(\eta^2_G = .016\); an interaction of \emph{material} and \emph{FOC
transition status}, \(F(1, 119) = 121.57\), \(\mathrm{MSE} = 714.88\),
\(p < .001\), \(\eta^2_G = .015\); an interaction of \emph{block number}
and \emph{FOC transition status}, \(F(6.32, 752.52) = 10.68\),
\(\mathrm{MSE} = 197.96\), \(p < .001\), \(\eta^2_G = .002\); and a
three-way interaction between \emph{material}, \emph{block number}, and
\emph{FOC transition status}, \(F(6.32, 752.52) = 5.70\),
\(\mathrm{MSE} = 197.96\), \(p < .001\), \(\eta^2_G = .001\).

Separate ANOVAs for each \emph{material} condition yielded, for random
material, only a significant main effect of \emph{block number},
\(F(4.38, 258.47) = 13.09\), \(\mathrm{MSE} = 1,276.78\), \(p < .001\),
\(\eta^2_G = .026\), with RTs decreasing over blocks (all other
\emph{F}s \textless{} 1). For probabilistic material, in contrast, we
obtained main effects of \emph{block number},
\(F(5.07, 304.28) = 22.09\), \(\mathrm{MSE} = 891.30\), \(p < .001\),
\(\eta^2_G = .035\); and of \emph{transition status},
\(F(1, 60) = 182.32\), \(\mathrm{MSE} = 976.60\), \(p < .001\),
\(\eta^2_G = .061\) (i.e.~responses to regular transitions were faster
than those for irregular transitions); importantly, we also obtained an
interaction of \emph{block number} and \emph{transition status},
\(F(5.93, 356.02) = 15.83\), \(\mathrm{MSE} = 194.03\), \(p < .001\),
\(\eta^2_G = .007\), showing that the RT difference between regular and
irregular transitions increased over blocks, indicating learning of the
regularities inherent in the probabilistic material.

\paragraph{Error rates}\label{error-rates-1}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl7-acquisition-error-1.pdf}
\caption{\label{fig:pdl7-acquisition-error}Error rates during acquisition
phase of Experiment 2, split by \emph{material} and \emph{FOC transition
status}. Error bars represent 95\% within-subjects confidence
intervals.}
\end{figure}

Figure \ref{fig:pdl7-acquisition-error} shows error rates during
acquisition. We conducted a 2 (\emph{Material}: Random
vs.~Probabilistic) \(\times\) 8 (\emph{Block number}) \(\times\) 2
(\emph{FOC transition status}: regular vs.~irregular) ANOVA that
revealed a main effect of \emph{block number},
\(F(5.83, 693.83) = 6.06\), \(\mathrm{MSE} = 11.83\), \(p < .001\),
\(\eta^2_G = .016\), indicating that error rates increased over blocks,
and a main effect of \emph{FOC transition status},
\(F(1, 119) = 38.19\), \(\mathrm{MSE} = 13.49\), \(p < .001\),
\(\eta^2_G = .019\), indicating that error rates were higher for
nonregular transitions. The interaction of \emph{material} and \emph{FOC
transition status} was also significant, \(F(1, 119) = 27.61\),
\(\mathrm{MSE} = 13.49\), \(p < .001\), \(\eta^2_G = .014\), reflecting
the finding that the effect of the latter factor was limited to the
probabilistic material. The three-way interaction of \emph{material},
\emph{block number}, and \emph{FOC transition status} was however not
significant, \(F(6.55, 778.97) = 1.84\), \(\mathrm{MSE} = 7.94\),
\(p = .082\), \(\eta^2_G = .004\).

To disentangle these interactions, we analyzed both \emph{material}
groups separately. As for RT, an ANOVA for the random material group
revealed only a main effect of \emph{block number},
\(F(4.94, 291.45) = 2.50\), \(\mathrm{MSE} = 16.03\), \(p = .031\),
\(\eta^2_G = .013\) (all other \emph{F}s \textless{} 1). The
probabilistic material group showed a main effect of \emph{block number}
\(F(5.73, 343.65) = 4.63\), \(\mathrm{MSE} = 10.29\), \(p < .001\),
\(\eta^2_G = .022\), and a main effect of \emph{FOC transition status},
\(F(1, 60) = 62.50\), \(\mathrm{MSE} = 14.23\), \(p < .001\),
\(\eta^2_G = .070\). Importantly, the interaction of \emph{block number}
and \emph{FOC transition status} was significant,
\(F(5.9, 353.81) = 3.23\), \(\mathrm{MSE} = 7.85\), \(p = .004\),
\(\eta^2_G = .012\), indicating that the difference in error rates
between regular and irregular transitions increased across blocks,
consistent with the learning effect obtained for reaction times.

\subsubsection{Generation task}\label{generation-task-1}

In a second step, we investigated how learned knowledge was expressed in
the generation task (descriptive statistics are reported in Appendix C).
We analyzed generation performance by fitting two hierarchical models,
\(\mathcal{M}_1\) and \(\mathcal{M}_2\). \(\mathcal{M}_1\) allows the
automatic and controlled processes to vary between inclusion and
exclusion, but it assumes that participants acquired only implicit
knowledge during the SRTT, and that revealing explicit knowledge after
the SRTT did not affect implicit knowledge. \(\mathcal{M}_2\) is a
hierarchical extension of the classical PD model that enforces the
invariance assumption. We computed model fit statistics to test whether
each model could account for the means, \(T_{A1}\), and covariances,
\(T_{B1}\), of the observed frequencies. We compared both models using
the DIC statistic that provides a combined assessment of parsimony and
goodness of fit and penalizes models for unnecessary complexity.
Parameter estimates from model \(\mathcal{M}_1\) were used to address
the invariance assumptions, directly.

The model checks for model \(\mathcal{M}_1\) were satisfactory,
\[T_{A1}^{observed} = 491.06, T_{A1}^{expected} = 469.94, p = .369,\]~
\[T_{B1}^{observed} = 9.05, T_{B1}^{expected} = 6.95, p = .366.\] In
contrast, the model checks for model \(\mathcal{M}_2\) revealed
significant deviations of the model's predictions from the data,
\[T_{A1}^{observed} = 1,092.06, T_{A1}^{expected} = 473.88, p = .002,\]~
\[T_{B1}^{observed} = 190.05, T_{B1}^{expected} = 6.93, p < .001.\]

Model \(\mathcal{M}_1\) attained a DIC value of 25,293.45 and clearly
outperformed model \(\mathcal{M}_2\) that attained a DIC value of
25,891.74,
\(\Delta \textrm{DIC}_{\mathcal{M}_1 - \mathcal{M}_2} = -598.29\). This
implies that the auxiliary assumptions we introduced to
\(\mathcal{M}_1\) were much less problematic than the invariance
assumption. Moreover, the standard PD model enforcing the invariance
assumption was not able to account for the data.

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl7-parameter-estimates-1.pdf}
\caption{\label{fig:pdl7-parameter-estimates}Parameter estimates from
Experiment 2. Error bars represent 95\% confidence intervals.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl7-posterior-differences-1.pdf}
\caption{\label{fig:pdl7-posterior-differences}Posterior differences between
\(A_I - A_E\) and \(C_I - C_E\) in Experiment 2, plotted for each
participant (gray dots) with 95\% credible intervals. Dashed lines
represent the posterior means of the differences between mean parameter
estimates. Dotted lines represent 95\% credible intervals.}
\end{figure}

Figure \ref{fig:pdl7-parameter-estimates} shows the parameter estimates
obtained from model \(\mathcal{M}_1\). Figure
\ref{fig:pdl7-posterior-differences} shows that the invariance
assumption for the automatic process was violated with \(A_I > A_E\),
95\% CI {[}.01, .03{]}, and a Bayesian \(p < .001\) (\(p = .360\) for
revealed transitions). The invariance assumption for the controlled
process was also violated with \(C_I > C_E\), 95\% CI {[}.08, .54{]},
and a Bayesian \(p = .003\).

\subsubsection{Robustness checks}\label{robustness-checks}

Next we assessed whether these findings were sensitive to the
assumptions of our models.\\
Despite the fact that the auxiliary assumptions could be upheld in model
comparison, and that the incorporating model was well able to account
for the data, it may nevertheless still be the case that violations have
biased parameter estimates. Specifically, if participants had in fact
acquired explicit knowledge about nonrevealed transitions during
learning, they may have used this knowledge to generate more regular
transitions under inclusion than exclusion. Because of our assumption
that \(C = 0\) for nonrevealed transitions, this performance difference
would have been reflected in greater estimates of implicit knowledge
under inclusion than exclusion, and might account for the observed
\(A_{I} > A_{E}\) pattern.

To assess this possibility, we used the questionnaire data to exclude
any transitions that participants reported in their explicit description
of the sequence (while keeping the revealed transitions); if the
acquired explicit knowledge was indeed the cause of the invariance
violation, excluding the transitions for which knowledge was reported
should make the violation disappear. To the contrary, excluding all
correctly reported transitions (9.04\% of cases) did not affect the
pattern of results.\footnote{Of the reported (nonrevealed) transitions,
  only approximately 25.47\% were indeed regular transitions. After
  excluding \emph{all} reported transitions regardless of whether they
  reflect correct knowledge or not (27.55\% of cases), the invariance
  violation was descriptively unchanged but no longer statistically
  significant, Bayesian \(p = .221\).}

We also tested the invariance assumption using a different model
\(\mathcal{M}_{1R}\) that extended \(\mathcal{M}_1\) by relaxing the
assumption that \(C = 0\) for nonrevealed transitions (see Appendix A
for details). The invariance violation for the controlled process,
\(C_I > C_E\), was reproduced in the absence of the assumption \(C=0\),
demonstrating its robustness. However, the small invariance violation
for the automatic process was no longer evident in \(\mathcal{M}_{1R}\).

\subsection{Discussion}\label{discussion-1}

The experimental manipulations had the expected results: Based on the
SRTT results, we can conclude that participants acquired sequence
knowledge during learning. In addition, explicit knowledge about one of
the six transitions had a clear effect on generation performance for
that transition.

The extended process-dissociation model \(\mathcal{M}_1\) revealed a
violation of the invariance assumptions for both the controlled process
(i.e., \(C_I > C_E\)) and the automatic process (i.e., \(A_I > A_E\)).
Model \(\mathcal{M}_1\) rested on two auxiliary assumptions: It was
assumed that controlled processes were not affected by learning material
(i.e., no explicit knowledge was acquired from the SRTT), and that
automatic processes were not affected by the manipulation of explicit
knowledge (i.e., revealing a transition). Both assumptions found support
in the current data as they did not harm model fit. Moreover, model
comparison by the DIC showed that model \(\mathcal{M}_1\) was a better
account of the data than the standard process-dissociation model
\(\mathcal{M}_2\) that did not impose these assumptions but instead
imposed the invariance assumption.

Invariance of the automatic process was significantly violated, but the
magnitude of the violation was small, and it disappeared entirely under
a relaxed model (\(\mathcal{M}_{1R}\); see Appendix A). Given the small
magnitude, and its lack of robustness to the modeling assumptions, the
invariance violation of \(A\) appears to be no serious threat to the
validity of the PD at this point.

In contrast, invariance of the controlled process was consistently found
to be violated and the violation was large in magnitude: Confirming the
speculation that explicit knowledge is not exhaustively used in
exclusion, explicit knowledge was used to a greater degree under
inclusion than exclusion.

\section{Experiment 3}\label{experiment-3}

The main goal of Experiment 3 was to replicate the previous findings and
extend them to second-order conditional (SOC) material.

A secondary goal was to explore whether different amounts of implicit
knowledge are acquired with \emph{mixed} versus \emph{pure} SOC
material. Previous studies of the SRTT using a PD generation task have
employed 12-item-sequences of four response locations (e.g., SOC1 =
\(3{-}4{-}2{-}3{-}1{-}2{-}1{-}4{-}3{-}2{-}4{-}1\); SOC2 =
\(3{-}4{-}1{-}2{-}4{-}3{-}1{-}4{-}2{-}1{-}3{-}2\), Destrebecqz \&
Cleeremans, 2001; Wilkinson \& Shanks, 2004). Analyzing these sequences
more closely, it is evident that they did not only contain second order
information (i.e., the last two locations predict the next location),
but they also incorporate lower-order information: First, direct
repetitions never occur; and reversals occur below chance (i.e., 1/12,
whereas chance level would equal \(1/3\) given that repetitions are
prohibited). Second, the last location of a triplet \(L_3\) is not
independent of the first location \(L_1\) (e.g., for SOC1,
\(p(L_3 = 2 | L_1 = 3) = 2/3\)). In other words, in two out of three
cases, the third location of a triplet can be predicted by the first
location of a triplet alone. It is plausible that participants are able
to learn this lower-order information, and that learning effects may not
(only) be based on second-order information (cf., Koch \& Hoffmann,
2000; Reed \& Johnson, 1994). To investigate this possibility,
Experiment 3 implemented two types of probabilistic material: A
\emph{mixed SOC} material that incorporated both second-order and
first-order types of information, and another \emph{pure SOC} material
that only followed a second-order regularity.

\subsection{Method}\label{method-2}

\subsubsection{Design}\label{design-2}

The study realized a 3 (\emph{material}: random, mixed SOC, pure SOC)
\(\times\) 2 (\emph{explicit knowledge}: no transition revealed vs.~two
transitions revealed) \(\times\) 2 (\emph{PD instruction}: inclusion
vs.~exclusion) \(\times\) 2 (\emph{block order}: inclusion first
vs.~exclusion first) design with repeated measures on the \emph{PD
instruction} factor.

\subsubsection{Participants}\label{participants-2}

One hundred and seventy-nine participants (120 women) aged between 18
and 58 years (\(M = 22.8\) years) completed the study. Most were
undergraduates from Heinrich-Heine-Universität Düsseldorf. Data from 8
participants were excluded from generation task analyses because they
had received erroneous exclusion instructions. Participants were
randomly assigned to experimental conditions. They received either
course credit or 3.50 Euro for their participation.

\subsubsection{Materials}\label{materials-2}

We implemented three different types of material:

\begin{itemize}
\tightlist
\item
  A \emph{random} sequence was randomly generated for each participant
  anew by drawing with replacement from a uniform distribution of six
  response locations.
\item
  A \emph{mixed SOC} sequence incorporated two types of information:
  First, the third location of a triplet was conditional upon the first
  two locations. Second, within such regular triplets, given a fixed
  first-position location, there was one highly probable third-position
  location and two somewhat less probable third-position locations; the
  other three response locations never occurred for this first-position
  location.
\item
  A \emph{pure SOC} sequence followed only the second-order regularity.
\end{itemize}

In both probabilistic materials (\emph{mixed} and \emph{pure} SOC),
87.5\% of trials adhered to the second-order regularity, which was
individually and randomly selected for each participant anew. In all
conditions, the material adhered to the following (additional)
restrictions: (1) there were no direct repetitions of response
locations, and (2) there were no response location reversals (i.e.,
1-2-1). To compute the dependent variable in the generation task (i.e.,
the number of rule-adhering triplets), for both \emph{probabilistic}
groups, we used the second-order sequence that was used to generate each
participant's materials. For the \emph{random} group, there is no
\enquote{regular} sequence and we again computed an individual criterion
sequence for each participant. For convenience, we did not generate all
possible second-order sequences for these participants (as we did for
first-order materials in Experiment 1), but chose to use individual
criterion sequences that were randomly generated similar to the
\emph{pure SOC} material.

\subsubsection{Procedure}\label{procedure-2}

The experimental procedure closely followed that of Experiment 1: In the
acquisition task, participants performed a SRTT consisting of 8 blocks
with 180 trials each (for a total of 1,440 responses). The
response-stimulus interval (RSI) was \(0~\text{ms}\). Following the SRTT
phase, participants were told that stimulus locations during the SRTT
followed some underlying sequential structure. They were then asked to
try to generate a short sequence of thirty locations that followed this
structure.

The generation task followed, with inclusion versus exclusion block
order counterbalanced. We fixed the number of practice blocks that
preceded both inclusion and exclusion task: Prior to the inclusion task,
three practice blocks involved inclusion instructions; prior to the
exclusion task, the first and second practice block involved inclusion
instructions, and the third involved exclusion instructions. Before
working on practice blocks, two transitions were revealed to one half of
the participants.

Upon completing the computerized task, participants were asked to
complete a questionnaire containing the following items: (1)
\enquote{Did you notice anything special working on the task? Please
mention anything that comes to your mind.}, (2) \enquote{One of the
tasks mentioned a sequence in which the squares lit up during the first
part of the study. In one of the experimental conditions, the squares
did indeed follow a specific sequence. Do you think you were in this
condition or not?}, (3) \enquote{How confident are you (in \%)?}, (4)
\enquote{Can you describe the sequence in detail?}. Subsequently,
participants were asked to indicate, for ten first-order transitions,
the next three keys in the sequence on a printed keyboard layout. The
first-order transitions were individually selected for each participant
so that each participant had the chance to express full explicit
knowledge about the second-order regularity.

\subsubsection{Data analysis}\label{data-analysis-2}

For analyses of reaction times during the acquisition task, we excluded
the first two trials of each block because the first two locations
cannot be predicted, as well as error trials, trials succeeding an
error, reactions faster than 50 ms and slower than 1,000 ms. For
analyses of error rates during the acquisition task, we excluded the
first two trials of each block.

Generation task analyses were conducted with the first two trials of a
block as well as any response repetitions and reversals excluded.
Model-based analyses were conducted with models \(\mathcal{M}_1\) and
\(\mathcal{M}_2\) analogous to those used in Experiment 2 (see Appendix
for details).

\subsection{Results}\label{results-2}

We first analyzed reaction times and error rates during the SRT task to
determine whether sequence knowledge had been acquired during the task.
Next, we analyzed generation task performance using hierarchical PD
models (descriptive statistics are reported in Appendix C).

\subsubsection{Acquisition task}\label{acquisition-task-2}

If participants acquired sequence knowledge from probabilistic
materials, we expect a performance advantage for regular over irregular
transitions, reflected in reduced RT and/or error rate. If this
advantage is due to learning, it is expected to increase over SRTT
blocks. If participants are able to learn lower-order information that
is only present in \emph{mixed SOC} material, the advantage is expected
to be greater in \emph{mixed SOC} material compared to \emph{pure SOC}.
If participants are able to learn second-order information, a
performance advantage is to be expected not only in \emph{mixed SOC} but
also in \emph{pure SOC} material.

\paragraph{Reaction times}\label{reaction-times-2}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl10-acquisition-rt-1.pdf}
\caption{\label{fig:pdl10-acquisition-rt}RTs during acquisition phase of
Experiment 3, split by \emph{material} and \emph{SOC transition status}.
Error bars represent 95\% within-subjects confidence intervals.}
\end{figure}

Figure \ref{fig:pdl10-acquisition-rt} shows reaction times during
acquisition. We conducted a 3 (\emph{Material}: random vs.~pure SOC
vs.~mixed SOC) \(\times\) 2 (\emph{Transition status}: regular
vs.~irregular SOC) \(\times\) 8 (\emph{Block number}) ANOVA with
repeated measures on the last two factors that revealed a main effect of
\emph{block number}, \(F(4.46, 780.51) = 41.53\),
\(\mathrm{MSE} = 1,515.93\), \(p < .001\), \(\eta^2_G = .020\),
reflecting decreasing RT over blocks; a main effect of \emph{transition
status}, \(F(1, 175) = 40.02\), \(\mathrm{MSE} = 582.10\), \(p < .001\),
\(\eta^2_G = .002\), reflecting an RT advantage for regular transitions;
and an interaction of \emph{block number} and \emph{transition status},
\(F(6.39, 1118.42) = 2.81\), \(\mathrm{MSE} = 439.60\), \(p = .009\),
\(\eta^2_G = .001\), reflecting the finding that the RT advantage for
regular transitions increased over block (i.e., the sequence learning
effect). We also found an interaction of \emph{material} and
\emph{transition status}, \(F(2, 175) = 7.40\),
\(\mathrm{MSE} = 582.10\), \(p = .001\), \(\eta^2_G = .001\), reflecting
the finding that the effect of \emph{transition status} was absent in
the random material group, \(F(1, 58) = 0.44\),
\(\mathrm{MSE} = 380.19\), \(p = .510\), \(\eta^2_G = .000\); trivially,
no sequence knowledge was learned from random material.

The three-way interaction was not significant,
\(F(12.78, 1118.42) = 0.92\), \(\mathrm{MSE} = 439.60\), \(p = .535\),
\(\eta^2_G = .000\), suggesting that the sequence-learning effect did
not differ across material groups. We conducted separate analyses to
probe for sequence-learning effects in each material condition.
Analyzing only the random material group revealed only a main effect of
\emph{block number}, \(F(3.82, 221.55) = 15.74\),
\(\mathrm{MSE} = 1,484.04\), \(p < .001\), \(\eta^2_G = .020\) (all
other \emph{p}s \textgreater{} .05). In the \emph{pure SOC} group, in
contrast, a main effect of \emph{block number},
\(F(3.96, 229.51) = 12.04\), \(\mathrm{MSE} = 2,038.65\), \(p < .001\),
\(\eta^2_G = .019\), was accompanied by a main effect of
\emph{transition status}, \(F(1, 58) = 28.48\),
\(\mathrm{MSE} = 637.73\), \(p < .001\), \(\eta^2_G = .004\), and an
interaction of both factors, \(F(6.03, 349.61) = 2.47\),
\(\mathrm{MSE} = 530.13\), \(p = .023\), \(\eta^2_G = .002\), reflecting
a sequence learning effect on RT.

In the \emph{mixed SOC} group, we obtained only main effects of
\emph{block number}, \(F(4.91, 289.7) = 15.95\),
\(\mathrm{MSE} = 1,334.22\), \(p < .001\), \(\eta^2_G = .024\), and of
\emph{transition status}, \(F(1, 59) = 18.83\),
\(\mathrm{MSE} = 725.90\), \(p < .001\), \(\eta^2_G = .003\), but the
interaction of \emph{block number} and \emph{transition status} was not
significant, \(F(5.74, 338.77) = 1.15\), \(\mathrm{MSE} = 571.40\),
\(p = .331\), \(\eta^2_G = .001\). This is despite the fact that the
effect of transition status is also likely to be a result of sequence
learning, and it is of similar magnitude to that obtained in the pure
SOC group. The notion that both learning effects are similar was also
supported by a joint analysis of the pure SOC and mixed SOC groups: The
two-way interaction between block number and transition status was
significant, \(F(6.14, 718.32) = 2.75\), \(\mathrm{MSE} = 527.50\),
\(p = .011\), \(\eta^2_G = .001\), but the three-way-interaction of
\emph{material}, \emph{block number}, and \emph{transition status} was
not significant, \(F(6.14, 718.32) = 0.87\), \(\mathrm{MSE} = 527.50\),
\(p = .521\), \(\eta^2_G = .000\). Taken together, we interpret these
findings to show that the learning effect in the mixed SOC group was
comparable to that observed in the pure SOC group but too small to reach
significance in a separate analysis.

\paragraph{Error rates}\label{error-rates-2}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl10-acquisition-error-1.pdf}
\caption{\label{fig:pdl10-acquisition-error}Error rates during acquisition
phase of Experiment 3, split by \emph{material} and \emph{SOC transition
status}. Error bars represent 95\% within-subjects confidence
intervals.}
\end{figure}

Figure \ref{fig:pdl10-acquisition-error} shows error rates during
acquisition. We conducted a 3 (\emph{Material}: Random vs.~mixed SOC
vs.~pure SOC) \(\times\) 8 (\emph{Block number}) \(\times\) 2 (\emph{SOC
transition status}: regular vs.~irregular) ANOVA with repeated measures
on the last two factors that revealed a main effect of \emph{block
number}, \(F(3.66, 644.87) = 3.78\), \(\mathrm{MSE} = 39.10\),
\(p = .006\), \(\eta^2_G = .008\), reflecting increasing error rates
over blocks, and a main effect of \emph{transition status},
\(F(1, 176) = 16.14\), \(\mathrm{MSE} = 9.08\), \(p < .001\),
\(\eta^2_G = .002\), reflecting an accuracy advantage for regular
transitions. The interaction of \emph{material} and \emph{transition
status} was not significant, \(F(2, 176) = 2.66\),
\(\mathrm{MSE} = 9.08\), \(p = .073\), \(\eta^2_G = .001\),

Separate analyses yielded no significant effects in the random material
group (all \emph{p}s \textgreater{} .05). Importantly, an effect of
\emph{transition status} was clearly absent from the random material
group, \(F(1, 58) = 0.62\), \(\mathrm{MSE} = 7.68\), \(p = .433\),
\(\eta^2_G = .000\). In the \emph{mixed SOC} group, a main effect of
\emph{block number} was found, \(F(5.66, 334.01) = 2.96\),
\(\mathrm{MSE} = 15.46\), \(p = .009\), \(\eta^2_G = .017\), along with
a main effect of \emph{transition status}, \(F(1, 59) = 12.88\),
\(\mathrm{MSE} = 11.29\), \(p = .001\), \(\eta^2_G = .009\), reflecting
higher error rates for irregular than for regular transitions. Finally,
in the \emph{pure SOC} group, block number did not affect error rates,
\(F(1.87, 110.6) = 1.72\), \(\mathrm{MSE} = 133.60\), \(p = .185\),
\(\eta^2_G = .011\); but a main effect of \emph{transition status} was
also found, \(F(1, 59) = 5.55\), \(\mathrm{MSE} = 8.24\), \(p = .022\),
\(\eta^2_G = .001\), reflecting higher error rates for irregular than
regular transitions.

Taken together, error rates mirror RTs in that they also reflect a
performance advantage for regular transitions in the mixed and pure SOC
groups that was not evident in the random control group. Deviating from
the RT result pattern, this advantage did not reliably increase across
blocks.

\subsubsection{Generation task}\label{generation-task-2}

We analyzed generation performance by fitting the two hierarchical
models \(\mathcal{M}_1\) and \(\mathcal{M}_2\) that we introduced above
to the data from Experiment 3. For both models, we computed model fit
statistics to assess whether each model could account for the data; we
then compared both models using the DIC. Parameter estimates from model
\(\mathcal{M}_1\) were then used to address the invariance assumptions
directly.

The model checks for model \(\mathcal{M}_1\) were satisfactory,
\[T_{A1}^{observed} = 692.77, T_{A1}^{expected} = 653.45, p = .291,\]~
\[T_{B1}^{observed} = 8.44, T_{B1}^{expected} = 6.04, p = .292.\] In
contrast, the model checks for model \(\mathcal{M}_2\) revealed
significant deviations of the model's predictions from the data,
\[T_{A1}^{observed} = 1,077.52, T_{A1}^{expected} = 652.79, p = .003,\]~
\[T_{B1}^{observed} = 49.97, T_{B1}^{expected} = 6.06, p < .001.\]

Model \(\mathcal{M}_1\) attained a DIC value of 38,907.43 and
outperformed model \(\mathcal{M}_2\) that attained a DIC value of
39,210.66,
\(\Delta \textrm{DIC}_{\mathcal{M}_1 - \mathcal{M}_2} = -303.23\). This
implies that our auxiliary assumptions that we introduced to make model
\(\mathcal{M}_1\) identifiable (i.e., that participants did not acquire
explicit knowledge during training, and that revealing explicit
knowledge about a transition did not affect implicit knowledge) were
less problematic than the invariance assumption. Moreover, the standard
PD model enforcing the invariance assumption was not able to account for
the data.

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl10-parameter-estimates-1.pdf}
\caption{\label{fig:pdl10-parameter-estimates}Parameter estimates from
Experiment 3. Error bars represent 95\% confidence intervals.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{main_files/figure-latex/pdl10-posterior-differences-1.pdf}
\caption{\label{fig:pdl10-posterior-differences}Posterior differences
\(A_I - A_E\) and \(C_I - C_E\) in Experiment 3, plotted for each
participant (gray dots) with 95\% credible intervals. Dashed lines
represent the posterior means of the differences between mean parameter
estimates. Dotted lines represent 95\% credible intervals.}
\end{figure}

Figure \ref{fig:pdl10-parameter-estimates} shows the parameter estimates
obtained from model \(\mathcal{M}_1\). Figure
\ref{fig:pdl10-posterior-differences} shows that the invariance
assumption for controlled processes was again violated with
\(C_I > C_E\), 95\% CI {[}.27, .63{]}, Bayesian \(p < .001\). The
invariance violation was also obtained with model \(\mathcal{M}_{1R}\),
showing that it is robust to the specific modeling assumptions (see
Appendix A). In contrast to the results of Experiment 2, the invariance
assumption for automatic processes was not violated but could be upheld,
95\% CI {[}-.01, .01{]}, Bayesian \(p = .638\) for non-revealed
transitions and 95\% CI {[}-.10, .05{]}, \(p = .763\) for revealed
transitions.

\subsection{Discussion}\label{discussion-2}

The experimental manipulations had the expected results: Based on the
SRTT results, we can conclude that participants acquired some (albeit
weak) sequence knowledge during learning. In addition, generation
performance was clearly affected by instructed explicit knowledge, as
revealed by the clearly above-zero estimates of the \(C\) parameters for
revealed transitions.

An extended process-dissociation model \(\mathcal{M}_1\) revealed a
violation of the invariance assumption for controlled processes with
\(C_I > C_E\). The invariance assumption for automatic processes could
be upheld. Model \(\mathcal{M}_1\) rested on two auxiliary assumptions:
It was assumed that controlled processes were not affected by learning
material, and that automatic processes were not affected by the
manipulation of explicit knowledge (i.e., revealing a transition). Both
assumptions found support in the current data as they did not harm model
fit. Importantly, when comparing model \(\mathcal{M}_1\) to a standard
process-dissociation model \(\mathcal{M}_2\) that did not impose these
assumptions but left the invariance assumption intact, model
\(\mathcal{M}_1\) was strongly favored by the DIC.

Regarding our secondary goal to explore whether different amounts of
sequence knowledge are acquired from mixed versus pure second-order
conditional material, we did not find evidence for a difference between
these two types of material in the SRTT. This may well be due to the
overall low levels of acquired sequence knowledge in the present study.
Clearly, the present data are not strong enough to rule out such
differences; this question requires further study.

\section{General Discussion}\label{general-discussion}

\subsection{Summary of main findings}\label{summary-of-main-findings}

The process-dissociation approach as applied to sequence learning
assumes either (1) that automatic processes monotonically increase both
inclusion and exclusion performance, while controlled processes increase
inclusion but decrease exclusion performance (if the ordinal approach is
used), or (2) that the controlled and automatic process are invariant
under inclusion and exclusion instructions (if the parametric model is
used).

In three sequence-learning experiments, we tested whether the
monotonicity and invariance assumptions hold in the generation task. The
results show a consistent pattern.

\subsubsection{Monotonicity assumption}\label{monotonicity-assumption}

Increases in explicit knowledge across conditions consistently increased
overall \emph{inclusion} performance, but were insufficient to reliably
decrease overall \emph{exclusion} performance. Participants were largely
unable to use their explicit knowledge to suppress the proportion of
regular transitions generated in the exclusion task to levels below
baseline. Below-baseline generation levels for revealed transitions were
robustly found only for material with a first-order regularity, and only
in participants who had explicit knowledge about (at least) two
transitions and engaged in generation-task practice specific to a given
to-be-excluded transition (Exp. 1, Transfer condition). In these
participants, there was even some evidence that below-chance exclusion
performance transferred to non-practiced explicit knowledge. However,
transition-specific practice was (necessary but) not sufficient for
successful exclusion: Whereas participants without such practice (i.e.,
the No-Practice and Unspecific-Practice conditions of Exp.1) failed to
reach below-chance levels, participants with practice also failed to
attain below-chance levels under exclusion instructions if they worked
on the inclusion task first (i.e., Exp. 1, Practice condition). Taken
together, these results confirm Wilkinson and Shanks's (2004)
speculation that inclusion and exclusion strategies may differ and that
explicit knowledge is not exhaustively expressed in the generation
task's exclusion condition, to the effect that increasing explicit
knowledge does not result in decreased generation of regular transitions
under exclusion.

\subsubsection{Invariance of the controlled
process}\label{invariance-of-the-controlled-process}

The finding that explicit knowledge was less likely to affect exclusion
performance also suggests a violation of invariance. Experiments 2 and 3
showed that, indeed, the invariance assumption for explicit knowledge
was consistently violated, in first-order as well as second-order
material, and despite extensive opportunity for practice. In all cases,
explicit knowledge was expressed to a greater degree under inclusion
than under exclusion instructions: Participants succeeded in generating
the revealed transition under inclusion conditions, but failed to
consistently refrain from generating that transition under exclusion
conditions; specifically, under exclusion conditions, participants
typically generated the revealed transition at chance levels, instead of
suppressing its generation altogether as instructed.

\subsection{Limitations and open
questions}\label{limitations-and-open-questions}

Before turning to the implications of the present findings, we discuss
potential limitations and identify open questions.

\subsubsection{The invariance violation of the automatic process may
reflect learned explicit
knowledge}\label{the-invariance-violation-of-the-automatic-process-may-reflect-learned-explicit-knowledge}

In Experiment 2 that used first-order conditional material we found
evidence suggesting a violation of the invariance assumption for
implicit knowledge; no such evidence was however found for the
second-order conditional material used in Experiment 3. If interpreted
in a standard PD framework, the inclusion-exclusion performance
difference resulting from this violation may lead to erroneous
conclusions about the presence of explicit knowledge (if such knowledge
is indeed absent), or to overestimation of the contribution of explicit
knowledge. We believe these findings of an inclusion-exclusion
difference in estimates of the automatic parameter should be interpreted
with some caution, for at least three reasons. First, the finding was
inconsistent across studies, and there are multiple possible causes of
this inconsistency: The lack of a violation in Experiment 3 may be due
to specific properties of the material, or it may be due to the fact
that sequence knowledge levels in that study were too low for
differences in its expression to be measurable.

Second, the violation was relatively small (i.e., the \(A_{I}-A_{E}\)
difference ranged between .01 and .03 in Exp.2; and between .00 and .03
in Exp.1, see Appendix B). In the absence of controlled influences, this
would be equivalent to a difference between inclusion and exclusion
performance of approximately 2 percentage points --- an effect barely
noticeable under typical conditions.

Third, it is unclear whether the observed invariance violation of
parameter \(A\) reflects implicit knowledge at all. Note that the
parameter for the automatic process captures the sum of all
non-controlled influences on generation performance. In particular, it
might reflect guessing strategies, and these may differ under inclusion
versus exclusion conditions (Stahl et al., 2015). In other words, the
above effect may reflect a violation of invariance of guessing or
response strategies instead of a violation of invariance of the
automatic expression of implicit knowledge. Taken together, we interpret
the finding as too weak to conclude that the invariance assumption is
violated also for the automatic process.

Instead of being due to guessing, the inclusion-exclusion difference in
estimates of the automatic parameter may be due to explicit knowledge
acquired during learning. Such an effect, if present at all, is likely
to be small given that (1) the material was probabilistic and therefore
difficult to learn explicitly; (2) the model incorporating the
assumption that no learned explicit knowledge was learned fitted the
data well; and (3) the results were unchanged when we excluded the data
from transitions that participants (correctly) reproduced during
debriefing. However, we cannot exclude the possibility that small
amounts of explicit knowledge, obtained during the SRTT phase, may have
distorted our model's parameter estimates. This interpretation could
also account for the lack of such an effect in Experiment 3 given that
explicit knowledge was less likely to be learned from the more complex
second-order conditional material used in that study. If this were true,
then any differences between inclusion and exclusion that were
attributed by the model to an invariance violation of the implicit
process may in fact have been a consequence of residual explicit
knowledge that was not reflected in our debriefing questionnaire
(perhaps due to participants' conservative reporting criteria).

To further address this possibility, we conducted additional model
analyses for Experiments 2 and 3 (reported in Appendix B) that aimed at
estimating the amount of this residual explicit knowledge; we still
found a violation of invariance for the automatic process, but of
different direction --- a finding that we consider to be an artifact of
the auxiliary modeling assumptions. This limitation is another reason
for caution in interpreting the above finding as evidence for a
violation of invariance of the automatic process. Note that it does not
limit the interpretation of our main finding of the invariance violation
of the controlled process, which was robust against changes in auxiliary
assumptions.

\subsubsection{The evidence for sequence learning was weak for SOC
material in Experiment
3}\label{the-evidence-for-sequence-learning-was-weak-for-soc-material-in-experiment-3}

As expected, second-order conditional material (Experiment 3) was more
difficult to learn than first-order conditional material (Experiments 1
\& 2). This was reflected here in the finding that (despite a 20\%
increase in learning trials) there was only weak evidence for sequence
learning in Experiment 3. Specifically, responses to regular transitions
were clearly faster and more accurate for both variants of the SOC
materials, but the interaction between regularity and training block,
which is critical for unambiguously interpreting a performance advantage
for regular transitions as an effect of learning, was not significant.
Clearly, an even larger amount of SRTT training should be realized in
future studies using SOC materials. Yet, it is unlikely that the
observed RT advantage for regular transitions has any other causes than
learning, given that it was absent from the random condition, and that
the effect could not be attributed to properties of specific transitions
because regularity of a transition was randomized for each participant
anew. Nevertheless, because evidence for (implicit) sequence learning
was not beyond doubt, it is not warranted to interpret the modeling
results as stringent tests of the invariance assumption for the
automatic process.

\subsubsection{Explicit knowledge learned via instruction may be
qualitatively different from acquired explicit
knowledge}\label{explicit-knowledge-learned-via-instruction-may-be-qualitatively-different-from-acquired-explicit-knowledge}

The present study manipulated explicit knowledge via instruction.
Although it is an established method (e.g., Liefooghe, Wenke, \& De
Houwer, 2012) that has yielded important insights in other domains, one
might argue that explicit knowledge acquired via instruction is somehow
qualitatively different from explicit knowledge acquired during SRTT
training, and that therefore the present results do not speak to the
question of interest regarding the invariance of the expression of
acquired knowledge. We believe our manipulation to be valid for the
following reasons. First, the instructed explicit knowledge communicated
the same proposition about the sequence that participants would have
acquired during SRTT training (i.e., that a specific location was
regularly followed by another location). Second, we took precautions to
avoid any inconsistency or conflict with learned sequence knowledge:
Transitions that were revealed to participants were part of the regular
sequence and therefore compatible with acquired (implicit or explicit)
sequence knowledge. Third, we allowed participants to integrate
instructed and acquired knowledge during the practice blocks before the
generation task.

Given that the instructed and acquired propositions are identical, we
would argue that qualitative differences between acquired and instructed
knowledge are likely to involve non-propositional forms of knowledge;
such non-propositional knowledge is typically considered to be implicit.
Indeed, it is likely that strong implicit knowledge is a precondition
for acquiring explicit knowledge (Cleeremans \& Jiménez, 2002; Haider \&
Frensch, 2009): Instructed and acquired explicit knowledge are therefore
likely to differ in the degree to which they are correlated with
implicit knowledge. If participants are better able to control acquired
than instructed explicit knowledge, this would then be due,
paradoxically, to the presence of acquired implicit knowledge. Finally,
even if that was the case, note that this would not salvage the PD
method because a strong correlation between explicit and implicit
knowledge would violate the independence assumption, thereby posing
another problem for its validity.

\subsection{Implications}\label{implications}

We will first discuss implications for the PD approach before we suggest
ways to improve measurement of sequence knowledge using the generation
task. We conclude with a few broader implications.

\subsubsection{Validity of the PD
method}\label{validity-of-the-pd-method}

The present findings show that participants fail to exhaustively
suppress generating regular transitions under exclusion instructions;
this finding has repercussions for both the ordinal- and parametric-PD
approaches.

In the ordinal approach, given a single experimental condition, it is
concluded that implicit knowledge is present if exclusion performance is
above a (chance or empirical) baseline; and it is concluded that
explicit knowledge is present if inclusion performance exceeds exclusion
performance. These conclusions depend on the assumption that a
monotonically increasing controlled process should lead to a monotonic
increase of inclusion performance and at the same time a monotonic
decrease of exclusion performance. The present study shows, however,
that exclusion performance cannot be assumed to reliably decrease with
increasing explicit knowledge. This implies that the assumptions
underlying the ordinal-PD approach are violated for the generation task
as applied to sequence learning. In addition, we have previously shown
that another assumption of ordinal PD, namely that baseline performance
is identical in the inclusion and exclusion tasks, is also violated at
least in some cases (Stahl et al., 2015). Given that these two
fundamental assumptions are violated, the analysis approach adopted in
the SRTT literature is also compromised.

The controlled process was found to operate less effectively under
exclusion than inclusion instructions; in terms of the parametric PD
model, invariance for the controlled process was violated with
\(C_I > C_E\). A model that nevertheless incorporates the invariance
assumption will likely fail to adequately account for the data, and will
yield distorted estimates of the automatic and controlled process. To
illustrate, assume that the true values of the parameters are
\(C_{Inclusion} = .8, C_{Exclusion} = .4\), and
\(A_{Inclusion} = A_{Exclusion} = .25\). This yields the following
generation proportions of regular transitions
\(I = .8 + (1-.8)*.25 = 0.85\) and \(E = (1-.4)*.25 = 0.15\). When
fitting a traditional PD model enforcing the invariance assumption
\(C = C_{Inclusion} = C_{Exclusion}\) to these data, we get \(C=.7\)
that lies somewhere between the true values of \(C\), and \(A = .5\)
which is a vast overestimation of the true \(A\). Importantly, note that
if the true value of \(A=.25\) represents chance level, applications of
the traditional PD method might lead to the erroneous conclusion that
implicit knowledge had been learned even if such knowledge was in fact
entirely absent. In addition, if we are interested in the amount of
explicit knowledge learned from the SRTT training phase, it might be
argued that the higher estimate obtained from the inclusion condition
might be a more valid estimate of learned explicit knowledge; the
inability to express this knowledge under exclusion may be of secondary
interest. By this argument, applying the traditional PD method also
yields an underestimation of explicit knowledge.

We therefore recommend against using the PD method unless separate
estimates of \(C_{Inclusion}\) and \(C_{Exclusion}\) can be obtained,
for example as we have done in the present study. To do so, an extension
of the standard design is necessary; for instance, in the present study
we implemented two levels of an explicit-knowledge factor across which
we equated the \(A\) parameters; this allowed us to estimate separate
\(C\) parameters for inclusion and exclusion. Note that this strategy
may not be broadly applicable in typical SRTT studies because of the
strong correlation between (acquired) \(C\) and \(A\); the assumption
that the level of implicit knowledge is constant across two different
levels of explicit knowledge will be warranted only in special cases
such as realized in the present studies (e.g., if explicit knowledge is
revealed).

\subsubsection{Generation task as a measure of sequence
knowledge}\label{generation-task-as-a-measure-of-sequence-knowledge}

The generation task has been proposed as a useful and sensitive measure
of implicit knowledge (Jiménez et al., 1996; Perruchet \& Amorim, 1992).
Its sensitivity may be called into question by the finding that RT
effects obtained during the SRTT were often greater than
implicit-knowledge effects in the generation task. In part, this may be
attributed to the greater reliability of the RT measure, as it relies on
aggregation across a larger number of trials than does the generation
task. Another possible reason is that the generation task's sensitivity
as a measure of implicit knowledge may be lower than previously thought.
For instance, previous findings of implicit knowledge using the
generation task may have been overestimates of implicit knowledge due to
a violation of invariance for the controlled process with \(C_I > C_E\).
Note that most studies used much easier-to-learn materials (with four
instead of six locations); it is thus plausible that participants
acquired more explicit knowledge than they did in our experiments, and
that the overestimation bias was more severe in those studies.

Another possible reason for overestimating implicit knowledge is that
the regularities in the sequences implemented in previous research were
such that the probability of reversals (e.g., 1-2-1) was below chance.
Given that participants spontaneously tend to generate reversals at
below-chance levels, this implies that they instead generate other
regular transitions at slightly above-chance levels even in the absence
of any true sequence knowledge (Stahl et al., 2015). As a consequence of
this reversal-avoidance bias, implicit knowledge might be overestimated
if one uses chance baselines as a reference. This problem has been
discussed before (Destrebecqz \& Cleeremans, 2003; Reed \& Johnson,
1994; Shanks \& Johnstone, 1999), and was solved by comparing
performance on the training sequence with performance on a transfer
sequence containing a similarly low proportion of reversals. This
implies, however, that the PD approach does not provide a measure of the
absolute level of implicit or explicit knowledge; instead, by relying on
a comparison of performance across two sequences, it yields a difference
measure that is associated with reduced reliability. In addition, the
reversal-avoidance bias may not only mimic implicit knowledge; it may
also mimic (or mask) explicit knowledge if it interacted with the
inclusion-exclusion instructions, perhaps via different response
strategies or criteria adopted under inclusion versus exclusion
instructions.

\subsection{Conclusion and Outlook }\label{conclusion-and-outlook}

In light of the present findings suggesting limited validity of the PD
generation task, what can we conclude about explicit and implicit
sequence knowledge from its previous applications? Clearly, the
violation of basic assumptions implies that PD results cannot be
unambiguously interpreted: Unless we have a better understanding of the
processes that drive generation performance, and the degree to which
they operate under inclusion versus exclusion instructions, comparisons
between inclusion and exclusion performance do not support conclusions
about implicit and explicit knowledge. This also implies that a
reanalysis of previous findings (which is beyond the scope of the
present article) would probably provide limited insight. In this section
we therefore take a different approach: We initially accept the
conclusions reported in the literature about the contribution of
implicit and explicit knowledge at face value; consider the implications
of these conclusions about the presence of distortions arising from the
invariance violation; and then discuss how the initial conclusion should
be corrected in light of these distortions. To recap, the invariance
violation results in overestimation of implicit knowledge and
underestimation of explicit knowledge. These distortions differentially
affect the three patterns of results found in the literature (i.e.,
evidence for only implicit knowledge, for only explicit knowledge, or
both).

The first pattern, evidence for implicit but no explicit knowledge, was
found in only two studies (no-RSI condition, Destrebecqz \& Cleeremans,
2001; and Exp.3, 6-blocks condition, Q. Fu et al., 2008). In these
studies, however, explicit knowledge may nevertheless have been
acquired; the observed lack of significant evidence for explicit
knowledge may instead reflect the underestimation bias resulting from
the invariance violation, perhaps combined with relatively low
statistical power (with \(N = 12\) and \(N = 24\) in the respective
conditions).

Other attempts to replicate this finding were unsuccessful and instead
produced the second, opposite, pattern --- evidence for explicit but no
implicit knowledge (e.g., Wilkinson \& Shanks, 2004). In this case, the
evidence for explicit knowledge suggests that the distortions due to the
invariance violation apply: Obtaining evidence for explicit knowledge
despite the underestimation bias implies that explicit knowledge was
likely present. Obtaining no evidence for implicit knowledge despite the
likely presence of an overestimation bias supports the absence of
implicit knowledge (or, alternatively, it may reflect lack of
statistical power).

The third pattern---evidence for both explicit and implicit
knowledge---was reported in several studies (e.g., Destrebecqz \&
Cleeremans, 2001, 2003; Jiménez, Vaquero, \& Lupiáñez, 2006). The
evidence for explicit knowledge suggests that the distortions resulting
from the invariance violation may have compromised the results: Again,
the evidence for explicit knowledge obtained despite the underestimation
bias should probably be assumed to be reliable; however, the evidence
for implicit knowledge may be an artifact of the overestimation bias and
should be interpreted with caution.

Taken together, when considering the limitations discovered in our
studies, the PD approach to using the generation task as a measure of
implicit and explicit sequence knowledge in the SRTT has so far yielded
few reliable conclusions. If anything, results support the presence of
explicit knowledge and call into question the interpretation of PD
results as indicative of implicit knowledge.

It might be possible to devise a version of the generation task that
allows for the separation of automatic and controlled processes but does
not depend on exclusion of explicit knowledge and does not induce
different response criteria. For example, D'Angelo, Milliken, Jiménez,
and Lupiáñez (2013) implemented such a generation task variant in
artificial grammar learning in which two different inclusion
instructions were compared: After learning about two different grammars,
participants were asked, in the first (second) inclusion block to
generate exemplars from the first (second) grammar. Under certain
assumptions, performance differences between blocks can be interpreted
as evidence for explicit controllable knowledge. Exclusion failure and
different criteria presumably do not matter in this task: Participants
were not instructed to exclude explicit knowledge, and it is plausible
that the similarity of instructions for both generation tasks also
induced comparable response criteria. As another example, in the domain
of recognition memory, the PD procedure can be replaced by a
source-memory task in which, instead of including versus excluding items
from one of two study lists (A and B), participants are asked to
indicate the source of the word (list A or list B; Buchner et al., 1997;
Steffens, Buchner, Martensen, \& Erdfelder, 2000; Yu \& Bellezza, 2000).
Perhaps with a similar modification, an improved generation task may
prove a useful measure of sequence knowledge. Future research should
also consider using alternative methods of assessing implicit and
explicit knowledge (for a recent overview, see Timmermans \& Cleeremans,
2015).

One of the great benefits of multinomial models such as the PD model is
that they are flexibly adaptable measurement models for studying latent
cognitive processes using a wide variety of experimental paradigms
(Erdfelder et al., 2009). To validate a new model, it is common to
assess its goodness of fit, and to empirically demonstrate that its
parameters can be selectively manipulated and interpreted
psychologically (i.e., parameter estimates reflect targeted experimental
manipulations in the predicted manner; W. H. Batchelder \& Riefer,
1999). In many cases, however, simplifying assumptions need to be made;
for instance, latent processes are equated across two or more
experimental conditions (e.g., a single controlled process \(C\) is
assumed to operate under inclusion and exclusion conditions). Whenever
such assumptions of invariance are made, we propose that they should
also be tested empirically as part of the model-validation effort when a
new model is proposed, before it is used to investigate substantive
issues (for an example, see Brainerd, Reyna, \& Mojardin, 1999).


\section{References}\label{references}

\setlength{\parindent}{-0.5in} \setlength{\leftskip}{0.5in}
\setlength{\parskip}{8pt}

\hypertarget{refs}{}
\hypertarget{ref-albert_bayesian_1993}{}
Albert, J. H., \& Chib, S. (1993). Bayesian Analysis of Binary and
Polychotomous Response Data. \emph{Journal of the American Statistical
Association}, \emph{88}(422), 669--679.
doi:\href{https://doi.org/10.1080/01621459.1993.10476321}{10.1080/01621459.1993.10476321}

\hypertarget{ref-R-papaja}{}
Aust, F., \& Barth, M. (2017). \emph{papaja: Create APA manuscripts with
R Markdown}. Retrieved from \url{https://github.com/crsh/papaja}

\hypertarget{ref-batchelder_theoretical_1999}{}
Batchelder, W. H., \& Riefer, D. M. (1999). Theoretical and empirical
review of multinomial process tree modeling. \emph{Psychonomic Bulletin
\& Review}, \emph{6}(1), 57--86.
doi:\href{https://doi.org/10.3758/BF03210812}{10.3758/BF03210812}

\hypertarget{ref-brainerd_conjoint_1999}{}
Brainerd, C. J., Reyna, V. F., \& Mojardin, A. H. (1999). Conjoint
recognition. \emph{Psychological Review}, \emph{106}(1), 160--179.
doi:\href{https://doi.org/10.1037/0033-295X.106.1.160}{10.1037/0033-295X.106.1.160}

\hypertarget{ref-buchner_toward_1995}{}
Buchner, A., Erdfelder, E., \& Vaterrodt-Plünnecke, B. (1995). Toward
unbiased measurement of conscious and unconscious memory processes
within the process dissociation framework. \emph{Journal of Experimental
Psychology: General}, \emph{124}(2), 137--160.
doi:\href{https://doi.org/10.1037/0096-3445.124.2.137}{10.1037/0096-3445.124.2.137}

\hypertarget{ref-buchner_nature_1997}{}
Buchner, A., Erdfelder, E., Steffens, M. C., \& Martensen, H. (1997).
The nature of memory processes underlying recognition judgments in the
process dissociation procedure. \emph{Memory \& Cognition},
\emph{25}(4), 508--517.
doi:\href{https://doi.org/10.3758/BF03201126}{10.3758/BF03201126}

\hypertarget{ref-buchner_role_1998}{}
Buchner, A., Steffens, M. C., \& Rothkegel, R. (1998). On the role of
fragmentary knowledge in a sequence learning task. \emph{The Quarterly
Journal of Experimental Psychology Section A}, \emph{51}(2), 251--281.
doi:\href{https://doi.org/10.1080/713755757}{10.1080/713755757}

\hypertarget{ref-carpenter_stan:_2016}{}
Carpenter, B., Gelman, A., Hoffman, M., Lee, D., Goodrich, B.,
Betancourt, M., \ldots{} Riddell, A. (2016). Stan: A probabilistic
programming language. \emph{Journal of Statistical Software}, \emph{20},
1--37.
doi:\href{https://doi.org/10.18637/jss.v076.i01}{10.18637/jss.v076.i01}

\hypertarget{ref-cleeremans_implicit_2002}{}
Cleeremans, A., \& Jiménez, L. (2002). Implicit learning and
consciousness: A graded, dynamic perspective. In R. M. French \& A.
Cleeremans (Eds.), \emph{Implicit learning and consciousness: An
empirical, philosophical and computational consensus in the making} (pp.
1--40). Hove: Psychology Press. Retrieved from
\url{http://journalpsyche.org/articles/0xc03a.pdf}

\hypertarget{ref-cohen_attention_1990}{}
Cohen, A., Ivry, R. I., \& Keele, S. W. (1990). Attention and structure
in sequence learning. \emph{Journal of Experimental Psychology:
Learning, Memory, and Cognition}, \emph{16}(1), 17--30.
doi:\href{https://doi.org/10.1037/0278-7393.16.1.17}{10.1037/0278-7393.16.1.17}

\hypertarget{ref-curran_implicit_2001}{}
Curran, T. (2001). Implicit learning revealed by the method of
opposition. \emph{Trends in Cognitive Sciences}, \emph{5}(12), 503--504.
doi:\href{https://doi.org/10.1016/S1364-6613(00)01791-5}{10.1016/S1364-6613(00)01791-5}

\hypertarget{ref-curran_violations_1995}{}
Curran, T., \& Hintzman, D. L. (1995). Violations of the independence
assumption in process dissociation. \emph{Journal of Experimental
Psychology: Learning, Memory, and Cognition}, \emph{21}(3), 531--547.
doi:\href{https://doi.org/10.1037/0278-7393.21.3.531}{10.1037/0278-7393.21.3.531}

\hypertarget{ref-curran_consequences_1997}{}
Curran, T., \& Hintzman, D. L. (1997). Consequences and causes of
correlations in process dissociation. \emph{Journal of Experimental
Psychology. Learning, Memory \& Cognition}, \emph{23}(2), 496.
doi:\href{https://doi.org/10.1037/0278-7393.23.2.496}{10.1037/0278-7393.23.2.496}

\hypertarget{ref-destrebecqz_effect_2004}{}
Destrebecqz, A. (2004). The effect of explicit knowledge on sequence
learning: A graded account. \emph{Psychologica Belgica}, \emph{44}(4),
217. doi:\href{https://doi.org/10.5334/pb-44-4-217}{10.5334/pb-44-4-217}

\hypertarget{ref-destrebecqz_can_2001}{}
Destrebecqz, A., \& Cleeremans, A. (2001). Can sequence learning be
implicit? New evidence with the process dissociation procedure.
\emph{Psychonomic Bulletin \& Review}, \emph{8}(2), 343--350.
doi:\href{https://doi.org/10.3758/BF03196171}{10.3758/BF03196171}

\hypertarget{ref-destrebecqz_temporal_2003_doi}{}
Destrebecqz, A., \& Cleeremans, A. (2003). Temporal effects in sequence
learning. In \emph{Attention and implicit learning} (pp. 181--213).
Amsterdam, Netherlands: John Benjamins Publishing Company.
doi:\href{https://doi.org/10.1075/aicr.48.11des}{10.1075/aicr.48.11des}

\hypertarget{ref-dangelo_implementing_2013}{}
D'Angelo, M. C., Milliken, B., Jiménez, L., \& Lupiáñez, J. (2013).
Implementing flexibility in automaticity: Evidence from context-specific
implicit sequence learning. \emph{Consciousness and Cognition},
\emph{22}(1), 64--81.
doi:\href{https://doi.org/10.1016/j.concog.2012.11.002}{10.1016/j.concog.2012.11.002}

\hypertarget{ref-erdfelder_multinomial_2009}{}
Erdfelder, E., Auer, T.-S., Hilbig, B. E., Aßfalg, A., Moshagen, M., \&
Nadarevic, L. (2009). Multinomial Processing Tree Models: A review of
the literature. \emph{Zeitschrift Für Psychologie / Journal of
Psychology}, \emph{217}(3), 108--124.
doi:\href{https://doi.org/10.1027/0044-3409.217.3.108}{10.1027/0044-3409.217.3.108}

\hypertarget{ref-fu_implicit_2008}{}
Fu, Q., Fu, X., \& Dienes, Z. (2008). Implicit sequence learning and
conscious awareness. \emph{Consciousness and Cognition}, \emph{17}(1),
185--202.
doi:\href{https://doi.org/10.1016/j.concog.2007.01.007}{10.1016/j.concog.2007.01.007}

\hypertarget{ref-graf_process_1994}{}
Graf, P., \& Komatsu, S.-I. (1994). Process dissociation procedure:
Handle with caution! \emph{European Journal of Cognitive Psychology},
\emph{6}(2), 113--129.
doi:\href{https://doi.org/10.1080/09541449408520139}{10.1080/09541449408520139}

\hypertarget{ref-haider_conflicts_2009}{}
Haider, H., \& Frensch, P. A. (2009). Conflicts between expected and
actually performed behavior lead to verbal report of incidentally
acquired sequential knowledge. \emph{Psychological Research},
\emph{73}(6), 817--834.
doi:\href{https://doi.org/10.1007/s00426-008-0199-6}{10.1007/s00426-008-0199-6}

\hypertarget{ref-haider_old_2011}{}
Haider, H., Eichler, A., \& Lange, T. (2011). An old problem: How can we
distinguish between conscious and unconscious knowledge acquired in an
implicit learning task? \emph{Consciousness and Cognition},
\emph{20}(3), 658--672.
doi:\href{https://doi.org/10.1016/j.concog.2010.10.021}{10.1016/j.concog.2010.10.021}

\hypertarget{ref-hintzman_more_1997}{}
Hintzman, D. L., \& Curran, T. (1997). More than one way to violate
independence: Reply to Jacoby and Shrout (1997). \emph{Journal of
Experimental Psychology. Learning, Memory \& Cognition}, \emph{23}(2),
511.
doi:\href{https://doi.org/10.1037/0278-7393.23.2.511}{10.1037/0278-7393.23.2.511}

\hypertarget{ref-hirshman_ordinal_2004}{}
Hirshman, E. (2004). Ordinal Process Dissociation and the Measurement of
Automatic and Controlled Processes. \emph{Psychological Review},
\emph{111}(2), 553--560.
doi:\href{https://doi.org/10.1037/0033-295X.111.2.553}{10.1037/0033-295X.111.2.553}

\hypertarget{ref-jacoby_process_1991}{}
Jacoby, L. L. (1991). A process dissociation framework: Separating
automatic from intentional uses of memory. \emph{Journal of Memory and
Language}, \emph{30}(5), 513--541.
doi:\href{https://doi.org/10.1016/0749-596X(91)90025-F}{10.1016/0749-596X(91)90025-F}

\hypertarget{ref-jacoby_toward_1997}{}
Jacoby, L. L., \& Shrout, P. E. (1997). Toward a psychometric analysis
of violations of the independence assumption in process dissociation.
\emph{Journal of Experimental Psychology. Learning, Memory \&
Cognition}, \emph{23}(2), 505.
doi:\href{https://doi.org/10.1037/0278-7393.23.2.505}{10.1037/0278-7393.23.2.505}

\hypertarget{ref-jimenez_which_1999}{}
Jiménez, L., \& Méndez, C. (1999). Which attention is needed for
implicit sequence learning? \emph{Journal of Experimental Psychology:
Learning, Memory, and Cognition}, \emph{25}(1), 236--259.
doi:\href{https://doi.org/10.1037/0278-7393.25.1.236}{10.1037/0278-7393.25.1.236}

\hypertarget{ref-jimenez_comparing_1996}{}
Jiménez, L., Méndez, C., \& Cleeremans, A. (1996). Comparing direct and
indirect measures of sequence learning. \emph{Journal of Experimental
Psychology: Learning, Memory, and Cognition}, \emph{22}(4), 948.
doi:\href{https://doi.org/10.1037/0278-7393.22.4.948}{10.1037/0278-7393.22.4.948}

\hypertarget{ref-jimenez_qualitative_2006}{}
Jiménez, L., Vaquero, J. M. M., \& Lupiáñez, J. (2006). Qualitative
differences between implicit and explicit sequence learning.
\emph{Journal of Experimental Psychology: Learning, Memory, and
Cognition}, \emph{32}(3), 475--490.
doi:\href{https://doi.org/10.1037/0278-7393.32.3.475}{10.1037/0278-7393.32.3.475}

\hypertarget{ref-joordens_independence_1993}{}
Joordens, S., \& Merikle, P. M. (1993). Independence or redundancy? Two
models of conscious and unconscious influences. \emph{Journal of
Experimental Psychology: General}, \emph{122}(4), 462--467.
doi:\href{https://doi.org/10.1037/0096-3445.122.4.462}{10.1037/0096-3445.122.4.462}

\hypertarget{ref-joordens_turning_2010}{}
Joordens, S., Wilson, D. E., Spalek, T. M., \& Paré, D. E. (2010).
Turning the process-dissociation procedure inside-out: A new technique
for understanding the relation between conscious and unconscious
influences. \emph{Consciousness and Cognition}, \emph{19}(1), 270--280.
doi:\href{https://doi.org/10.1016/j.concog.2009.09.011}{10.1016/j.concog.2009.09.011}

\hypertarget{ref-klauer_hierarchical_2010}{}
Klauer, K. C. (2010). Hierarchical Multinomial Processing Tree Models: A
Latent-Trait Approach. \emph{Psychometrika}, \emph{75}(1), 70--98.
doi:\href{https://doi.org/10.1007/s11336-009-9141-0}{10.1007/s11336-009-9141-0}

\hypertarget{ref-klauer_invariance_2015}{}
Klauer, K. C., Dittrich, K., Scholtes, C., \& Voss, A. (2015). The
Invariance Assumption in Process-Dissociation Models: An Evaluation
Across Three Domains. \emph{Journal of Experimental Psychology:
General}, \emph{144}(1), 198--221.
doi:\href{https://doi.org/10.1037/xge0000044}{10.1037/xge0000044}

\hypertarget{ref-knapp_representing_2004}{}
Knapp, B. R., \& Batchelder, W. H. (2004). Representing parametric order
constraints in multi-trial applications of multinomial processing tree
models. \emph{Journal of Mathematical Psychology}, \emph{48}(4),
215--229.
doi:\href{https://doi.org/10.1016/j.jmp.2004.03.002}{10.1016/j.jmp.2004.03.002}

\hypertarget{ref-koch_patterns_2000}{}
Koch, I., \& Hoffmann, J. (2000). Patterns, chunks, and hierarchies in
serial reaction-time tasks. \emph{Psychological Research}, \emph{63}(1),
22--35.
doi:\href{https://doi.org/10.1007/PL00008165}{10.1007/PL00008165}

\hypertarget{ref-lewandowski_generating_2009}{}
Lewandowski, D., Kurowicka, D., \& Joe, H. (2009). Generating random
correlation matrices based on vines and extended onion method.
\emph{Journal of Multivariate Analysis}, \emph{100}(9), 1989--2001.
doi:\href{https://doi.org/10.1016/j.jmva.2009.04.008}{10.1016/j.jmva.2009.04.008}

\hypertarget{ref-liefooghe_instruction-based_2012}{}
Liefooghe, B., Wenke, D., \& De Houwer, J. (2012). Instruction-based
task-rule congruency effects. \emph{Journal of Experimental Psychology:
Learning, Memory, and Cognition}, \emph{38}(5), 1325--1335.
doi:\href{https://doi.org/10.1037/a0028148}{10.1037/a0028148}

\hypertarget{ref-nissen_attentional_1987}{}
Nissen, M. J., \& Bullemer, P. (1987). Attentional requirements of
learning: Evidence from performance measures. \emph{Cognitive
Psychology}, \emph{19}(1), 1--32.
doi:\href{https://doi.org/10.1016/0010-0285(87)90002-8}{10.1016/0010-0285(87)90002-8}

\hypertarget{ref-norman_fringe_2006}{}
Norman, E., Price, M. C., \& Duff, S. C. (2006). Fringe consciousness in
sequence learning: The influence of individual differences.
\emph{Consciousness and Cognition}, \emph{15}(4), 723--760.
doi:\href{https://doi.org/10.1016/j.concog.2005.06.003}{10.1016/j.concog.2005.06.003}

\hypertarget{ref-perruchet_conscious_1992}{}
Perruchet, P., \& Amorim, M.-A. (1992). Conscious knowledge and changes
in performance in sequence learning: Evidence against dissociation.
\emph{Journal of Experimental Psychology: Learning, Memory, and
Cognition}, \emph{18}(4), 785.
doi:\href{https://doi.org/10.1037/0278-7393.18.4.785}{10.1037/0278-7393.18.4.785}

\hypertarget{ref-perruchet_association_1993}{}
Perruchet, P., \& Gallego, J. (1993). Association between conscious
knowledge and performance in normal subjects: Reply to Cohen and Curran
(1993) and Willingham, Greeley, and Bardone (1993).
doi:\href{https://doi.org/10.1037/0278-7393.19.6.1438}{10.1037/0278-7393.19.6.1438}

\hypertarget{ref-perruchet_emergence_1997}{}
Perruchet, P., Bigand, E., \& Benoit-Gonin, F. (1997). The emergence of
explicit knowledge during the early phase of learning in sequential
reaction time tasks. \emph{Psychological Research}, \emph{60}(1-2),
4--13. doi:\href{https://doi.org/10.1007/BF00419676}{10.1007/BF00419676}

\hypertarget{ref-R-base}{}
R Core Team. (2017). \emph{R: A language and environment for statistical
computing}. Vienna, Austria: R Foundation for Statistical Computing.
Retrieved from \url{https://www.R-project.org/}

\hypertarget{ref-ratcliff_process_1995}{}
Ratcliff, R., Van Zandt, T., \& McKoon, G. (1995). Process dissociation,
single-process theories, and recognition memory. \emph{Journal of
Experimental Psychology: General}, \emph{124}(4), 352--374.
doi:\href{https://doi.org/10.1037/0096-3445.124.4.352}{10.1037/0096-3445.124.4.352}

\hypertarget{ref-reed_assessing_1994}{}
Reed, J., \& Johnson, P. (1994). Assessing implicit learning with
indirect tests: Determining what is learned about sequence structure.
\emph{Journal of Experimental Psychology: Learning, Memory, and
Cognition}, \emph{20}(3), 585--594.
doi:\href{https://doi.org/10.1037/0278-7393.20.3.585}{10.1037/0278-7393.20.3.585}

\hypertarget{ref-reingold_inter-relatedness_1990}{}
Reingold, E. M., \& Merikle, P. M. (1990). On the inter-relatedness of
theory and measurement in the study of unconscious processes. \emph{Mind
\& Language}, \emph{5}(1), 9--28.
doi:\href{https://doi.org/10.1111/j.1468-0017.1990.tb00150.x}{10.1111/j.1468-0017.1990.tb00150.x}

\hypertarget{ref-rouder_introduction_2005}{}
Rouder, J. N., \& Lu, J. (2005). An introduction to Bayesian
hierarchical models with an application in the theory of signal
detection. \emph{Psychonomic Bulletin \& Review}, \emph{12}(4),
573--604.
doi:\href{https://doi.org/10.3758/BF03196750}{10.3758/BF03196750}

\hypertarget{ref-rouder_hierarchical_2008}{}
Rouder, J. N., Lu, J., Morey, R. D., Sun, D., \& Speckman, P. L. (2008).
A hierarchical process-dissociation model. \emph{Journal of Experimental
Psychology: General}, \emph{137}(2), 370--389.
doi:\href{https://doi.org/10.1037/0096-3445.137.2.370}{10.1037/0096-3445.137.2.370}

\hypertarget{ref-shanks_evaluating_1999}{}
Shanks, D. R., \& Johnstone, T. (1999). Evaluating the relationship
between explicit and implicit knowledge in a sequential reaction time
task. \emph{Journal of Experimental Psychology: Learning, Memory, and
Cognition}, \emph{25}(6), 1435--1451.
doi:\href{https://doi.org/10.1037/0278-7393.25.6.1435}{10.1037/0278-7393.25.6.1435}

\hypertarget{ref-shanks_dissociation_2002}{}
Shanks, D. R., \& Perruchet, P. (2002). Dissociation between priming and
recognition in the expression of sequential knowledge. \emph{Psychonomic
Bulletin \& Review}, \emph{9}(2), 362--367.
doi:\href{https://doi.org/10.3758/BF03196294}{10.3758/BF03196294}

\hypertarget{ref-shanks_characteristics_1994}{}
Shanks, D. R., \& St. John, M. F. (1994). Characteristics of dissociable
human learning systems. \emph{Behavioral and Brain Sciences},
\emph{17}(3), 367--395.
doi:\href{https://doi.org/10.1017/S0140525X00035032}{10.1017/S0140525X00035032}

\hypertarget{ref-shanks_attentional_2005}{}
Shanks, D. R., Rowland, L. A., \& Ranger, M. S. (2005). Attentional load
and implicit sequence learning. \emph{Psychological Research},
\emph{69}(5-6), 369--382.
doi:\href{https://doi.org/10.1007/s00426-004-0211-8}{10.1007/s00426-004-0211-8}

\hypertarget{ref-R-afex}{}
Singmann, H., Bolker, B., Westfall, J., \& Aust, F. (2017). \emph{Afex:
Analysis of factorial experiments}. Retrieved from
\url{https://CRAN.R-project.org/package=afex}

\hypertarget{ref-spiegelhalter_bayesian_2002}{}
Spiegelhalter, D. J., Best, N. G., Carlin, B. P., \& Van Der Linde, A.
(2002). Bayesian measures of model complexity and fit. \emph{Journal of
the Royal Statistical Society: Series B (Statistical Methodology)},
\emph{64}(4), 583--639.
doi:\href{https://doi.org/10.1111/1467-9868.00353}{10.1111/1467-9868.00353}

\hypertarget{ref-spiegelhalter_deviance_2014}{}
Spiegelhalter, D. J., Best, N. G., Carlin, B. P., \& van der Linde, A.
(2014). The deviance information criterion: 12 years on. \emph{Journal
of the Royal Statistical Society: Series B (Statistical Methodology)},
\emph{76}(3), 485--493.
doi:\href{https://doi.org/10.1111/rssb.12062}{10.1111/rssb.12062}

\hypertarget{ref-stahl_distorted_2015}{}
Stahl, C., Barth, M., \& Haider, H. (2015). Distorted estimates of
implicit and explicit learning in applications of the
process-dissociation procedure to the SRT task. \emph{Consciousness and
Cognition}, \emph{37}, 27--43.
doi:\href{https://doi.org/10.1016/j.concog.2015.08.003}{10.1016/j.concog.2015.08.003}

\hypertarget{ref-steffens_further_2000}{}
Steffens, M. C., Buchner, A., Martensen, H., \& Erdfelder, E. (2000).
Further evidence on the similarity of memory processes in the process
dissociation procedure and in source monitoring. \emph{Memory \&
Cognition}, \emph{28}(7), 1152--1164.
doi:\href{https://doi.org/10.3758/BF03211816}{10.3758/BF03211816}

\hypertarget{ref-timmermans_how_2015}{}
Timmermans, B., \& Cleeremans, A. (2015). How can we measure awareness?
An overview of current methods. In \emph{Behavioural Methods in
Consciousness Research} (pp. 21--46). Oxford: Oxford University Press.

\hypertarget{ref-wilkinson_intentional_2004}{}
Wilkinson, L., \& Shanks, D. R. (2004). Intentional control and implicit
sequence learning. \emph{Journal of Experimental Psychology: Learning,
Memory, and Cognition}, \emph{30}(2), 354--369.
doi:\href{https://doi.org/10.1037/0278-7393.30.2.354}{10.1037/0278-7393.30.2.354}

\hypertarget{ref-willingham_development_1989}{}
Willingham, D. B., Nissen, M. J., \& Bullemer, P. (1989). On the
development of procedural knowledge. \emph{Journal of Experimental
Psychology: Learning, Memory, and Cognition}, \emph{15}(6), 1047--1060.
doi:\href{https://doi.org/10.1037/0278-7393.15.6.1047}{10.1037/0278-7393.15.6.1047}

\hypertarget{ref-yu_process_2000}{}
Yu, J., \& Bellezza, F. S. (2000). Process dissociation as source
monitoring. \emph{Journal of Experimental Psychology: Learning, Memory,
and Cognition}, \emph{26}(6), 1518--1533.
doi:\href{https://doi.org/10.1037/0278-7393.26.6.1518}{10.1037/0278-7393.26.6.1518}



\onecolumn

  \begin{appendix}
  \section{Generation performance}\label{generation-performance}
  
  This appendix provides the raw generation performance for all
  experiments in tables A1, A2, and A3.
  
  \begin{table}[h]
  \begin{center}
  \begin{threeparttable}
  \caption{\label{tab:appendix-pdl9-generation}Mean percentage of regular transitions generated in Experiment 1, excluding repetions. Standard deviations are given in parentheses.}
  \begin{tabular}{lll}
  \toprule
   & \multicolumn{1}{c}{Inclusion} & \multicolumn{1}{c}{Exclusion}\\
  \midrule
  $\textit{Full dataset}$ &  & \\
  Control & 25.10 (11.74) & 24.17 (7.02)\\
  No-Practice & 37.94 (16.26) & 28.66 (13.39)\\
  Unspecific-Practice & 34.46 (14.14) & 26.46 (15.02)\\
  Practice & 38.74 (13.08) & 24.59 (9.34)\\
  Transfer & 56.16 (18.32) & 26.51 (7.93)\\
  $\textit{Nonrevealed transitions}$ &  & \\
  Control & 25.10 (11.74) & 24.17 (7.02)\\
  No-Practice & 29.20 (18.56) & 31.90 (14.01)\\
  Unspecific-Practice & 30.38 (15.48) & 29.34 (14.06)\\
  Practice & 29.63 (14.62) & 26.81 (11.35)\\
  Transfer & 45.68 (24.66) & 43.95 (17.03)\\
  $\textit{Revealed, but nonpracticed transitions}$ &  & \\
  No-Practice & 47.64 (39.71) & 24.65 (31.82)\\
  Unspecific-Practice & 33.91 (32.58) & 20.07 (26.96)\\
  Transfer & 59.65 (33.59) & 16.72 (22.52)\\
  $\textit{Revealed-and-practiced transitions}$ &  & \\
  Practice & 75.65 (24.96) & 15.63 (29.87)\\
  Transfer & 79.51 (21.81) & 7.50 (7.13)\\
  \bottomrule
  \end{tabular}
  \end{threeparttable}
  \end{center}
  \end{table}
  
  \begin{table}[h]
  \begin{center}
  \begin{threeparttable}
  \caption{\label{tab:appendix-pdl7-generation}Mean percentage of regular transitions generated in Experiment 2, excluding repetions. Standard deviations are given in parentheses.}
  \begin{tabular}{lllll}
  \toprule
   & \multicolumn{2}{c}{Random} & \multicolumn{2}{c}{Probabilistic} \\
  \cmidrule(r){2-3} \cmidrule(r){4-5}
  Condition & \multicolumn{1}{c}{Inclusion} & \multicolumn{1}{c}{Exclusion} & \multicolumn{1}{c}{Inclusion} & \multicolumn{1}{c}{Exclusion}\\
  \midrule
  $\textit{Full dataset}$ &  &  &  & \\
  No transition revealed & 17.06 (8.64) & 18.94 (10.99) & 25.80 (19.20) & 23.37 (10.16)\\
  One transition revealed & 30.00 (14.91) & 15.26 (10.44) & 41.56 (15.60) & 22.38 (11.58)\\
  $\textit{Nonrevealed transitions}$ &  &  &  & \\
  No transition revealed & 17.06 (8.64) & 18.94 (10.99) & 25.80 (19.20) & 23.37 (10.16)\\
  One transition revealed & 18.46 (17.67) & 16.80 (11.47) & 31.29 (17.49) & 25.82 (14.26)\\
  $\textit{Revealed transitions}$ &  &  &  & \\
  One transition revealed & 79.37 (24.65) & 8.74 (11.51) & 86.75 (20.28) & 6.77 (12.20)\\
  \bottomrule
  \end{tabular}
  \end{threeparttable}
  \end{center}
  \end{table}
  

  \begin{table}[h]
  \begin{center}
  \begin{threeparttable}
  \caption{\label{tab:appendix-pdl10-generation}Mean percentage of regular transitions generated in Experiment 3, excluding repetions and reversals. Standard deviations are given in parentheses.}
  \begin{tabular}{lllllll}
  \toprule
   & \multicolumn{2}{c}{Random} & \multicolumn{2}{c}{Mixed SOC} & \multicolumn{2}{c}{Pure SOC} \\
  \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
  Condition & \multicolumn{1}{c}{Inclusion} & \multicolumn{1}{c}{Exclusion} & \multicolumn{1}{c}{Inclusion} & \multicolumn{1}{c}{Exclusion} & \multicolumn{1}{c}{Inclusion} & \multicolumn{1}{c}{Exclusion}\\
  \midrule
  $\textit{Full dataset}$ &  &  &  &  &  & \\
  No transition revealed & 26.57 (9.25) & 23.16 (9.58) & 28.43 (11.07) & 25.11 (9.51) & 28.85 (13.03) & 25.98 (9.13)\\
  Two transitions revealed & 34.27 (8.75) & 25.82 (6.00) & 38.87 (10.47) & 27.02 (10.85) & 34.26 (8.86) & 29.54 (8.93)\\
  $\textit{Nonrevealed transitions}$ &  &  &  &  &  & \\
  No transition revealed & 26.57 (9.25) & 23.16 (9.58) & 28.43 (11.07) & 25.11 (9.51) & 28.85 (13.03) & 25.98 (9.13)\\
  Two transitions revealed & 19.54 (8.86) & 24.46 (7.59) & 27.05 (11.64) & 27.19 (8.94) & 22.01 (9.61) & 27.93 (7.63)\\
  $\textit{Revealed transitions}$ &  &  &  &  &  & \\
  Two transitions revealed & 78.73 (28.18) & 28.90 (31.97) & 80.02 (21.62) & 24.59 (27.24) & 78.64 (26.53) & 29.92 (31.57)\\
  \bottomrule
  \end{tabular}
  \end{threeparttable}
  \end{center}
  \end{table}
  
  \clearpage
  \section{Additional model analyses}\label{additional-model-analyses}
  
  \setlength{\parindent}{0.5in} \setlength{\leftskip}{0in}
  \setlength{\parskip}{0pt}
  
  This appendix provides results of additional model analyses not included
  in the main text.
  
  \subsection{\texorpdfstring{Experiment 1, model
  \(\mathcal{M}_1\)}{Experiment 1, model \textbackslash{}mathcal\{M\}\_1}}\label{experiment-1-model-mathcalm_1}
  
  In Experiment 1, we fitted model \(\mathcal{M}_1\) and used posterior
  analyses to evaluate the invariance assumption. We adapted the equations
  from Experiment 2 to the design of Experiment 1 (which did not contain
  experimental groups with random material). In order to accommodate for
  the more complex design, we used a model specification that allowed for
  participant and item (i.e., transition) effects and their interactions
  by estimating fixed effects for each transition type plus individual
  participants' deviations from these effects. The model equations of
  model \(\mathcal{M}_1\) are given by:
  
  \[
    C_{ijm} = \begin{cases}
      \Phi(\mu_{jlm}^{(C)} + \delta_{ijm}^{(C)}) & \text{if } j \epsilon 1, 2 \text{ (item has been revealed \& practiced, revealed \& non-practiced)}\\
                                                0 & \text{if }j=3 \text{ (item has not been revealed)}\\
      \end{cases}
  \] and \[
    A_{imt} = \Phi(\mu_{mt}^{(A)} + \delta_{imt}^{(A)})
  \] where \(\mu_{jlm}^{(C)}\) is the fixed effect of transition type
  \(j\) (non-revealed, revealed \& practiced, revealed \& non-practiced)
  in condition \(l\) and \emph{PD instruction} condition \(m\) on
  controlled processes, and \(\delta_{ijm}^{(C)}\) is the \(i\)th
  participant's deviation from the corresponding mean. Accordingly,
  \(\mu_{mt}^{(A)}\) is the fixed effect of \emph{PD instruction}
  condition \(m\) and transition \(t\) on automatic processes, and
  \(\delta_{imt}^{(A)}\) is the \(i\)th participant's deviation from the
  corresponding mean.
  
  Model \(\mathcal{M}_1\) imposes two auxiliary assumptions: First, it
  assumed that no explicit knowledge has been acquired during the SRT
  phase (i.e., \(C=0\) for non-revealed transitions). Second, it assumed
  that revealing sequence knowledge did not affect automatic processes
  (i.e., \(A\) does not vary as a function of the between-subjects
  manipulation of explicit knowledge, index \(l\)). Both auxiliary
  assumptions were tested by posterior predictive checks. In addition to
  reporting \(T_{A1}\) and \(T_{B1}\) as in Experiments 2 and 3, we
  calculated additional model check statistic \(T_{A2}\), which summarizes
  how well the model describes the item-wise category counts (aggregated
  over participants), and \(T_{A3}\), which summarizes how well the model
  describes the category counts per participant-item combination; finally,
  the additional statistic \(T_{B2}\) summarizes how well the model
  describes the variances and covariances introduced by items. We also
  calculated the posterior differences \(C_I - C_E\) and \(A_I - A_E\) to
  more directly test the invariance assumption.
  
  \subsubsection{Results}\label{results}
  
  We analyzed generation performance by fitting \(\mathcal{M}_1\) and
  computed model fit statistics to assess whether each model can account
  for the data. Parameter estimates from model \(\mathcal{M}_1\) were used
  to address the invariance assumptions, directly. The first trial of a
  block as well as any response repetitions were excluded from all
  generation task analyses.
  
  The model checks for model \(\mathcal{M}_1\) were satisfactory,
  \[T_{A1}^{observed} = 35.97, T_{A1}^{expected} = 33.96, p = .322,\]~
  \[T_{A2}^{observed} = 0.05, T_{A2}^{expected} = 0.05, p = .480,\]~
  \[T_{A3}^{observed} = 1,763.79, T_{A3}^{expected} = 1,720.63, p = .372,\]~
  \[T_{B1}^{observed} = 5.31, T_{B1}^{expected} = 4.62, p = .457,\]~
  \[T_{B2}^{observed} = 3,852.65, T_{B2}^{expected} = 3,393.90, p = .464.\]
  
  \begin{figure}
  \centering
  \includegraphics{main_files/figure-latex/pdl9-parameter-estimates-1.pdf}
  \caption{\label{fig:pdl9-parameter-estimates}Parameter estimates from
  Experiment 1, model \(\mathcal{M}_1\). Error bars represent 95\%
  confidence intervals.}
  \end{figure}
  
  \begin{figure}
  \centering
  \includegraphics{main_files/figure-latex/pdl9-posterior-differences-1.pdf}
  \caption{\label{fig:pdl9-posterior-differences}Posterior differences between
  \(A_I - A_E\) and \(C_I - C_E\) in Experiment 1, plotted for each
  participant (gray dots) with 95\% credible intervals. Dashed lines
  represent the posterior means of the differences between mean parameter
  estimates. Dotted lines represent 95\% credible intervals.}
  \end{figure}
  
  Figure \ref{fig:pdl9-parameter-estimates} shows the parameter estimates
  obtained from model \(\mathcal{M}_1\); while estimates of the automatic
  process were only slightly above chance in both \emph{PD instruction}
  conditions, estimates of the controlled process differ strongly between
  \emph{PD instruction} conditions.
  
  Figure \ref{fig:pdl9-posterior-differences} shows that the invariance
  assumption for automatic processes was violated with \(A_I > A_E\), 95\%
  CI {[}.00, .03{]}, and Bayesian \(p = .008\). For revealed and practiced
  transitions, the invariance assumption was violated with \(C_I > C_E\),
  95\% CI {[}.19, .63{]} and a Bayesian \(p = .001\). For revealed but
  non-practiced transitions, the invariance assumption was violated with
  \(C_I > C_E\), 95\% CI {[}.03, .31{]} and a Bayesian \(p = .005\).
  
  \subsection{\texorpdfstring{Experiment 2, model
  \(\mathcal{M}_{1R}\)}{Experiment 2, model \textbackslash{}mathcal\{M\}\_\{1R\}}}\label{experiment-2-model-mathcalm_1r}
  
  To test whether our results are robust against changes in auxiliary
  assumptions, we fitted another model \(\mathcal{M}_{1R}\) with different
  auxiliary assumptions. Specifically, we dropped the assumption that
  \(C=0\) for nonrevealed transitions and instead estimated
  explicit-knowledge parameters for all transitions. Instead, we imposed
  ordinal restrictions (Knapp \& Batchelder, 2004) as follows: In model
  \(\mathcal{M}_{1R}\), it is assumed that \(C\) parameters are greater
  under inclusion than exclusion. We also fitted a parallel model with the
  reversed assumption, but estimation of this model failed to converge.
  
  The second-level equations of model \(\mathcal{M}_{1R}\) are given by:
  
  \[
    \begin{aligned}
    C_{ij1} &= C_{ij, Inclusion} &= \Phi(\mu_{jk,Inclusion}^{(C)} + \delta_{ij, Inclusion}^{(C)})& \\
    C_{ij2} &= C_{ij, Exclusion} &= \Phi(\mu_{jk,Exclusion}^{(C)} + \delta_{ij, Exclusion}^{(C)})& * C_{ij, Inclusion}
    \end{aligned}
  \] and
  
  \[
    A_{ijm} = \Phi(\mu_{jkm}^{(A)} + \delta_{ijm}^{(A)})
  \] \(\mu_{jkm}^{(C)}\) is the fixed effect of material \(k\) (that
  participant \(i\) worked on during the SRTT), \emph{transition type}
  \(j\) (\(j = 1\) if a transition has actually been revealed, \(j=2\) if
  not), and \emph{PD instruction} condition \(m\) on controlled processes.
  \(\delta_{ijm}^{(C)}\) is the \(i\)th participant's deviation from the
  respective group mean. For participants who did not receive explicit
  knowledge about a single transition, we assumed that all
  \(\mu_{jk, Inclusion}^{(C)} = \mu_{k, Inclusion}^{(C)}\) and
  \(\mu_{jk, Exclusion}^{(C)} = \mu_{k, Exclusion}^{(C)}\), i.e.~we
  assumed that the grand mean of explicit knowledge did not vary as a
  function of the transition that \emph{would} have been revealed if
  participants \emph{were} in another condition. Accordingly,
  \(\mu_{jkm}^{(A)}\) is the fixed effect of transition type \(j\)
  (\(j = 1\) for the transition that was or \emph{would} have been
  revealed, i.e.~transition \(2{-}6\), \(j=2\) for all other transitions),
  material \(k\), and \emph{PD instruction} condition \(m\) on automatic
  processes, and \(\delta_{ijm}^{(A)}\) is the \(i\)th participant's
  deviation from the corresponding mean.
  
  Note that this specification imposes two auxiliary assumptions to the
  model: First, it is assumed that
  \[\forall{ij}(C_{ij, \textit{Inclusion}} \geq C_{ij, \textit{Exclusion}})\]
  Second, it is assumed that automatic processes \(A\) do not vary as a
  function of the between-subjects manipulation of explicit knowledge
  \(l\) (both assumptions were necessary so that the model was identified;
  an alternative model imposing an order constraint \(C_I < C_E\) was also
  not identified).
  
  \subsubsection{Results}\label{results-1}
  
  The model checks for model \(\mathcal{M}_{1R}\) were satisfactory,
  \[T_{A1}^{observed} = 484.60, T_{A1}^{expected} = 470.11, p = .409,\]~
  \[T_{B1}^{observed} = 9.13, T_{B1}^{expected} = 6.88, p = .358.\] and
  attained a DIC value of \(25{,}294.53\), a value comparable to our
  extended model \(\mathcal{M}_{1}\) presented in the main text and
  clearly outperforming \(\mathcal{M}_2\). This again implies that our
  auxiliary assumptions introduced to \(\mathcal{M}_{1R}\) were much less
  problematic than the invariance assumption.
  
  \begin{figure}
  \centering
  \includegraphics{main_files/figure-latex/pdl7-m1r-parameter-estimates-1.pdf}
  \caption{\label{fig:pdl7-m1r-parameter-estimates}Parameter estimates from
  Experiment 2, model \(\mathcal{M}_{1R}\). Error bars represent 95\%
  confidence intervals.}
  \end{figure}
  
  \begin{figure}
  \centering
  \includegraphics{main_files/figure-latex/pdl7-m1r-posterior-differences-1.pdf}
  \caption{\label{fig:pdl7-m1r-posterior-differences}Posterior differences
  between \(A_I - A_E\) and \(C_I - C_E\) in Experiment 2, model
  \(\mathcal{M}_{1R}\), plotted for each participant (gray dots) with 95\%
  credible intervals. Dashed lines represent the posterior means of the
  differences between mean parameter estimates. Dotted lines represent
  95\% credible intervals.}
  \end{figure}
  
  Figure \ref{fig:pdl7-m1r-parameter-estimates} shows the parameter
  estimates obtained from model \(\mathcal{M}_{1R}\). The pattern of
  results mostly replicates the estimates from model \(\mathcal{M}_1\).
  The main difference was that \(C\) parameters were slightly greater than
  zero for nonrevealed transitions (these were set to zero for model
  \(\mathcal{M}_1\)). This may suggest that some explicit knowledge may
  have been acquired during the learning phase. Alternatively, it may also
  reflect a technical issue with the present family of models that biases
  estimates away from zero: Specifically, for nonrevealed transitions, the
  inclusion-exclusion difference in \(C\) estimates should vary around
  zero, with half below zero and half above zero; the auxiliary assumption
  however forces all of them to be positive, which biases the
  corresponding \(C\) parameters. Either way, the effect is not
  substantial, as suggested by the finding that model \(\mathcal{M}_1\),
  which assumes \(C=0\), achieved an equally good fit. The \(C>0\)
  estimates also have a tradeoff effect on \(A\) parameters, with lower
  estimates under inclusion and slightly higher estimates under exclusion.
  This biasing effect eliminated (for revealed transitions) or even
  inverted (for nonrevealed transitions) the invariance-violation effect
  found in \(\mathcal{M}_1\).
  
  Figure \ref{fig:pdl7-m1r-posterior-differences} shows the posterior
  differences obtained from model \(\mathcal{M}_{1R}\). Most importantly,
  the pattern of results shows that the invariance violation for
  controlled processes \(C\) for revealed transitions (i.e., whenever
  substantial explicit knowledge is present) is robust to the change in
  auxiliary assumptions.
  
  \subsection{\texorpdfstring{Experiment 3, model
  \(\mathcal{M}_{1R}\)}{Experiment 3, model \textbackslash{}mathcal\{M\}\_\{1R\}}}\label{experiment-3-model-mathcalm_1r}
  
  For the data of Experiment 3, we additionally fitted model
  \(\mathcal{M}_{1R}\) analogous to \(\mathcal{M}_{1R}\) of Experiment 2.
  
  \subsubsection{Results}\label{results-2}
  
  The model checks for model \(\mathcal{M}_{1R}\) were satisfactory,
  \[T_{A1}^{observed} = 689.87, T_{A1}^{expected} = 657.24, p = .314,\]~
  \[T_{B1}^{observed} = 8.94, T_{B1}^{expected} = 6.02, p = .263.\] and
  attained a DIC value of \(38{,}881.68\), a value somewhat smaller than
  the DIC of our extended model \(\mathcal{M}_{1}\) presented in the main
  text and clearly outperforming \(\mathcal{M}_2\). This again implies
  that our auxiliary assumptions introduced to \(\mathcal{M}_{1R}\) were
  much less problematic than the invariance assumption.
  
  \begin{figure}
  \centering
  \includegraphics{main_files/figure-latex/pdl10-m1r-parameter-estimates-1.pdf}
  \caption{\label{fig:pdl10-m1r-parameter-estimates}Parameter estimates from
  Experiment 3, model \(\mathcal{M}_{1R}\). Error bars represent 95\%
  confidence intervals.}
  \end{figure}
  
  \begin{figure}
  \centering
  \includegraphics{main_files/figure-latex/pdl10-m1r-posterior-differences-1.pdf}
  \caption{\label{fig:pdl10-m1r-posterior-differences}Posterior differences
  between \(A_I - A_E\) and \(C_I - C_E\) in Experiment 3, model
  \(\mathcal{M}_{1R}\), plotted for each participant (gray dots) with 95\%
  credible intervals. Dashed lines represent the posterior means of the
  differences between mean parameter estimates. Dotted lines represent
  95\% credible intervals.}
  \end{figure}
  
  Figure \ref{fig:pdl10-m1r-parameter-estimates} shows the parameter
  estimates obtained from model \(\mathcal{M}_{1R}\). The pattern of
  results mostly replicates the estimates from model \(\mathcal{M}_1\);
  with parameters for controlled processes \(C\) being estimated close to
  zero for nonrevealed transitions.
  
  Figure \ref{fig:pdl10-m1r-posterior-differences} shows the posterior
  differences obtained from model \(\mathcal{M}_{1R}\). The pattern of
  results again demonstrates robustness of the invariance violation for
  controlled processes \(C\) for revealed transitions (i.e., whenever
  substantial explicit knowledge was present). There was again some
  indication of an invariance violation for automatic processes \(A\);
  however, the effect was very small and depended on the specific modeling
  assumptions.
  
  \clearpage
  \section{Specification of priors}\label{specification-of-priors}
  
  This section provides a complete specification of the models and priors
  used. Code (\textbf{\textsf{R}}/\textbf{\textit{Stan}}) is available at
  \url{https://github.com/methexp/pdl2}.
  
  \subsection{\texorpdfstring{Experiment 1, model
  \(\mathcal{M}_1\)}{Experiment 1, model \textbackslash{}mathcal\{M\}\_1}}\label{experiment-1-model-mathcalm_1-1}
  
  Priors on fixed effects were
  
  \[
  \begin{aligned}
  \mu_{jlm}^{(C)} & \sim N(0, 1), j = \lbrace 1, 2 \rbrace; l = \lbrace 1, 2 \rbrace; m = \lbrace 1, 2 \rbrace\\
  \mu_{mt}^{(A)} & \sim N(0, 1), t = \lbrace 1, ..., 6 \rbrace ; m = \lbrace 1, 2 \rbrace\\
  \end{aligned}
  \]
  
  where \(j\) indexes \emph{transition type} (revealed \& practiced
  vs.~revealed \& non-practiced), \(l\) indexes practice condition
  (Control, No-practice, Unspecific-practice, Practice, Transfer), \(t\)
  indexes specific items (i.e., transitions), and \(m\) indexes \emph{PD
  instruction} (inclusion vs.~exclusion). Participant effects
  \(\delta_{imt}^{(A)}\) and \(\delta_{ijm}^{(C)}\) can be written as
  vectors \(\boldsymbol{\delta}_i\). For participants in the
  \emph{Control} group, these were modeled by \[
  \boldsymbol{\delta}_i \sim N_{12} (0, \Sigma_l), i = 1, ..., I
  \] For participants in the \emph{No-Practice},
  \emph{Unspecific-Practice}, and \emph{Practice} groups, \[
  \boldsymbol{\delta}_i \sim N_{14} (0, \Sigma_l), i = 1, ..., I
  \] For participants in the \emph{Transfer} group \[
  \boldsymbol{\delta}_i \sim N_{16} (0, \Sigma_l), i = 1, ..., I
  \] The covariance matrices \(\Sigma_l\) were modeled separately and
  independently for each between-subjects condition. Priors on these
  matrices were as described below for Experiment 2.
  
  \subsection{\texorpdfstring{Experiment 2, model
  \(\mathcal{M}_1\)}{Experiment 2, model \textbackslash{}mathcal\{M\}\_1}}\label{experiment-2-model-mathcalm_1}
  
  Priors on fixed effects were
  
  \[
  \begin{aligned}
  \mu_{km}^{(C)} \sim & N(0, 1), k = \lbrace 1, 2 \rbrace; m = \lbrace 1, 2 \rbrace\\
  \mu_{jkm}^{(A)} \sim & N(0, 1), j = \lbrace 1, 2 \rbrace; k = \lbrace 1, 2 \rbrace; m = \lbrace 1, 2 \rbrace
  \end{aligned}
  \] where \(j\) indexes transition type (revealed vs.~non-revealed),
  \(k\) indexes learning material presented during the SRTT (random
  vs.~probabilistic), and \(m\) indexes \emph{PD instruction} condition
  (inclusion vs.~exclusion). For participants who did not receive explicit
  knowledge about a single transition, we assumed that all
  \(C_{ijkm} = 0\). Therefore, participant effects are only required for
  automatic processes (\(\delta_{ijkm}^{(A)}\)). In participants who
  received explicit knowledge about one transition, two additional
  participant effects were needed to model controlled processes for
  revealed transitions (\(\delta_{ikm}^{(C)}\)). We thus provide the
  specification of participant effects for these two groups of
  participants separately.
  
  \paragraph{Participants who did not receive explicit knowledge about one
  transition}\label{participants-who-did-not-receive-explicit-knowledge-about-one-transition}
  
  For participants who did not receive explicit knowledge about one
  transition, participant effects \(\delta_{ijm}^{(A)}\) can be written as
  vectors \(\boldsymbol{\delta}_i\) that were modeled as draws from a
  multivariate normal
  
  \[
  \boldsymbol{\delta}_i \sim N_4 (0, \Sigma_{kl}), i = 1, ..., I
  \] where \(k\) indexes the learning material that was presented to
  participant \(i\) and \(l\) indexes his or her level of the
  explicit-knowledge factor. The covariance matrices \(\Sigma_{kl}\) were
  obtained from the standard deviations of participant effects
  \(\boldsymbol{\sigma}_{kl}\) and correlation matrices \(\Omega_{kl}\)
  
  \[
  \Sigma_{kl} = Diag(\boldsymbol{\sigma}_{kl})~\Omega_{kl}~Diag(\boldsymbol{\sigma}_{kl}), k = \lbrace 1, 2 \rbrace, l = \lbrace 1, 2 \rbrace
  \] Each element \(\sigma_{klp}\) of the vectors of standard deviations
  \(\boldsymbol{\sigma}_{kl}\) was drawn from independent half-normal
  prior distributions.
  
  \[
  \sigma_{klp} \sim N (0, 1)_{\mathcal{I}(0, \infty)}, k = \lbrace 1, 2 \rbrace, l = \lbrace 1, 2 \rbrace
  \] For the correlation matrices \(\Omega_{k}\), we used LKJ priors with
  a scaling factor of 1 (Lewandowski, Kurowicka, \& Joe, 2009):
  
  \[
  \Omega_{kl} \sim \textit{LKJcorr}(\nu = 1), k = \lbrace 1, 2 \rbrace, l = \lbrace 1, 2 \rbrace
  \]
  
  \paragraph{Participants who received explicit knowledge about one
  transition}\label{participants-who-received-explicit-knowledge-about-one-transition}
  
  For participants who received explicit knowledge about one transition,
  participant effects \(\delta_{ijm}^{(A)}\) and \(\delta_{im}^{(C)}\) can
  be written as vectors \(\boldsymbol{\delta}_i\) that were modeled as
  draws from a multivariate normal
  
  \[
  \boldsymbol{\delta}_i \sim N_6 (0, \Sigma_{kl}), i = 1, ..., I
  \] where \(k\) indexes the learning material that was presented to
  participant \(i\) and \(l\) indexes his or her level of the
  explicit-knowledge factor. The covariance matrices \(\Sigma_kl\) were
  specified as above, with the only exception that six instead of four
  parameters were required.
  
  \subsection{\texorpdfstring{Experiment 2, model
  \(\mathcal{M}_2\)}{Experiment 2, model \textbackslash{}mathcal\{M\}\_2}}\label{experiment-2-model-mathcalm_2}
  
  Priors on fixed effects were
  
  \[
  \begin{aligned}
  \mu_{jkl}^{(C)} \sim & N(0, 1), j = \lbrace 1, 2 \rbrace; k = \lbrace 1, 2 \rbrace; l = \lbrace 1, 2 \rbrace\\
  \mu_{jkl}^{(A)} \sim & N(0, 1), j = \lbrace 1, 2 \rbrace; k = \lbrace 1, 2 \rbrace; l = \lbrace 1, 2 \rbrace\\
  \end{aligned}
  \] Participant effects \(\delta_{ij}^{(A)}\) and \(\delta_{ij}^{(C)}\)
  can be written as vectors \(\boldsymbol{\delta}_i\) that were modeled by
  \[
  \boldsymbol{\delta}_i \sim N_4 (0, \Sigma_{kl}), i = 1, ..., I
  \] Priors for the covariance matrix \(\Sigma_{kl}\) were specified as
  above.
  
  \subsection{\texorpdfstring{Experiment 2, model
  \(\mathcal{M}_{1R}\)}{Experiment 2, model \textbackslash{}mathcal\{M\}\_\{1R\}}}\label{experiment-2-model-mathcalm_1r-1}
  
  Priors on fixed effects were
  
  \[
  \begin{aligned}
  \mu_{jkm}^{(C)} \sim & N(0, 1), j = \lbrace 1, 2 \rbrace; k = \lbrace 1, 2 \rbrace; m = \lbrace 1, 2 \rbrace\\
  \mu_{jkm}^{(A)} \sim & N(0, 1), j = \lbrace 1, 2 \rbrace; k = \lbrace 1, 2 \rbrace; m = \lbrace 1, 2 \rbrace
  \end{aligned}
  \] where \(j\) indexes transition type (revealed vs.~non-revealed),
  \(k\) indexes learning material presented during the SRTT (random
  vs.~probabilistic), and \(m\) indexes \emph{PD instruction} condition
  (inclusion vs.~exclusion). Participant effects \(\delta_{ijm}^{(A)}\)
  and \(\delta_{ijm}^{(C)}\) can be written as vectors
  \(\boldsymbol{\delta}_i\) that were modeled as draws from a multivariate
  normal
  
  \[
  \boldsymbol{\delta}_i \sim N_8 (0, \Sigma_{kl}), i = 1, ..., I
  \] where \(k\) indexes the learning material that was presented to
  participant \(i\) and \(l\) indexes his or her level of the
  explicit-knowledge factor. Priors for the covariance matrix
  \(\Sigma_{kl}\) were specified as above.
  
  \subsection{\texorpdfstring{Experiment 3, models \(\mathcal{M}_1\),
  \(\mathcal{M}_2\), and
  \(\mathcal{M}_{1R}\)}{Experiment 3, models \textbackslash{}mathcal\{M\}\_1, \textbackslash{}mathcal\{M\}\_2, and \textbackslash{}mathcal\{M\}\_\{1R\}}}\label{experiment-3-models-mathcalm_1-mathcalm_2-and-mathcalm_1r}
  
  For the model-based analyses, we used models \(\mathcal{M}_1\),
  \(\mathcal{M}_2\), and \(\mathcal{M}_{1R}\) analogous to those used in
  Experiment 2.
  \end{appendix}

\end{document}
